<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <title>2026-02-17 - é‡‘èæ•°æ®åŸºç¡€ â€” OHLCVã€Adjusted Pricesã€æ•°æ®æ¸…æ´—</title>
  <style>
    body { font-family: -apple-system, system-ui, sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; line-height: 1.8; color: #333; }
    .bilingual { display: grid; grid-template-columns: 1fr 1fr; gap: 20px; }
    .zh { border-left: 3px solid #c41e3a; padding-left: 15px; }
    .en { border-left: 3px solid #1a73e8; padding-left: 15px; }
    h1 { color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px; }
    h2 { color: #2c3e50; margin-top: 30px; }
    h3 { color: #34495e; }
    .formula { background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 15px 0; font-family: 'Courier New', monospace; }
    .code { background: #1e1e1e; color: #d4d4d4; padding: 15px; border-radius: 8px; overflow-x: auto; font-family: 'Courier New', monospace; white-space: pre; }
    .insight { background: #eaf2f8; padding: 15px; border-radius: 8px; margin: 20px 0; }
    .references { background: #f8f9fa; padding: 15px; border-radius: 8px; }
    .warning { background: #fdecea; padding: 15px; border-radius: 8px; border-left: 4px solid #e74c3c; margin: 15px 0; }
    .example { background: #e8f5e9; padding: 15px; border-radius: 8px; margin: 15px 0; }
    table { border-collapse: collapse; width: 100%; margin: 15px 0; }
    th, td { border: 1px solid #ddd; padding: 8px 12px; text-align: right; }
    th { background: #f8f9fa; text-align: center; }
    .tag { display: inline-block; background: #3498db; color: white; padding: 2px 8px; border-radius: 4px; font-size: 0.85em; margin: 2px; }
  </style>
</head>
<body>

<h1>ğŸ“Š Day 2: é‡‘èæ•°æ®åŸºç¡€ â€” OHLCVã€Adjusted Pricesã€æ•°æ®æ¸…æ´—</h1>
<p><strong>Financial Data Fundamentals â€” OHLCV, Adjusted Prices & Data Cleaning</strong></p>
<p><span class="tag">Phase 1: Foundations</span> <span class="tag">2026-02-17</span></p>

<hr>

<h2>ğŸ¯ ä¸ºä»€ä¹ˆæ•°æ®æ˜¯é‡åŒ–äº¤æ˜“çš„åœ°åŸºï¼Ÿ</h2>

<div class="bilingual">
<div class="zh">
<p>"Garbage in, garbage out" â€” è¿™å¥è¯åœ¨é‡åŒ–äº¤æ˜“ä¸­æ˜¯é“å¾‹ã€‚ä½ çš„ç­–ç•¥å†ç²¾å¦™ï¼Œå¦‚æœå»ºç«‹åœ¨æœ‰é—®é¢˜çš„æ•°æ®ä¸Šï¼Œç»“æœå°±æ˜¯ç¾éš¾ã€‚Renaissance Technologies çš„ Medallion åŸºé‡‘èŠ±äº†å¤§é‡èµ„æºæ¸…æ´—æ•°æ®ï¼ŒJim Simons æ›¾è¯´æ•°æ®è´¨é‡æ˜¯ä»–ä»¬æœ€é‡è¦çš„ç«äº‰ä¼˜åŠ¿ä¹‹ä¸€ã€‚</p>
<p>ä»Šå¤©æˆ‘ä»¬ä»æœ€åŸºç¡€çš„ä»·æ ¼æ•°æ®å¼€å§‹ï¼šç†è§£ OHLCV çš„å«ä¹‰ã€ä¸ºä»€ä¹ˆéœ€è¦è°ƒæ•´ä»·æ ¼ã€ä»¥åŠæ•°æ®æ¸…æ´—ä¸­æœ€å¸¸è§çš„é™·é˜±ã€‚</p>
</div>
<div class="en">
<p>"Garbage in, garbage out" â€” this is an iron law in quantitative trading. No matter how elegant your strategy, building it on flawed data leads to disaster. Renaissance Technologies' Medallion Fund invested heavily in data cleaning; Jim Simons has said data quality was one of their most important competitive advantages.</p>
<p>Today we start from the most fundamental price data: understanding OHLCV, why we need adjusted prices, and the most common pitfalls in data cleaning.</p>
</div>
</div>

<h2>ğŸ“ˆ 1. OHLCV â€” ä»·æ ¼æ•°æ®çš„äº”ä¸ªç»´åº¦</h2>

<div class="bilingual">
<div class="zh">
<h3>ä»€ä¹ˆæ˜¯ OHLCVï¼Ÿ</h3>
<p>å¯¹äºä»»ä½•ä¸€ä¸ªæ—¶é—´å‘¨æœŸï¼ˆæ—¥/æ—¶/åˆ†ï¼‰ï¼Œæˆ‘ä»¬è®°å½•äº”ä¸ªæ ¸å¿ƒæ•°æ®ç‚¹ï¼š</p>
<ul>
  <li><strong>O (Open)</strong> â€” å¼€ç›˜ä»·ï¼šè¯¥å‘¨æœŸç¬¬ä¸€ç¬”æˆäº¤ä»·æ ¼</li>
  <li><strong>H (High)</strong> â€” æœ€é«˜ä»·ï¼šè¯¥å‘¨æœŸå†…æœ€é«˜æˆäº¤ä»·æ ¼</li>
  <li><strong>L (Low)</strong> â€” æœ€ä½ä»·ï¼šè¯¥å‘¨æœŸå†…æœ€ä½æˆäº¤ä»·æ ¼</li>
  <li><strong>C (Close)</strong> â€” æ”¶ç›˜ä»·ï¼šè¯¥å‘¨æœŸæœ€åä¸€ç¬”æˆäº¤ä»·æ ¼</li>
  <li><strong>V (Volume)</strong> â€” æˆäº¤é‡ï¼šè¯¥å‘¨æœŸå†…æ€»æˆäº¤è‚¡æ•°</li>
</ul>
<p>æ”¶ç›˜ä»·æ˜¯æœ€é‡è¦çš„â€”â€”å¤§å¤šæ•°æŠ€æœ¯æŒ‡æ ‡å’Œç­–ç•¥éƒ½åŸºäºæ”¶ç›˜ä»·è®¡ç®—ã€‚ä½†å¼€ç›˜ä»·å¯¹ gap ç­–ç•¥å¾ˆé‡è¦ï¼Œé«˜ä½ä»·å¯¹æ³¢åŠ¨ç‡è®¡ç®—å¾ˆå…³é”®ã€‚</p>
</div>
<div class="en">
<h3>What is OHLCV?</h3>
<p>For any time period (daily/hourly/minute), we record five core data points:</p>
<ul>
  <li><strong>O (Open)</strong> â€” Opening price: first trade of the period</li>
  <li><strong>H (High)</strong> â€” Highest trade price during the period</li>
  <li><strong>L (Low)</strong> â€” Lowest trade price during the period</li>
  <li><strong>C (Close)</strong> â€” Closing price: last trade of the period</li>
  <li><strong>V (Volume)</strong> â€” Total shares traded during the period</li>
</ul>
<p>The close is the most important â€” most indicators and strategies are computed from closing prices. But open matters for gap strategies, and high/low are critical for volatility calculations.</p>
</div>
</div>

<div class="example">
<strong>ğŸ“‹ ç¤ºä¾‹ï¼šAAPL æ—¥çº¿æ•°æ®</strong>
<table>
<tr><th>Date</th><th>Open</th><th>High</th><th>Low</th><th>Close</th><th>Volume</th><th>Adj Close</th></tr>
<tr><td>2024-08-05</td><td>199.09</td><td>213.50</td><td>196.00</td><td>209.27</td><td>119,548,600</td><td>208.54</td></tr>
<tr><td>2024-08-06</td><td>205.30</td><td>209.99</td><td>201.07</td><td>207.23</td><td>69,714,700</td><td>206.51</td></tr>
<tr><td>2024-08-07</td><td>206.90</td><td>213.64</td><td>206.39</td><td>209.82</td><td>60,402,800</td><td>209.09</td></tr>
</table>
</div>

<h2>âš ï¸ 2. ä¸ºä»€ä¹ˆ Close â‰  Adjusted Closeï¼Ÿ</h2>

<div class="bilingual">
<div class="zh">
<h3>ä¸¤ä¸ªä¼šæ”¹å˜ä»·æ ¼çš„äº‹ä»¶</h3>
<p><strong>â‘  è‚¡ç¥¨æ‹†åˆ† (Stock Split)</strong></p>
<p>å½“å…¬å¸åš 4:1 æ‹†åˆ†æ—¶ï¼Œæ¯è‚¡ä»·æ ¼å˜ä¸ºåŸæ¥çš„ 1/4ï¼Œä½†æŒè‚¡æ•°å˜ä¸º 4 å€ã€‚å¦‚æœä¸è°ƒæ•´å†å²ä»·æ ¼ï¼Œä½ çš„å›¾è¡¨ä¸Šä¼šå‡ºç°ä¸€ä¸ªå·¨å¤§çš„"æ–­å´–"â€”â€”çœ‹èµ·æ¥è‚¡ä»·æš´è·Œäº† 75%ï¼Œä½†å®é™…ä¸Šä»€ä¹ˆéƒ½æ²¡å‘ç”Ÿã€‚</p>

<p><strong>â‘¡ ç°é‡‘åˆ†çº¢ (Cash Dividend)</strong></p>
<p>é™¤æ¯æ—¥ (ex-dividend date) å½“å¤©ï¼Œè‚¡ä»·ä¼šè‡ªåŠ¨ä¸‹è°ƒçº¦ç­‰äºåˆ†çº¢é‡‘é¢ã€‚å¦‚æœ AAPL æ´¾å‘ $0.25 çš„è‚¡æ¯ï¼Œé™¤æ¯æ—¥è‚¡ä»·å¤§çº¦ä¸‹è·Œ $0.25ã€‚ä¸è°ƒæ•´çš„è¯ï¼Œä½ çš„æ”¶ç›Šç‡è®¡ç®—ä¼šä½ä¼°çœŸå®å›æŠ¥ã€‚</p>

<h3>è°ƒæ•´å…¬å¼</h3>
</div>
<div class="en">
<h3>Two Events That Change Prices</h3>
<p><strong>â‘  Stock Splits</strong></p>
<p>When a company does a 4:1 split, the per-share price becomes 1/4 but share count quadruples. Without adjustment, your chart shows a massive "cliff" â€” looks like a 75% crash, but nothing actually happened.</p>

<p><strong>â‘¡ Cash Dividends</strong></p>
<p>On the ex-dividend date, the stock price automatically drops by roughly the dividend amount. If AAPL pays $0.25 dividend, the price drops ~$0.25. Without adjustment, your return calculations underestimate true returns.</p>

<h3>Adjustment Formulas</h3>
</div>
</div>

<div class="formula">
<strong>æ‹†åˆ†è°ƒæ•´ / Split Adjustment:</strong><br><br>
Split Factor = 1 / Split Ratio<br>
ä¾‹: 4:1 split â†’ Split Factor = 0.25<br><br>
Adjusted Price = Raw Price Ã— Split Factor<br><br>

<strong>åˆ†çº¢è°ƒæ•´ / Dividend Adjustment:</strong><br><br>
Dividend Factor = 1 - (Dividend / Close_before_ex)<br><br>
ä¾‹: Close = $200, Dividend = $0.50<br>
Dividend Factor = 1 - (0.50 / 200) = 0.9975<br><br>

<strong>ç»¼åˆè°ƒæ•´ / Combined:</strong><br><br>
Adjusted Close = Close Ã— âˆ(Split Factors) Ã— âˆ(Dividend Factors)<br>
<em>æ³¨æ„ï¼šè°ƒæ•´æ˜¯å‘åè¿½æº¯çš„ (backward-looking)ï¼Œæœ€æ–°ä»·æ ¼ = åŸå§‹ä»·æ ¼</em>
</div>

<div class="warning">
<strong>âš ï¸ å…³é”®é™·é˜±ï¼šè°ƒæ•´ä»·æ ¼ä¼šéšæ—¶é—´å˜åŒ–ï¼</strong><br>
æ¯æ¬¡å…¬å¸æ´¾å‘æ–°çš„è‚¡æ¯æˆ–æ‹†åˆ†ï¼Œ<em>æ‰€æœ‰</em>å†å²è°ƒæ•´ä»·æ ¼éƒ½ä¼šé‡æ–°è®¡ç®—ã€‚è¿™æ„å‘³ç€ä½ ä¸Šå‘¨ä¸‹è½½çš„ Adjusted Close å’Œä»Šå¤©ä¸‹è½½çš„å¯èƒ½ä¸åŒã€‚<strong>å›æµ‹æ—¶å¿…é¡»ä½¿ç”¨ point-in-time æ•°æ®ï¼Œå¦åˆ™ä¼šå¼•å…¥ look-ahead biasã€‚</strong>
</div>

<h2>ğŸ§¹ 3. æ•°æ®æ¸…æ´— â€” ä½ å¿…é¡»å¤„ç†çš„ 7 ä¸ªé—®é¢˜</h2>

<div class="bilingual">
<div class="zh">
<h3>é—®é¢˜ 1ï¼šç¼ºå¤±æ•°æ® (Missing Data)</h3>
<p>èŠ‚å‡æ—¥æ— äº¤æ˜“ï¼Œæœ‰äº›æ•°æ®æºä¼šè·³è¿‡è¿™äº›å¤©ï¼Œæœ‰äº›ä¼šå¡« NaNã€‚å¤„ç†æ–¹æ³•ï¼šå‘å‰å¡«å…… (forward fill)ï¼Œä½†æ³¨æ„ä¸è¦è·¨è¶Šå¤ªé•¿çš„ gapã€‚</p>

<h3>é—®é¢˜ 2ï¼šå¼‚å¸¸å€¼ (Outliers)</h3>
<p>Flash crashã€é”™è¯¯æŠ¥ä»·ã€æ•°æ®ä¼ è¾“é”™è¯¯éƒ½ä¼šäº§ç”Ÿå¼‚å¸¸å€¼ã€‚2010 å¹´ Flash Crash æ—¶ï¼Œä¸€äº›è‚¡ç¥¨ç¬é—´è·Œåˆ° $0.01ã€‚ç”¨ç»Ÿè®¡æ–¹æ³•æ£€æµ‹ï¼šå¦‚æœå•æ—¥æ”¶ç›Šç‡è¶…è¿‡ Â±50%ï¼Œæ ‡è®°ä¸ºå¯ç–‘ã€‚</p>

<h3>é—®é¢˜ 3ï¼šå¹¸å­˜è€…åå·® (Survivorship Bias)</h3>
<p>å¦‚æœä½ çš„æ•°æ®åªåŒ…å«å½“å‰åœ¨å¸‚çš„è‚¡ç¥¨ï¼Œå¿½ç•¥äº†å·²é€€å¸‚çš„å…¬å¸ï¼ˆç ´äº§ã€è¢«æ”¶è´­ç­‰ï¼‰ï¼Œä½ çš„å›æµ‹ç»“æœä¼šè¿‡åº¦ä¹è§‚ã€‚è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨åŒ…å«é€€å¸‚è‚¡ç¥¨çš„æ•°æ®åº“ã€‚</p>

<h3>é—®é¢˜ 4ï¼šå¤æƒæ–¹å¼ä¸ä¸€è‡´</h3>
<p>å‰å¤æƒ vs åå¤æƒ vs ä¸å¤æƒ â€” ä¸åŒæ•°æ®æºå¯èƒ½é»˜è®¤ä¸åŒã€‚ç»Ÿä¸€ä½¿ç”¨åå¤æƒ (backward adjusted) åšå›æµ‹ã€‚</p>

<h3>é—®é¢˜ 5ï¼šæ—¶åŒºä¸æ—¶é—´æˆ³</h3>
<p>ç¾è‚¡äº¤æ˜“æ—¶é—´ 9:30-16:00 ETã€‚åŠ å¯†è´§å¸ 24/7ã€‚æ··åˆæ•°æ®æ—¶è¦å¯¹é½æ—¶åŒºã€‚</p>

<h3>é—®é¢˜ 6ï¼šå…¬å¸è¡Œä¸ºäº‹ä»¶ (Corporate Actions)</h3>
<p>é™¤äº†æ‹†åˆ†å’Œåˆ†çº¢ï¼Œè¿˜æœ‰ï¼šåå‘æ‹†åˆ†ã€ç‰¹åˆ«åˆ†çº¢ã€spin-offï¼ˆåˆ†æ‹†ï¼‰ã€‚æ¯ä¸€ç§éƒ½éœ€è¦ä¸åŒçš„è°ƒæ•´é€»è¾‘ã€‚</p>

<h3>é—®é¢˜ 7ï¼šæ•°æ®æºå·®å¼‚</h3>
<p>Yahoo Financeã€Bloombergã€Refinitiv çš„åŒä¸€è‚¡ç¥¨åŒä¸€å¤©çš„æ•°æ®å¯èƒ½ä¸å®Œå…¨ç›¸åŒã€‚å°¤å…¶æ˜¯æˆäº¤é‡å’Œè°ƒæ•´ä»·æ ¼ã€‚</p>
</div>
<div class="en">
<h3>Problem 1: Missing Data</h3>
<p>Holidays have no trades; some sources skip dates, others fill NaN. Solution: forward-fill, but beware of long gaps.</p>

<h3>Problem 2: Outliers</h3>
<p>Flash crashes, erroneous quotes, transmission errors all create outliers. During the 2010 Flash Crash, some stocks momentarily traded at $0.01. Statistical detection: flag single-day returns exceeding Â±50%.</p>

<h3>Problem 3: Survivorship Bias</h3>
<p>If your data only includes currently-listed stocks, ignoring delisted companies (bankrupt, acquired, etc.), your backtest results will be over-optimistic. Solution: use a database that includes delisted stocks.</p>

<h3>Problem 4: Inconsistent Adjustments</h3>
<p>Forward-adjusted vs backward-adjusted vs unadjusted â€” different sources may default differently. Standardize on backward-adjusted for backtesting.</p>

<h3>Problem 5: Timezone & Timestamps</h3>
<p>US stocks trade 9:30-16:00 ET. Crypto trades 24/7. When mixing data, align timezones carefully.</p>

<h3>Problem 6: Corporate Actions</h3>
<p>Beyond splits and dividends: reverse splits, special dividends, spin-offs. Each needs different adjustment logic.</p>

<h3>Problem 7: Data Source Discrepancies</h3>
<p>Yahoo Finance, Bloomberg, Refinitiv may report different values for the same stock on the same day. Especially volume and adjusted prices.</p>
</div>
</div>

<h2>ğŸ’» 4. Python å®æˆ˜ â€” ä¸‹è½½ã€æ¸…æ´—ã€è°ƒæ•´</h2>

<div class="code">import yfinance as yf
import pandas as pd
import numpy as np

# ============================================
# Step 1: Download OHLCV Data
# ============================================
ticker = "AAPL"
df = yf.download(ticker, start="2020-01-01", end="2026-02-17")
print(f"Shape: {df.shape}")
print(df.head())

# ============================================
# Step 2: Check for Missing Data
# ============================================
print(f"\nMissing values:\n{df.isnull().sum()}")

# Check for gaps in trading days
df.index = pd.to_datetime(df.index)
trading_days = pd.bdate_range(df.index[0], df.index[-1])
missing_days = trading_days.difference(df.index)
print(f"\nMissing trading days: {len(missing_days)}")
# Note: some are holidays, which is normal

# ============================================
# Step 3: Detect Outliers
# ============================================
df['returns'] = df['Close'].pct_change()
df['log_returns'] = np.log(df['Close'] / df['Close'].shift(1))

# Flag extreme moves (> 3 standard deviations)
mean_ret = df['returns'].mean()
std_ret = df['returns'].std()
outliers = df[np.abs(df['returns'] - mean_ret) > 3 * std_ret]
print(f"\nOutlier days (>3Ïƒ): {len(outliers)}")
print(outliers[['Close', 'returns']].head(10))

# ============================================
# Step 4: Verify Adjusted Prices
# ============================================
# The adjustment ratio tells us about splits/dividends
df['adj_ratio'] = df['Adj Close'] / df['Close']
print(f"\nAdj ratio range: {df['adj_ratio'].min():.6f} to {df['adj_ratio'].max():.6f}")

# If ratio < 1 for historical data, dividends/splits occurred
# If ratio = 1 for recent data, that's expected (most recent = unadjusted)

# ============================================
# Step 5: Calculate Returns Correctly
# ============================================
# WRONG: using raw Close
wrong_returns = df['Close'].pct_change()

# RIGHT: using Adjusted Close (captures dividends)
right_returns = df['Adj Close'].pct_change()

# Compare cumulative returns
wrong_cumulative = (1 + wrong_returns).cumprod().iloc[-1] - 1
right_cumulative = (1 + right_returns).cumprod().iloc[-1] - 1
print(f"\nCumulative return (raw close):      {wrong_cumulative:.2%}")
print(f"Cumulative return (adjusted close):  {right_cumulative:.2%}")
print(f"Difference (missed dividends):       {right_cumulative - wrong_cumulative:.2%}")

# ============================================
# Step 6: Build a Clean Dataset
# ============================================
def clean_ohlcv(df, max_return=0.5):
    """Clean OHLCV data for backtesting."""
    clean = df.copy()
    
    # 1. Remove rows with any NaN in OHLCV
    clean = clean.dropna(subset=['Open', 'High', 'Low', 'Close', 'Volume'])
    
    # 2. Validate OHLCV relationships
    # High must be >= Open, Close, Low
    # Low must be <= Open, Close, High
    valid = (
        (clean['High'] >= clean['Low']) &
        (clean['High'] >= clean['Open']) &
        (clean['High'] >= clean['Close']) &
        (clean['Low'] <= clean['Open']) &
        (clean['Low'] <= clean['Close']) &
        (clean['Volume'] >= 0)
    )
    invalid_count = (~valid).sum()
    if invalid_count > 0:
        print(f"Removed {invalid_count} rows with invalid OHLCV relationships")
    clean = clean[valid]
    
    # 3. Flag extreme returns (but don't auto-remove)
    returns = clean['Adj Close'].pct_change()
    extreme = np.abs(returns) > max_return
    if extreme.sum() > 0:
        print(f"Warning: {extreme.sum()} days with |return| > {max_return:.0%}")
        print(clean[extreme][['Close', 'Volume']])
    
    # 4. Forward-fill minor gaps (max 3 days)
    clean = clean.asfreq('B')  # Business day frequency
    clean = clean.ffill(limit=3)
    
    return clean

df_clean = clean_ohlcv(df)
print(f"\nClean dataset: {len(df_clean)} rows")</div>

<h2>ğŸ“ 5. å…³é”®å…¬å¼æ€»ç»“</h2>

<div class="formula">
<strong>ç®€å•æ”¶ç›Šç‡ / Simple Return:</strong><br>
R_t = (P_t - P_{t-1}) / P_{t-1} = P_t / P_{t-1} - 1<br><br>

<strong>å¯¹æ•°æ”¶ç›Šç‡ / Log Return:</strong><br>
r_t = ln(P_t / P_{t-1}) = ln(P_t) - ln(P_{t-1})<br><br>

<strong>ä¸ºä»€ä¹ˆå¯¹æ•°æ”¶ç›Šç‡æ›´å¥½ï¼Ÿ</strong><br>
1. å¯åŠ æ€§ï¼šr_total = r_1 + r_2 + ... + r_n ï¼ˆç®€å•æ”¶ç›Šç‡ä¸å¯åŠ ï¼‰<br>
2. å¯¹ç§°æ€§ï¼š+10% å’Œ -10% çš„å¯¹æ•°æ”¶ç›Šç‡å¹…åº¦ç›¸ç­‰<br>
3. ç»Ÿè®¡æ€§è´¨æ›´å¥½ï¼šè¿‘ä¼¼æ­£æ€åˆ†å¸ƒ<br><br>

<strong>ä½†æ³¨æ„ï¼š</strong><br>
- æˆªé¢æ¯”è¾ƒï¼ˆè·¨è‚¡ç¥¨ï¼‰æ—¶ç”¨ç®€å•æ”¶ç›Šç‡<br>
- æ—¶é—´åºåˆ—åˆ†æï¼ˆå•åªè‚¡ç¥¨è·¨æ—¶é—´ï¼‰æ—¶ç”¨å¯¹æ•°æ”¶ç›Šç‡<br>
- ç»„åˆæ”¶ç›Šç‡ = Î£(w_i Ã— R_i) â€” åªå¯¹ç®€å•æ”¶ç›Šç‡æˆç«‹ï¼
</div>

<h2>ğŸ” 6. æ•°æ®æºå¯¹æ¯”</h2>

<table>
<tr><th>æ•°æ®æº</th><th>å…è´¹?</th><th>è°ƒæ•´ä»·æ ¼</th><th>é€€å¸‚è‚¡ç¥¨</th><th>é€‚åˆ</th></tr>
<tr><td>Yahoo Finance</td><td>âœ…</td><td>âœ… åå¤æƒ</td><td>âŒ æœ‰é™</td><td>å­¦ä¹ ã€åŸå‹</td></tr>
<tr><td>Alpha Vantage</td><td>âœ… (é™é€Ÿ)</td><td>âœ…</td><td>âŒ</td><td>å°è§„æ¨¡é¡¹ç›®</td></tr>
<tr><td>Polygon.io</td><td>ğŸ’° (å…è´¹å±‚)</td><td>âœ…</td><td>âœ…</td><td>ä¸­ç­‰è§„æ¨¡</td></tr>
<tr><td>Quandl/Nasdaq</td><td>ğŸ’°</td><td>âœ…</td><td>âœ…</td><td>ä¸“ä¸šå›æµ‹</td></tr>
<tr><td>Bloomberg</td><td>ğŸ’°ğŸ’°ğŸ’°</td><td>âœ…</td><td>âœ…</td><td>æœºæ„çº§</td></tr>
<tr><td>CRSP</td><td>ğŸ’°ğŸ’°</td><td>âœ… æœ€æƒå¨</td><td>âœ… å®Œæ•´</td><td>å­¦æœ¯ç ”ç©¶</td></tr>
</table>

<div class="insight">
<strong>ğŸ’¡ å®æˆ˜å»ºè®®</strong><br>
<p>ä¸ªäººé‡åŒ–èµ·æ­¥é˜¶æ®µï¼šYahoo Finance + yfinance åº“è¶³å¤Ÿäº†ã€‚ä½†è¦æ„è¯†åˆ°å…¶å±€é™æ€§ï¼š</p>
<ul>
  <li>è°ƒæ•´ä»·æ ¼å¯èƒ½ä¸å®Œå…¨å‡†ç¡®ï¼ˆç‰¹åˆ«æ˜¯å†å²è¾ƒä¹…çš„æ•°æ®ï¼‰</li>
  <li>ä¸åŒ…å«å®Œæ•´çš„é€€å¸‚è‚¡ç¥¨æ•°æ® â†’ å¹¸å­˜è€…åå·®</li>
  <li>åˆ†é’Ÿçº§æ•°æ®åªä¿ç•™æœ€è¿‘ 30 å¤©</li>
</ul>
<p>å½“ç­–ç•¥éªŒè¯é˜¶æ®µç»“æŸã€å‡†å¤‡å®ç›˜æ—¶ï¼Œå»ºè®®å‡çº§åˆ° Polygon.io æˆ– Databentoã€‚</p>
</div>

<h2>ğŸ”— çŸ¥è¯†ç½‘ç»œ Knowledge Graph</h2>

<div class="insight">
<p><strong>Day 1 (é‡åŒ–äº¤æ˜“æ¦‚è§ˆ)</strong> â†’ æˆ‘ä»¬çŸ¥é“äº†é‡åŒ–äº¤æ˜“çš„å…¨è²Œ<br>
<strong>Day 2 (é‡‘èæ•°æ®åŸºç¡€)</strong> â†’ ç°åœ¨ç†è§£äº†æ•°æ®â€”â€”é‡åŒ–çš„åŸææ–™<br>
<strong>Day 3 (æ”¶ç›Šç‡è®¡ç®—)</strong> â†’ æ¥ä¸‹æ¥æ·±å…¥æ”¶ç›Šç‡çš„æ•°å­¦ï¼Œè¿™æ˜¯ç­–ç•¥è¯„ä¼°çš„åŸºç¡€</p>

<p>æ•°æ®æ˜¯ä¸€åˆ‡çš„èµ·ç‚¹ã€‚æ²¡æœ‰å¹²å‡€çš„æ•°æ®ï¼Œå†å¥½çš„æ¨¡å‹ä¹Ÿæ— ç”¨ã€‚Jim Simonsã€Cliff Asnessã€Ernest Chan éƒ½åå¤å¼ºè°ƒï¼š<strong>åœ¨å†™ç¬¬ä¸€è¡Œç­–ç•¥ä»£ç ä¹‹å‰ï¼Œå…ˆèŠ± 80% çš„æ—¶é—´ç¡®ä¿æ•°æ®æ­£ç¡®ã€‚</strong></p>
</div>

<h2>ğŸ“– å‚è€ƒæ–‡çŒ® References</h2>

<div class="references">
<ul>
  <li>Ernest P. Chan, <em>Quantitative Trading</em>, Wiley, 2nd ed. â€” Chapter 2: "Finding and Assessing Data"</li>
  <li>Marcos LÃ³pez de Prado, <em>Advances in Financial Machine Learning</em>, Wiley â€” Chapter 2: "Financial Data Structures"</li>
  <li>Stefan Jansen, <em>Machine Learning for Algorithmic Trading</em>, 2nd ed. â€” Chapter 2: "Market & Fundamental Data"</li>
  <li>QuantStart, "Understanding Equities Data" â€” quantstart.com</li>
  <li>CRSP Data Documentation â€” crsp.org</li>
</ul>
</div>

<h2>ğŸ’­ æ€è€ƒé¢˜ Think About It</h2>

<div class="insight">
<p><strong>ğŸ¤” å¦‚æœä½ åœ¨å›æµ‹ä¸€ä¸ªåˆ†çº¢è‚¡ç­–ç•¥ï¼ˆæ¯”å¦‚ Dogs of the Dowï¼‰ï¼Œç”¨åŸå§‹æ”¶ç›˜ä»·å’Œè°ƒæ•´æ”¶ç›˜ä»·åˆ†åˆ«è®¡ç®—ï¼Œç»“æœå·®è·ä¼šæœ‰å¤šå¤§ï¼Ÿä¸ºä»€ä¹ˆè¿™ä¸ªå·®è·åœ¨é•¿æœŸå›æµ‹ä¸­ä¼šè¢«æ”¾å¤§ï¼Ÿ</strong></p>
<p><em>Hint: æƒ³æƒ³å¤åˆ©æ•ˆåº”ã€‚AAPL ä» 2015 åˆ° 2025 å¹´ç´¯è®¡åˆ†çº¢çº¦ $25/è‚¡ã€‚å¦‚æœå½“æ—¶è‚¡ä»· $30ï¼ˆæ‹†åˆ†å‰ï¼‰ï¼Œåˆ†çº¢å æ¯” >80%ã€‚å¿½ç•¥åˆ†çº¢æ„å‘³ç€å¿½ç•¥äº†å¤§éƒ¨åˆ†çœŸå®æ”¶ç›Šã€‚</em></p>
</div>

<p style="text-align: center; color: #888; margin-top: 40px;">ğŸ“š Knowledge Agent | Quantitative Trading Series Day 2 | 2026-02-17</p>

</body>
</html>