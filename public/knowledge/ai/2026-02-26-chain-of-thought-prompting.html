<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <title>2026-02-26 â€” Chain-of-Thought Prompting & Self-Consistency</title>
  <style>
    body { font-family: -apple-system, system-ui, sans-serif; max-width: 960px; margin: 0 auto; padding: 24px; line-height: 1.7; color: #2d2d2d; }
    h1 { color: #1a1a2e; border-bottom: 3px solid #f9ab00; padding-bottom: 10px; }
    h2 { color: #16213e; margin-top: 36px; }
    h3 { color: #0f3460; }
    .meta { color: #666; font-size: 0.9em; margin-bottom: 30px; }
    .bilingual { display: grid; grid-template-columns: 1fr 1fr; gap: 24px; margin: 20px 0; }
    .zh { border-left: 4px solid #f9ab00; padding-left: 16px; background: #fffdf0; border-radius: 0 8px 8px 0; padding: 12px 16px; }
    .en { border-left: 4px solid #1a73e8; padding-left: 16px; background: #f0f6ff; border-radius: 0 8px 8px 0; padding: 12px 16px; }
    .architecture { background: #f8f9fa; padding: 20px; border-radius: 10px; margin: 20px 0; border: 1px solid #e0e0e0; }
    pre { background: #1e1e1e; color: #d4d4d4; padding: 18px; border-radius: 10px; overflow-x: auto; font-size: 0.88em; line-height: 1.5; }
    code { font-family: 'JetBrains Mono', 'Fira Code', monospace; }
    .highlight { background: #fff3cd; padding: 14px 18px; border-radius: 8px; margin: 14px 0; border-left: 4px solid #f9ab00; }
    .highlight.blue { background: #e8f4fd; border-left-color: #1a73e8; }
    .highlight.green { background: #e8f5e9; border-left-color: #34a853; }
    .highlight.red { background: #fce8e6; border-left-color: #ea4335; }
    .diagram { background: #1e1e1e; color: #a8ff78; padding: 18px; border-radius: 10px; font-family: monospace; font-size: 0.9em; margin: 20px 0; white-space: pre; overflow-x: auto; }
    .interview { background: #1a1a2e; color: #e2e8f0; padding: 20px; border-radius: 10px; margin: 24px 0; }
    .interview h3 { color: #f9ab00; }
    .interview .q { color: #68d391; font-weight: bold; }
    .interview .a { color: #bee3f8; margin-left: 16px; margin-bottom: 12px; }
    .phase-badge { display: inline-block; background: #1a73e8; color: white; padding: 3px 10px; border-radius: 12px; font-size: 0.8em; margin-left: 8px; }
    .new-badge { display: inline-block; background: #34a853; color: white; padding: 3px 10px; border-radius: 12px; font-size: 0.8em; margin-left: 8px; }
    table { width: 100%; border-collapse: collapse; margin: 16px 0; }
    th { background: #1a1a2e; color: white; padding: 10px 14px; text-align: left; }
    td { padding: 10px 14px; border-bottom: 1px solid #e0e0e0; }
    tr:nth-child(even) { background: #f9f9f9; }
    .follow-up { margin-top: 36px; padding: 18px; border: 2px dashed #dadce0; border-radius: 10px; }
    .tip { background: #e8f5e9; border-left: 4px solid #34a853; padding: 12px 16px; border-radius: 0 8px 8px 0; margin: 12px 0; }
    .warning { background: #fce8e6; border-left: 4px solid #ea4335; padding: 12px 16px; border-radius: 0 8px 8px 0; margin: 12px 0; }
    .comparison { display: grid; grid-template-columns: 1fr 1fr; gap: 16px; margin: 16px 0; }
    .box { background: #f8f9fa; border-radius: 8px; padding: 14px; border: 1px solid #e0e0e0; }
    .box h4 { margin-top: 0; }
  </style>
</head>
<body>

<h1>ğŸ§  Chain-of-Thought Prompting & Self-Consistency
  <span class="new-badge">Phase 1.1 å¼€å§‹ï¼</span>
</h1>
<p class="meta">ğŸ“… 2026-02-26 Â· Prompt Engineering ç³»åˆ— Day 1 Â· <a href="#">æŸ¥çœ‹è¯¾ç¨‹è¿›åº¦</a></p>

<h2>ğŸ“– ä»Šæ—¥ä¸»é¢˜æ¦‚è§ˆ / Overview</h2>
<div class="bilingual">
  <div class="zh">
    <strong>ä½ æ˜¯å¦æƒ³è¿‡ï¼š</strong>ä¸ºä»€ä¹ˆ GPT-4 èƒ½è§£æ•°å­¦é¢˜ï¼Œä½† GPT-3.5 å´ç»å¸¸ç®—é”™ï¼Ÿç­”æ¡ˆä¸æ˜¯æ¨¡å‹å¤§å°ï¼Œè€Œæ˜¯<strong>æç¤ºè¯è®¾è®¡</strong>ã€‚

    <br><br>Chain-of-Thought (CoT) æ˜¯ 2022 å¹´ Google Brain æå‡ºçš„çªç ´æ€§æŠ€æœ¯ï¼šé€šè¿‡åœ¨ prompt ä¸­åŠ å…¥"æ¨ç†æ­¥éª¤"ï¼Œè®©æ¨¡å‹ä¸€æ­¥æ­¥æ€è€ƒï¼Œè€Œä¸æ˜¯ç›´æ¥è·³åˆ°ç­”æ¡ˆã€‚è¿™ä¸€æŠ€å·§å°†å¤æ‚æ¨ç†ä»»åŠ¡çš„å‡†ç¡®ç‡æå‡äº† <strong>40-60%</strong>ã€‚

    <br><br>ä»Šå¤©æˆ‘ä»¬æ·±å…¥å‰–æ CoT çš„åŸç†ã€å˜ä½“ã€ä»¥åŠå®é™…å·¥ç¨‹åº”ç”¨ã€‚
  </div>
  <div class="en">
    <strong>Have you wondered:</strong> why GPT-4 can solve math problems but GPT-3.5 often fails? The answer isn't just model size â€” it's <strong>prompt design</strong>.

    <br><br>Chain-of-Thought (CoT) was introduced by Google Brain in 2022: by adding "reasoning steps" to the prompt, the model thinks step-by-step instead of jumping to an answer. This technique improved complex reasoning accuracy by <strong>40-60%</strong>.

    <br><br>Today we'll deeply analyze CoT's principles, variants, and real engineering applications.
  </div>
</div>

<h2>ğŸ”¬ ä¸ºä»€ä¹ˆ LLM éœ€è¦"æ…¢æ€è€ƒ"ï¼Ÿ</h2>

<div class="highlight">
  <strong>æ ¸å¿ƒæ´å¯Ÿï¼š</strong>LLM ç”Ÿæˆ token æ—¶ï¼Œæ¯ä¸ª token çš„è®¡ç®—é‡æ˜¯å›ºå®šçš„ã€‚å¯¹äºéœ€è¦å¤šæ­¥æ¨ç†çš„é—®é¢˜ï¼Œ<strong>ä¸€æ­¥åˆ°ä½çš„ç­”æ¡ˆ</strong>æ„å‘³ç€æŠŠå¤æ‚æ¨ç†å‹ç¼©è¿›å•æ¬¡ forward passï¼Œå®¹æ˜“å‡ºé”™ã€‚CoT è®©æ¨¡å‹åœ¨ä¸­é—´ token ä¸Š"å¤–åŒ–"æ¨ç†è¿‡ç¨‹ï¼Œç›¸å½“äºç»™æ¨¡å‹æä¾›äº†"è‰ç¨¿çº¸"ã€‚
</div>

<div class="diagram">
Standard Prompt:
  User: "Roger has 5 tennis balls. He buys 2 more cans of 3 balls each. How many?"
  GPT:  "11"  âœ— (jumped to wrong answer)

Chain-of-Thought Prompt:
  User: "Roger has 5 tennis balls. He buys 2 cans of 3 balls each.
         Think step by step. How many tennis balls does he have now?"
  GPT:  "Roger starts with 5 balls.
         2 cans Ã— 3 balls/can = 6 new balls.
         5 + 6 = 11 balls total.
         Answer: 11" âœ“
</div>

<div class="bilingual">
  <div class="zh">
    <strong>ä¸ºä»€ä¹ˆ CoT æœ‰æ•ˆï¼Ÿ</strong>
    <ul>
      <li><strong>åˆ†è§£å¤æ‚åº¦</strong>ï¼šæŠŠ N æ­¥æ¨ç†é—®é¢˜æ‹†æˆ N ä¸ªç®€å•å­ä»»åŠ¡</li>
      <li><strong>æ³¨æ„åŠ›å¼•å¯¼</strong>ï¼šä¸­é—´æ­¥éª¤è®© attention èšç„¦åœ¨ç›¸å…³ä¿¡æ¯ä¸Š</li>
      <li><strong>å¯éªŒè¯æ€§</strong>ï¼šä¸­é—´æ­¥éª¤å¯ä»¥è¢«æ£€æµ‹å’Œçº é”™</li>
      <li><strong>æ¶Œç°èƒ½åŠ›</strong>ï¼šåœ¨ ~100B+ å‚æ•°æ¨¡å‹ä¸Šæ•ˆæœæœ€æ˜¾è‘—</li>
    </ul>
  </div>
  <div class="en">
    <strong>Why does CoT work?</strong>
    <ul>
      <li><strong>Decompose complexity</strong>: Break N-step reasoning into N simple subtasks</li>
      <li><strong>Attention guidance</strong>: Intermediate steps focus attention on relevant information</li>
      <li><strong>Verifiability</strong>: Intermediate steps can be detected and corrected</li>
      <li><strong>Emergent ability</strong>: Most effective on ~100B+ parameter models</li>
    </ul>
  </div>
</div>

<h2>ğŸ—‚ï¸ CoT çš„ä¸‰å¤§å˜ä½“</h2>

<h3>1. Few-Shot CoT (åŸå§‹è®ºæ–‡æ–¹æ¡ˆ)</h3>
<div class="highlight blue">
  åœ¨ prompt ä¸­æä¾› 3-8 ä¸ªå«æ¨ç†æ­¥éª¤çš„ç¤ºä¾‹ã€‚æ¨¡å‹å­¦ä¼šæ¨¡ä»¿æ¨ç†æ ¼å¼ã€‚é€‚åˆæœ‰ç¨³å®šæ¨ç†æ¨¡å¼çš„ä»»åŠ¡ã€‚
</div>

<pre><code class="language-python"># Few-Shot CoT Prompt
FEW_SHOT_COT = """
Solve each problem step by step.

Q: There are 15 trees. Loggers cut 5, then plant 3.
   How many trees are there?
A: Start: 15 trees.
   After cutting: 15 - 5 = 10 trees.
   After planting: 10 + 3 = 13 trees.
   Answer: 13

Q: Sara has 12 apples. She gives 4 to Tom and 2 to Jane.
   How many does she have left?
A: Sara starts with 12 apples.
   Gives 4 to Tom: 12 - 4 = 8 apples.
   Gives 2 to Jane: 8 - 2 = 6 apples.
   Answer: 6

Q: {user_question}
A:"""
</code></pre>

<h3>2. Zero-Shot CoT ("Let's think step by step")</h3>
<div class="highlight blue">
  2022å¹´ Tokyo Institute å‘ç°ï¼šä»…æ·»åŠ  <code>"Let's think step by step."</code> å°±èƒ½å¤§å¹…æå‡æ¨ç†å‡†ç¡®ç‡ã€‚æ— éœ€å‡†å¤‡ç¤ºä¾‹ï¼Œé€‚åˆå¿«é€Ÿéƒ¨ç½²ã€‚
</div>

<pre><code class="language-python">ZERO_SHOT_COT_TEMPLATES = {
    # ç»å…¸ç‰ˆ (Google Brain)
    "classic": "Let's think step by step.",
    
    # åˆ†è§£ç‰ˆï¼ˆæ›´ç»“æ„åŒ–ï¼‰
    "decompose": "Let's break this down step by step:",
    
    # é¢å‘ä»£ç /é€»è¾‘
    "logical": "Let's trace through the logic carefully:",
    
    # é¢å‘æ•°å­¦
    "math": "Let's solve this methodically, showing all calculations:",
    
    # Claude åå¥½ï¼ˆæ›´ XML ç»“æ„åŒ–ï¼‰
    "claude": """<thinking>
Let me work through this step by step.
</thinking>""",
    
    # å…³é”®æ­¥éª¤æç¤ºï¼ˆå‡å°‘å†—ä½™ï¼‰
    "concise": "Think through the key steps, then give a final answer:"
}

def zero_shot_cot(question: str, style: str = "classic") -> str:
    template = ZERO_SHOT_COT_TEMPLATES[style]
    return f"{question}\n\n{template}"
</code></pre>

<h3>3. Auto-CoTï¼ˆè‡ªåŠ¨ç”Ÿæˆç¤ºä¾‹ï¼‰</h3>
<div class="highlight blue">
  å½“æ²¡æœ‰äººå·¥æ ‡æ³¨çš„æ¨ç†ç¤ºä¾‹æ—¶ï¼Œç”¨ LLM è‡ªåŠ¨ç”Ÿæˆ CoT ç¤ºä¾‹ï¼Œç„¶åç”¨äº Few-Shot CoTã€‚è¿™æ˜¯ç”Ÿäº§ä¸­æœ€å®ç”¨çš„æ–¹æ¡ˆï¼
</div>

<pre><code class="language-typescript">// Auto-CoT Pipeline (TypeScript)
async function buildAutoCoT(
  taskDescription: string,
  sampleQuestions: string[],
  llm: LLMClient
): Promise<string> {
  
  // Step 1: è‡ªåŠ¨ç”Ÿæˆ CoT ç¤ºä¾‹
  const examples: string[] = [];
  
  for (const question of sampleQuestions.slice(0, 5)) {
    const cot = await llm.complete(`
      Question: ${question}
      
      Let's think step by step and provide a detailed solution:
    `);
    examples.push(`Q: ${question}\nA: ${cot}`);
  }
  
  // Step 2: ç»„è£… Few-Shot Prompt
  const fewShotPrompt = `
    ${taskDescription}
    
    Here are some examples with step-by-step reasoning:
    
    ${examples.join('\n\n---\n\n')}
    
    Now solve the following:
    Q: {question}
    A:
  `;
  
  return fewShotPrompt;
}
</code></pre>

<h2>âš¡ Self-Consistencyï¼šä»å•æ¬¡æ¨ç†åˆ°å¤šæ•°æŠ•ç¥¨</h2>

<div class="highlight red">
  <strong>CoT çš„é—®é¢˜ï¼š</strong>å•æ¬¡æ¨ç†æœ‰éšæœºæ€§ï¼ŒåŒä¸€ä¸ªé—®é¢˜é—®ä¸¤æ¬¡å¯èƒ½å¾—åˆ°ä¸åŒç­”æ¡ˆã€‚ç‰¹åˆ«æ˜¯åœ¨ temperature > 0 æ—¶ï¼Œä¸åŒæ¨ç†è·¯å¾„å¯èƒ½å¯¼å‘ä¸åŒç»“è®ºã€‚
</div>

<div class="diagram">
Self-Consistency = Chain-of-Thought Ã— Majority Voting

                    â”Œâ”€â”€ CoT Path 1 â†’ Answer: 42 â”€â”€â”
                    â”‚                              â”‚
Question â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CoT Path 2 â†’ Answer: 42 â”€â”€â”¼â”€â”€â–º Majority Vote â†’ 42 âœ“
(Sample N times)    â”‚                              â”‚
                    â””â”€â”€ CoT Path 3 â†’ Answer: 39 â”€â”€â”˜
                                                 (2/3 votes for 42)
</div>

<pre><code class="language-python">import asyncio
from collections import Counter
from typing import Any

async def self_consistency(
    question: str,
    llm,
    n_samples: int = 10,
    temperature: float = 0.7,
    extract_answer_fn=None
) -> dict:
    """
    Self-Consistency: é‡‡æ ·å¤šæ¡ CoT æ¨ç†è·¯å¾„ï¼Œå–å¤šæ•°ç»“æœ
    
    Args:
        n_samples: é‡‡æ ·æ¬¡æ•°ï¼Œä¸€èˆ¬ 5-20 æ¬¡
        temperature: æ¸©åº¦è¶Šé«˜ï¼Œè·¯å¾„è¶Šå¤šæ ·
        extract_answer_fn: ä» CoT æ–‡æœ¬ä¸­æå–æœ€ç»ˆç­”æ¡ˆ
    """
    
    # å¹¶å‘é‡‡æ · N æ¡æ¨ç†è·¯å¾„
    tasks = [
        llm.complete(
            f"{question}\n\nLet's think step by step:",
            temperature=temperature
        )
        for _ in range(n_samples)
    ]
    
    cot_responses = await asyncio.gather(*tasks)
    
    # æå–ç­”æ¡ˆï¼ˆé»˜è®¤å–æœ€åä¸€è¡Œï¼‰
    if extract_answer_fn is None:
        extract_answer_fn = lambda r: r.strip().split('\n')[-1]
    
    answers = [extract_answer_fn(r) for r in cot_responses]
    
    # å¤šæ•°æŠ•ç¥¨
    vote_counts = Counter(answers)
    winner, count = vote_counts.most_common(1)[0]
    confidence = count / n_samples
    
    return {
        "answer": winner,
        "confidence": confidence,         # 0.0 ~ 1.0
        "vote_distribution": dict(vote_counts),
        "reasoning_paths": cot_responses  # å¯ç”¨äº debug
    }

# ä½¿ç”¨ç¤ºä¾‹
result = await self_consistency(
    question="A bat and a ball cost $1.10. The bat costs $1 more than the ball. How much does the ball cost?",
    llm=my_llm,
    n_samples=10
)
# â†’ {"answer": "$0.05", "confidence": 0.8, ...}
</code></pre>

<div class="comparison">
  <div class="box">
    <h4>ğŸ“Š æ•ˆæœæå‡</h4>
    <ul>
      <li>GSM8K (å°å­¦æ•°å­¦): <strong>+17.9%</strong></li>
      <li>SVAMP (å¤æ‚æ•°å­¦): <strong>+11.0%</strong></li>
      <li>StrategyQA (ç­–ç•¥æ¨ç†): <strong>+6.4%</strong></li>
      <li>AQuA (ä»£æ•°): <strong>+12.2%</strong></li>
    </ul>
    <small>æ¥æº: Wang et al., 2023</small>
  </div>
  <div class="box">
    <h4>ğŸ’° æˆæœ¬æƒè¡¡</h4>
    <ul>
      <li>æˆæœ¬ = å•æ¬¡ Ã— N å€</li>
      <li>N=5: è¾ƒå¥½çš„å‡†ç¡®ç‡æå‡</li>
      <li>N=10: è¾¹é™…æ”¶ç›Šé€’å‡</li>
      <li>N=20+: æå°‘è§é¢å¤–æå‡</li>
      <li><strong>å»ºè®®</strong>: é«˜é£é™©å†³ç­–ç”¨ N=10ï¼Œä¸€èˆ¬åœºæ™¯ç”¨ N=5</li>
    </ul>
  </div>
</div>

<h2>ğŸ—ï¸ ç”Ÿäº§çº§ CoT æ¶æ„è®¾è®¡</h2>

<div class="architecture">
<pre>
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚        CoT Prompt Router        â”‚
                        â”‚                                 â”‚
  User Query â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  åˆ†ç±»ï¼šæ˜¯å¦éœ€è¦ CoT?             â”‚
                        â”‚  â€¢ ç®€å•é—®ç­”: Direct Answer       â”‚
                        â”‚  â€¢ å¤šæ­¥æ¨ç†: CoT                 â”‚
                        â”‚  â€¢ é«˜é£é™©å†³ç­–: Self-Consistency  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â–¼               â–¼               â–¼
            Direct Answer        CoT         Self-Consistency
                                              (N=5-10)
                   â”‚               â”‚               â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  Answer Extractor   â”‚
                        â”‚  + Confidence Score â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â–¼
                           Final Answer + 
                         Reasoning Trace
</pre>
</div>

<pre><code class="language-typescript">// ç”Ÿäº§çº§ CoT Router (TypeScript)
type ReasoningStrategy = 'direct' | 'cot' | 'self-consistency';

interface CoTConfig {
  strategy: ReasoningStrategy;
  nSamples?: number;   // for self-consistency
  temperature?: number;
  extractAnswer?: (response: string) => string;
}

function selectStrategy(query: string, context: {
  isHighStakes: boolean;
  queryType: 'factual' | 'reasoning' | 'calculation' | 'creative';
  latencyBudgetMs: number;
}): CoTConfig {
  
  // ç®€å•äº‹å®æŸ¥è¯¢ â†’ ç›´æ¥å›ç­”
  if (context.queryType === 'factual' && !context.isHighStakes) {
    return { strategy: 'direct' };
  }
  
  // é«˜é£é™© + æ¨ç† â†’ Self-Consistency
  if (context.isHighStakes && context.queryType !== 'creative') {
    return {
      strategy: 'self-consistency',
      nSamples: context.latencyBudgetMs > 5000 ? 10 : 5,
      temperature: 0.7
    };
  }
  
  // ä¸€èˆ¬æ¨ç†/è®¡ç®— â†’ Standard CoT
  return { strategy: 'cot', temperature: 0.3 };
}

async function reasonWithCot(
  query: string,
  config: CoTConfig,
  llm: LLMClient
): Promise<{ answer: string; reasoning: string; confidence: number }> {
  
  if (config.strategy === 'direct') {
    const response = await llm.complete(query);
    return { answer: response, reasoning: '', confidence: 1.0 };
  }
  
  const cotPrompt = `${query}

Let's think step by step:`;
  
  if (config.strategy === 'cot') {
    const response = await llm.complete(cotPrompt, { temperature: config.temperature });
    const answer = extractFinalAnswer(response);
    return { answer, reasoning: response, confidence: 0.85 };
  }
  
  // Self-Consistency
  const result = await selfConsistency(cotPrompt, llm, config.nSamples!);
  return {
    answer: result.answer,
    reasoning: result.reasoningPaths[0],  // å–ç¬¬ä¸€æ¡ä»£è¡¨è·¯å¾„
    confidence: result.confidence
  };
}
</code></pre>

<h2>âœ¨ è®¾è®¡äº®ç‚¹ / Design Highlights</h2>

<div class="highlight green">
  <h4>äº®ç‚¹ 1: CoT ä¸æ˜¯å…è´¹çš„åˆé¤</h4>
  <p>CoT å¯¹ <strong>é€»è¾‘æ¨ç†ã€æ•°å­¦ã€ä»£ç </strong> æ•ˆæœæ˜¾è‘—ï¼Œä½†å¯¹ <strong>ç®€å•äº‹å®æŸ¥è¯¢ã€åˆ›æ„å†™ä½œã€æƒ…æ„Ÿåˆ†æ</strong> åè€Œå¯èƒ½æœ‰æŸå‡†ç¡®ç‡ï¼ˆæ¨¡å‹è¿‡åº¦æ¨ç†ï¼Œç»•è·¯èµ°ï¼‰ã€‚ç”Ÿäº§ä¸­ä¸€å®šè¦åš<strong>åˆ†ç±»è·¯ç”±</strong>ï¼</p>
</div>

<div class="highlight green">
  <h4>äº®ç‚¹ 2: XML ç»“æ„åŒ–æ€è€ƒï¼ˆClaude æœ€ä½³å®è·µï¼‰</h4>
  <p>å¯¹äº Claudeï¼Œç”¨ <code>&lt;thinking&gt;</code> æ ‡ç­¾æ¯”è‡ªç„¶è¯­è¨€ CoT æ›´ç¨³å®šã€‚Claude 3.5 Sonnet åŠä»¥ä¸Šç‰ˆæœ¬åŸç”Ÿæ”¯æŒæ‰©å±•æ€è€ƒï¼ˆExtended Thinkingï¼‰ï¼Œç›´æ¥å¼€å¯æ¯”æ‰‹åŠ¨ CoT æ•ˆæœæ›´å¥½ã€‚</p>
</div>

<div class="highlight green">
  <h4>äº®ç‚¹ 3: ç½®ä¿¡åº¦ä¿¡å·</h4>
  <p>Self-Consistency çš„æŠ•ç¥¨åˆ†å¸ƒæœ¬èº«å°±æ˜¯ç½®ä¿¡åº¦æŒ‡æ ‡ã€‚è‹¥ 10 æ¬¡é‡‡æ ·ä¸­åªæœ‰ 5 ç¥¨æ”¯æŒæœ€é«˜ç­”æ¡ˆï¼Œè¯´æ˜é—®é¢˜æœ¬èº«å«ç³Šï¼Œåº”å½“æ¾„æ¸…é—®é¢˜è€Œéå¼ºè¡Œè¾“å‡ºç­”æ¡ˆã€‚</p>
</div>

<div class="warning">
  <h4>âš ï¸ å¸¸è§é™·é˜±ï¼šSycophancyï¼ˆè®¨å¥½æ€§é”™è¯¯ï¼‰</h4>
  <p>å¦‚æœ prompt ä¸­æš—ç¤ºäº†ç­”æ¡ˆæ–¹å‘ï¼ˆ"å¾ˆå¤šäººè®¤ä¸ºç­”æ¡ˆæ˜¯ Xï¼Œä½ æ€ä¹ˆçœ‹ï¼Ÿ"ï¼‰ï¼ŒCoT ä»ç„¶å¯èƒ½é¡ºç€èµ°ã€‚<strong>è§£å†³æ–¹æ¡ˆ</strong>ï¼šåœ¨ system prompt ä¸­æ˜ç¡®è¦æ±‚"ä¸è¦è¢«é—®é¢˜ä¸­çš„æš—ç¤ºå½±å“"ã€‚</p>
</div>

<h2>ğŸ“ è¿›é˜¶å˜ä½“ï¼šTree of Thoughts é¢„è§ˆ</h2>

<div class="bilingual">
  <div class="zh">
    CoT æ˜¯ä¸€æ¡çº¿æ€§æ¨ç†è·¯å¾„ã€‚2023 å¹´ Princeton/Google æå‡º <strong>Tree of Thoughts (ToT)</strong>ï¼šè®©æ¨¡å‹æ¢ç´¢å¤šæ¡åˆ†æ”¯è·¯å¾„ï¼Œå¹¶ç”¨ BFS/DFS æœç´¢æœ€ä¼˜è·¯å¾„ã€‚

    <br><br>é€‚åˆï¼šæ•°å­¦è¯æ˜ã€ç­–ç•¥è§„åˆ’ã€å¤æ‚é—®é¢˜åˆ†è§£ã€‚æˆæœ¬é«˜ï¼ˆNå€é‡‡æ · Ã— æ·±åº¦ï¼‰ï¼Œä¸€èˆ¬åªç”¨äºé«˜ä»·å€¼ä»»åŠ¡ã€‚
  </div>
  <div class="en">
    CoT is linear reasoning. In 2023, Princeton/Google proposed <strong>Tree of Thoughts (ToT)</strong>: letting the model explore multiple branching paths and using BFS/DFS to find the best one.

    <br><br>Best for: math proofs, strategic planning, complex problem decomposition. High cost (N-samples Ã— depth), usually only for high-value tasks.
  </div>
</div>

<div class="diagram">
Chain-of-Thought:         Tree of Thoughts:

Q â†’ Step1 â†’ Step2 â†’ A    Q â†’ Branch A â†’ A1 â†’ A2 â†’ âœ“ Answer
                             Branch B â†’ B1 â†’ âœ— Dead end
                             Branch C â†’ C1 â†’ C2 â†’ C3 â†’ (explore)
                          
                          è¯„ä¼°å™¨ (Evaluator) å‰ªææ— æœ›åˆ†æ”¯
</div>

<h2>ğŸ’» Claude Extended Thinkingï¼šåŸç”Ÿ CoT</h2>

<pre><code class="language-python">import anthropic

client = anthropic.Anthropic()

# Claude 3.7 Sonnet: åŸç”Ÿæ‰©å±•æ€è€ƒ
response = client.messages.create(
    model="claude-3-7-sonnet-20250219",
    max_tokens=16000,
    thinking={
        "type": "enabled",
        "budget_tokens": 10000  # æ§åˆ¶æ€è€ƒæ·±åº¦ (1024 ~ 100K+)
    },
    messages=[{
        "role": "user",
        "content": """
        A company has 3 factories. Factory A produces 200 units/day at $5/unit cost.
        Factory B produces 150 units/day at $4/unit cost.  
        Factory C produces 180 units/day at $6/unit cost.
        
        Demand is 400 units/day. What's the optimal production allocation
        to minimize cost while meeting demand?
        """
    }]
)

# è¾“å‡ºåŒ…å« thinking block + text block
for block in response.content:
    if block.type == "thinking":
        print(f"Reasoning: {block.thinking[:200]}...")  # å†…éƒ¨æ¨ç†
    elif block.type == "text":
        print(f"Answer: {block.text}")  # æœ€ç»ˆç­”æ¡ˆ
</code></pre>

<div class="tip">
  <strong>ğŸ“Œ å®è·µå»ºè®®ï¼š</strong>budget_tokens è®¾ç½®ï¼šç®€å•æ¨ç† 1K-4Kï¼Œå¤æ‚é—®é¢˜ 8K-32Kï¼Œæ•°å­¦/ä»£ç  32K+ã€‚é¢„ç®—æœªç”¨å®Œæ—¶æ¨¡å‹ä¼šæå‰åœæ­¢ï¼Œä¸ä¼šæµªè´¹ã€‚
</div>

<h2>ğŸ“Š æŠ€æœ¯å¯¹æ¯”è¡¨</h2>

<table>
  <tr>
    <th>æ–¹æ³•</th>
    <th>é€‚ç”¨åœºæ™¯</th>
    <th>æˆæœ¬</th>
    <th>å‡†ç¡®ç‡</th>
    <th>å»¶è¿Ÿ</th>
  </tr>
  <tr>
    <td>Direct</td>
    <td>ç®€å•äº‹å®ã€åˆ›æ„</td>
    <td>1x</td>
    <td>åŸºå‡†</td>
    <td>æœ€ä½</td>
  </tr>
  <tr>
    <td>Zero-Shot CoT</td>
    <td>ä¸­ç­‰æ¨ç†</td>
    <td>1.5-2x (æ›´å¤š tokens)</td>
    <td>+15-30%</td>
    <td>ä½</td>
  </tr>
  <tr>
    <td>Few-Shot CoT</td>
    <td>å›ºå®šæ¨ç†æ¨¡å¼</td>
    <td>2-3x</td>
    <td>+20-40%</td>
    <td>ä¸­</td>
  </tr>
  <tr>
    <td>Self-Consistency (N=5)</td>
    <td>é«˜å‡†ç¡®ç‡éœ€æ±‚</td>
    <td>5x</td>
    <td>+30-50%</td>
    <td>é«˜</td>
  </tr>
  <tr>
    <td>Extended Thinking</td>
    <td>å¤æ‚æ¨ç†/æ•°å­¦</td>
    <td>3-10x</td>
    <td>æœ€é«˜</td>
    <td>é«˜</td>
  </tr>
  <tr>
    <td>Tree of Thoughts</td>
    <td>æœç´¢å‹é—®é¢˜</td>
    <td>10-50x</td>
    <td>æœ€é«˜+</td>
    <td>æœ€é«˜</td>
  </tr>
</table>

<h2>ğŸ“š å¯å­¦ä¹ çš„ Patterns</h2>

<div class="highlight">
  <h4>Pattern 1: æ¨ç†-ç­”æ¡ˆåˆ†ç¦»</h4>
  <p>è®©æ¨¡å‹å…ˆè¾“å‡ºå®Œæ•´æ¨ç†è¿‡ç¨‹ï¼Œå†è¾“å‡ºç»“æ„åŒ–ç­”æ¡ˆã€‚åœ¨ä»£ç ä¸­è§£æç­”æ¡ˆæ—¶æ›´ç¨³å®šï¼š</p>
  <pre><code>prompt += "\n\nProvide your reasoning, then end with:\nFINAL_ANSWER: [your answer]"</code></pre>
</div>

<div class="highlight">
  <h4>Pattern 2: éªŒè¯æ­¥éª¤ï¼ˆåå‘æ£€æŸ¥ï¼‰</h4>
  <p>åœ¨ CoT æœ«å°¾åŠ å…¥ï¼š"Now verify your answer by checking each step." è®©æ¨¡å‹è‡ªæˆ‘æ ¸æŸ¥ï¼Œç±»ä¼¼äººåšæ•°å­¦é¢˜åéªŒç®—ã€‚</p>
</div>

<div class="highlight">
  <h4>Pattern 3: ç½®ä¿¡åº¦å£°æ˜</h4>
  <p>è¦æ±‚æ¨¡å‹åœ¨ç­”æ¡ˆåå£°æ˜ç½®ä¿¡åº¦ï¼š"On a scale of 1-10, how confident are you?" å¯ä»¥ä½œä¸ºæ˜¯å¦è§¦å‘ Self-Consistency çš„å†³ç­–ä¿¡å·ã€‚</p>
</div>

<div class="highlight">
  <h4>Pattern 4: ç»“æ„åŒ– CoTï¼ˆé¢å‘è§£æï¼‰</h4>
  <pre><code>Think through this problem using this structure:
GIVEN: [list what we know]
FIND: [what we need]
STEPS:
  1. [first step]
  2. [second step]
  ...
ANSWER: [final answer]
CHECK: [verify the answer makes sense]</code></pre>
</div>

<div class="interview">
  <h3>ğŸ¯ é¢è¯•é«˜é¢‘é—®é¢˜</h3>
  
  <div class="q">Q1: ä»€ä¹ˆæ—¶å€™ç”¨ CoTï¼Œä»€ä¹ˆæ—¶å€™ä¸ç”¨ï¼Ÿ</div>
  <div class="a">
    ç”¨ CoTï¼šå¤šæ­¥æ¨ç†ã€æ•°å­¦è®¡ç®—ã€é€»è¾‘åˆ¤æ–­ã€ä»£ç è°ƒè¯•ã€‚ä¸ç”¨ CoTï¼šç®€å•äº‹å®æŸ¥è¯¢ã€åˆ›æ„å†™ä½œã€åˆ†ç±»ä»»åŠ¡ï¼ˆå¯èƒ½è¿‡åº¦æ¨ç†åè€Œå‡ºé”™ï¼‰ã€‚
    å…³é”®åŸåˆ™ï¼š<strong>ä»»åŠ¡éœ€è¦ä¸­é—´æ­¥éª¤æ—¶ç”¨ CoTï¼Œä¸­é—´æ­¥éª¤åè€Œæ·»ä¹±æ—¶ä¸ç”¨</strong>ã€‚
  </div>
  
  <div class="q">Q2: Self-Consistency çš„æˆæœ¬å¤ªé«˜ï¼Œå¦‚ä½•ä¼˜åŒ–ï¼Ÿ</div>
  <div class="a">
    ä¸‰ä¸ªä¼˜åŒ–æ–¹å‘ï¼šâ‘  <strong>å°æ¨¡å‹é‡‡æ ·ï¼Œå¤§æ¨¡å‹éªŒè¯</strong>ï¼šç”¨ GPT-3.5 é‡‡æ · N æ¡è·¯å¾„ï¼Œç”¨ GPT-4 åˆ¤æ–­æœ€ä¼˜è·¯å¾„ï¼ˆæ¯”ç›´æ¥ GPT-4 Ã— N ä¾¿å®œï¼‰ï¼›
    â‘¡ <strong>æ—©åœ</strong>ï¼šè‹¥å‰ 3 æ¬¡å…¨éƒ¨ä¸€è‡´ï¼Œåœæ­¢é‡‡æ ·ï¼ˆæ— éœ€ 10 æ¬¡ï¼‰ï¼›
    â‘¢ <strong>ç¼“å­˜</strong>ï¼šç›¸ä¼¼é—®é¢˜çš„ CoT æ¨ç†è·¯å¾„å¯ä»¥å¤ç”¨ï¼ˆSemantic Cacheï¼‰ã€‚
  </div>
  
  <div class="q">Q3: å¦‚ä½•è¯„ä¼° CoT Prompt çš„è´¨é‡ï¼Ÿ</div>
  <div class="a">
    å»ºç«‹è¯„æµ‹é›†ï¼ˆGround Truth ç­”æ¡ˆï¼‰â†’ å¯¹æ¯” Direct vs CoT å‡†ç¡®ç‡ã€‚
    é™¤å‡†ç¡®ç‡å¤–ï¼Œçœ‹ï¼šâ‘  æ¨ç†ä¸€è‡´æ€§ï¼ˆ10 æ¬¡é‡‡æ ·çš„ agreement rateï¼‰ï¼›â‘¡ æ¨ç†æ­£ç¡®ä½†ç­”æ¡ˆé”™è¯¯çš„æ¯”ä¾‹ï¼ˆä¸­é—´æ­¥éª¤ grounding é—®é¢˜ï¼‰ï¼›
    â‘¢ Faithfulnessï¼ˆæœ€ç»ˆç­”æ¡ˆæ˜¯å¦çœŸçš„æ¥è‡ªæ¨ç†ï¼Œè€Œéæ¨ç†æ˜¯äº‹ååˆç†åŒ–ï¼‰ã€‚
  </div>
  
  <div class="q">Q4: å¦‚ä½•è®© CoT è¾“å‡ºæ›´é€‚åˆè§£æï¼ˆç»“æ„åŒ–è¾“å‡ºï¼‰ï¼Ÿ</div>
  <div class="a">
    ä¸¤ç§æ–¹æ¡ˆï¼šâ‘  <strong>ç»“æ„åŒ– CoT</strong>ï¼šåœ¨ prompt ä¸­æ˜ç¡®æ ¼å¼ï¼ˆGIVEN/STEPS/ANSWERï¼‰ï¼Œç„¶åç”¨æ­£åˆ™æˆ– LLM æå–ï¼›
    â‘¡ <strong>Two-step</strong>ï¼šStep 1 ç”¨é«˜æ¸©åº¦åš CoT æ¨ç†ï¼ˆè‡ªç”±æ ¼å¼ï¼‰ï¼ŒStep 2 ç”¨ä½æ¸©åº¦æå–ç»“æ„åŒ–ç­”æ¡ˆï¼ˆ"Based on your reasoning, output JSON: {...}"ï¼‰ã€‚
    é¿å…åœ¨ CoT æ¨ç†ä¸­è¦æ±‚ JSONï¼Œè¿™ä¼šå¹²æ‰°æ¨ç†è´¨é‡ã€‚
  </div>
</div>

<h2>ğŸ’¡ ä»Šæ—¥æ€è€ƒé¢˜</h2>

<div class="highlight" style="background: #e8f5e9; border-left-color: #34a853;">
  <strong>ä½ åœ¨ OpenClaw ä¸Šæ„å»ºäº† Agent ç³»ç»Ÿã€‚</strong>
  
  <br><br>é—®é¢˜ï¼šä½ çš„ Agent éœ€è¦åšä¸€ä¸ªå†³ç­–ï¼š"ç”¨æˆ·è¯´'æŠŠæ–‡ä»¶ç§»åˆ°å¤‡ä»½'ï¼Œåº”è¯¥ mv è¿˜æ˜¯ cpï¼Ÿ" è¿™æ˜¯ä¸€ä¸ªæœ‰é£é™©çš„æ“ä½œã€‚
  
  <br><br>ä½ ä¼šå¦‚ä½•è®¾è®¡è¿™ä¸ª Agent çš„æ¨ç†æ¨¡å—ï¼Ÿ
  <ul>
    <li>ç”¨ Directã€CoTã€è¿˜æ˜¯ Self-Consistencyï¼Ÿ</li>
    <li>å¦‚æœé€‰ CoTï¼Œæ¨ç†æ­¥éª¤åº”è¯¥åŒ…å«ä»€ä¹ˆï¼Ÿ</li>
    <li>å¦‚ä½•å†³å®š"ç½®ä¿¡åº¦å¤Ÿäº†"å†æ‰§è¡Œï¼Ÿ</li>
  </ul>
  
  <em>æç¤ºï¼šè€ƒè™‘æ“ä½œå¯é€†æ€§ã€ç”¨æˆ·æ„å›¾æ¨¡ç³Šæ€§ã€ä»¥åŠ Human-in-the-Loop çš„è§¦å‘æ¡ä»¶ã€‚</em>
</div>

<div class="follow-up">
  <h3>ğŸ’¬ åç»­è®¨è®º / Follow-up Discussion</h3>
  <p>æ˜å¤©ï¼š<strong>Few-Shot vs Zero-Shot æœ€ä½³å®è·µ</strong> â€”â€” ä»€ä¹ˆæ—¶å€™å†™ç¤ºä¾‹å€¼å¾—ï¼Œç¤ºä¾‹è´¨é‡ vs æ•°é‡çš„æƒè¡¡ï¼ŒåŠ¨æ€ç¤ºä¾‹é€‰æ‹©ï¼ˆRAG + CoTï¼‰ã€‚</p>
  <p>æœ‰é—®é¢˜éšæ—¶é—®ï¼</p>
</div>

</body>
</html>
