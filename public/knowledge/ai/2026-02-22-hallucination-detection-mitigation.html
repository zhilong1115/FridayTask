<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>2026-02-22 - LLM Hallucination æ£€æµ‹ä¸å¤„ç†</title>
  <style>
    body { font-family: -apple-system, system-ui, sans-serif; max-width: 900px; margin: 0 auto; padding: 20px; line-height: 1.7; color: #2d2d2d; }
    .bilingual { display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin: 15px 0; }
    .zh { border-left: 3px solid #f9ab00; padding-left: 15px; }
    .en { border-left: 3px solid #1a73e8; padding-left: 15px; }
    h1 { color: #3c4043; border-bottom: 2px solid #e8eaed; padding-bottom: 10px; }
    h2 { color: #1a73e8; margin-top: 35px; }
    h3 { color: #5f6368; }
    .architecture { background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 20px 0; }
    pre { background: #1e1e1e; color: #d4d4d4; padding: 15px; border-radius: 8px; overflow-x: auto; font-size: 13px; }
    code { font-family: 'SF Mono', Consolas, monospace; }
    .highlight { background: #fff3cd; padding: 12px 15px; border-radius: 8px; margin: 12px 0; }
    .highlight-blue { background: #d1ecf1; padding: 12px 15px; border-radius: 8px; margin: 12px 0; }
    .highlight-green { background: #d4edda; padding: 12px 15px; border-radius: 8px; margin: 12px 0; }
    .highlight-red { background: #f8d7da; padding: 12px 15px; border-radius: 8px; margin: 12px 0; }
    .diagram { background: #f8f9fa; padding: 20px; border-radius: 8px; margin: 20px 0; font-family: 'SF Mono', Consolas, monospace; font-size: 13px; white-space: pre; overflow-x: auto; line-height: 1.4; }
    .series-nav { background: #e8f0fe; padding: 15px; border-radius: 8px; margin: 20px 0; }
    .interview { background: #fce8e6; padding: 15px; border-radius: 8px; margin: 15px 0; }
    .interview h4 { color: #c5221f; margin-top: 0; }
    table { border-collapse: collapse; width: 100%; margin: 15px 0; }
    th, td { border: 1px solid #dadce0; padding: 10px 12px; text-align: left; }
    th { background: #f8f9fa; font-weight: 600; }
    .tag { display: inline-block; padding: 2px 8px; border-radius: 12px; font-size: 12px; margin: 2px; }
    .tag-detect { background: #e8f0fe; color: #1a73e8; }
    .tag-prevent { background: #d4edda; color: #155724; }
    .tag-fix { background: #fff3cd; color: #856404; }
    .follow-up { margin-top: 30px; padding: 15px; border: 1px dashed #dadce0; border-radius: 8px; }
  </style>
</head>
<body>

  <div class="series-nav">
    <strong>ğŸ“š LLM ç‰¹æœ‰é—®é¢˜ç³»åˆ— | Phase 2.3 Day 3 of 5</strong><br>
    <span style="color:#5f6368">
      <a href="2026-02-20-token-limit-handling-strategies.html">Day 1: Token é™åˆ¶å¤„ç†</a> â†’
      <a href="2026-02-21-llm-cost-optimization.html">Day 2: æˆæœ¬ä¼˜åŒ–</a> â†’
      <strong>Day 3: Hallucination æ£€æµ‹ä¸å¤„ç† (ä»Šå¤©)</strong> â†’
      Day 4: æµå¼è¾“å‡ºæ¶æ„ â†’
      Day 5: Multi-turn å¯¹è¯çŠ¶æ€ç®¡ç†
    </span>
  </div>

  <h1>ğŸ” LLM Hallucination æ£€æµ‹ä¸å¤„ç†</h1>
  <p>LLM Hallucination Detection & Mitigation â€” ä»åˆ†ç±»åˆ°æ£€æµ‹åˆ°é˜²å¾¡çš„å®Œæ•´å·¥ç¨‹æ–¹æ¡ˆ</p>

  <h2>ğŸ“– ä¸ºä»€ä¹ˆ Hallucination æ˜¯ LLM æœ€æ ¸å¿ƒçš„é—®é¢˜</h2>
  <div class="bilingual">
    <div class="zh">
      <p>Hallucinationï¼ˆå¹»è§‰ï¼‰æ˜¯ LLM ç”Ÿæˆçœ‹ä¼¼åˆç†ä½†å®é™…é”™è¯¯çš„å†…å®¹ã€‚è¿™ä¸æ˜¯ bugï¼Œè€Œæ˜¯è‡ªå›å½’è¯­è¨€æ¨¡å‹çš„æœ¬è´¨ç‰¹æ€§â€”â€”æ¨¡å‹åœ¨åš"æœ€å¯èƒ½çš„ä¸‹ä¸€ä¸ª token"é¢„æµ‹ï¼Œè€Œä¸æ˜¯"æœ€æ­£ç¡®çš„ä¸‹ä¸€ä¸ª token"ã€‚</p>
      <p>2025 å¹´çš„ç ”ç©¶æ˜¾ç¤ºï¼Œå³ä½¿æ˜¯ GPT-4o åœ¨åŒ»ç–—é—®ç­”ä¸­çš„å¹»è§‰ç‡ä¹Ÿé«˜è¾¾ 53%ï¼Œé€šè¿‡ prompt ä¼˜åŒ–å¯é™è‡³ 23%ï¼Œä½†æ— æ³•æ ¹é™¤ã€‚å› æ­¤ï¼Œ<strong>å·¥ç¨‹åŒ–çš„æ£€æµ‹å’Œé˜²å¾¡ä½“ç³»</strong>æ˜¯ç”Ÿäº§ç³»ç»Ÿçš„å¿…å¤‡ç»„ä»¶ã€‚</p>
    </div>
    <div class="en">
      <p>Hallucination is when LLMs generate plausible-sounding but factually incorrect content. It's not a bugâ€”it's an inherent property of autoregressive models that predict "most likely next token," not "most correct next token."</p>
      <p>A 2025 study showed GPT-4o's hallucination rate in medical QA was 53%, reducible to 23% with prompt engineering but never zero. This makes <strong>engineering-grade detection and defense systems</strong> essential for production.</p>
    </div>
  </div>

  <h2>ğŸ—‚ï¸ Hallucination åˆ†ç±»ä½“ç³»</h2>

  <div class="bilingual">
    <div class="zh">
      <p>ç†è§£åˆ†ç±»æ˜¯è®¾è®¡æ£€æµ‹ç³»ç»Ÿçš„åŸºç¡€ã€‚æ¯ç§ç±»å‹éœ€è¦ä¸åŒçš„æ£€æµ‹ç­–ç•¥ã€‚</p>
    </div>
    <div class="en">
      <p>Understanding the taxonomy is foundational for designing detection systems. Each type requires a different detection strategy.</p>
    </div>
  </div>

  <table>
    <tr>
      <th>ç±»å‹</th>
      <th>å®šä¹‰</th>
      <th>ä¾‹å­</th>
      <th>æ£€æµ‹éš¾åº¦</th>
    </tr>
    <tr>
      <td><strong>Intrinsic (å†…åœ¨)</strong></td>
      <td>ä¸æä¾›çš„ context çŸ›ç›¾</td>
      <td>æ–‡æ¡£è¯´ Q1 è¥æ”¶ $5Mï¼Œæ¨¡å‹è¯´ $8M</td>
      <td>â­â­ ä¸­ç­‰ â€” å¯ç”¨ NLI</td>
    </tr>
    <tr>
      <td><strong>Extrinsic (å¤–åœ¨)</strong></td>
      <td>context ä¸­æ— æ³•éªŒè¯çš„æ–°ä¿¡æ¯</td>
      <td>æ¨¡å‹ç¼–é€ äº†ä¸€ä¸ªä¸å­˜åœ¨çš„ API å‚æ•°</td>
      <td>â­â­â­ å›°éš¾</td>
    </tr>
    <tr>
      <td><strong>Factual (äº‹å®)</strong></td>
      <td>ä¸ä¸–ç•ŒçŸ¥è¯†çŸ›ç›¾</td>
      <td>"Python å‘å¸ƒäº 1995 å¹´" (å®é™… 1991)</td>
      <td>â­â­â­ éœ€è¦çŸ¥è¯†åº“</td>
    </tr>
    <tr>
      <td><strong>Faithfulness (å¿ å®åº¦)</strong></td>
      <td>ä¸å¿ äºè¾“å…¥/æŒ‡ä»¤</td>
      <td>è®©æ€»ç»“3ç‚¹ï¼Œç”Ÿæˆäº†5ç‚¹ä¸”åŠ äº†æ–°å†…å®¹</td>
      <td>â­â­ å¯æ¯”å¯¹</td>
    </tr>
  </table>

  <div class="highlight">
    <strong>ğŸ’¡ é¢è¯•é‡ç‚¹ï¼š</strong>é¢è¯•å®˜æœ€å…³å¿ƒ <strong>Faithfulness hallucination</strong>ï¼ˆRAG åœºæ™¯ï¼‰å’Œ <strong>Factual hallucination</strong>ï¼ˆå¼€æ”¾é—®ç­”åœºæ™¯ï¼‰ï¼Œå› ä¸ºè¿™ä¸¤ç§æœ€ç›´æ¥å½±å“ç”¨æˆ·ä¿¡ä»»ã€‚
  </div>

  <h2>ğŸ—ï¸ å…­å¤§æ£€æµ‹æ–¹æ³•ï¼šä»è½»é‡åˆ°é‡é‡</h2>

  <div class="diagram">
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Hallucination Detection Spectrum                â”‚
â”‚                                                             â”‚
â”‚  Light â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Heavy         â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚Logit â”‚  â”‚Self  â”‚  â”‚  NLI   â”‚  â”‚LLM-as â”‚  â”‚Knowledge â”‚  â”‚
â”‚  â”‚Probe â”‚  â”‚Consisâ”‚  â”‚Entail  â”‚  â”‚-Judge â”‚  â”‚Graph     â”‚  â”‚
â”‚  â”‚      â”‚  â”‚tency â”‚  â”‚ment    â”‚  â”‚       â”‚  â”‚Verify    â”‚  â”‚
â”‚  â””â”€â”€â”¬â”€â”€â”€â”˜  â””â”€â”€â”¬â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚
â”‚     â”‚         â”‚          â”‚           â”‚            â”‚         â”‚
â”‚  0.1ms     ~3-5x      ~50ms       ~1-2s        ~2-5s      â”‚
â”‚  cost      cost        cost        cost         cost       â”‚
â”‚  Free      Moderate    Low         High         High       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          + Citation Verification (è·¨æ–¹æ³•é€šç”¨)                â”‚
â”‚          å¯¹ç”Ÿæˆå†…å®¹çš„æ¯ä¸ª claim è¿½æº¯åˆ°æºæ–‡æ¡£                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</div>

  <h3>æ–¹æ³• 1: Logit/Entropy Probe â€” Token çº§ç½®ä¿¡åº¦</h3>
  <div class="bilingual">
    <div class="zh">
      <p><strong>åŸç†ï¼š</strong>åˆ†ææ¨¡å‹è¾“å‡ºæ¯ä¸ª token çš„æ¦‚ç‡åˆ†å¸ƒã€‚ä½æ¦‚ç‡æˆ–é«˜ entropy çš„ token æ›´å¯èƒ½æ˜¯å¹»è§‰ã€‚</p>
      <p><strong>ä¼˜åŠ¿ï¼š</strong>é›¶é¢å¤–æˆæœ¬ï¼Œå®æ—¶æ£€æµ‹ï¼ˆä¸ç”ŸæˆåŒæ­¥ï¼‰</p>
      <p><strong>å±€é™ï¼š</strong>éœ€è¦è®¿é—® logitsï¼ˆæ’é™¤é—­æº APIï¼‰ï¼Œä¸”é«˜ç½®ä¿¡çš„é”™è¯¯æ— æ³•æ•è·</p>
    </div>
    <div class="en">
      <p><strong>Principle:</strong> Analyze the probability distribution of each output token. Low-probability or high-entropy tokens are more likely hallucinated.</p>
      <p><strong>Strength:</strong> Zero extra cost, real-time detection (synchronous with generation)</p>
      <p><strong>Limitation:</strong> Requires logit access (excludes closed APIs), and confident errors go undetected</p>
    </div>
  </div>

<pre><code><span style="color:#569cd6">// Token-level entropy probe (vLLM HaluGate é£æ ¼)</span>
<span style="color:#c586c0">interface</span> <span style="color:#4ec9b0">TokenScore</span> {
  token: <span style="color:#4ec9b0">string</span>;
  logprob: <span style="color:#4ec9b0">number</span>;
  entropy: <span style="color:#4ec9b0">number</span>;    <span style="color:#569cd6">// Shannon entropy of top-k distribution</span>
  flagged: <span style="color:#4ec9b0">boolean</span>;
}

<span style="color:#c586c0">function</span> <span style="color:#dcdcaa">detectLowConfidenceSpans</span>(
  tokens: TokenScore[],
  entropyThreshold = <span style="color:#b5cea8">2.5</span>,
  windowSize = <span style="color:#b5cea8">5</span>
): Span[] {
  <span style="color:#569cd6">// æ»‘åŠ¨çª—å£ï¼šè¿ç»­é«˜ entropy tokens â†’ æ ‡è®°ä¸ºå¯ç–‘</span>
  <span style="color:#c586c0">const</span> spans: Span[] = [];
  <span style="color:#c586c0">let</span> start = -<span style="color:#b5cea8">1</span>;

  <span style="color:#c586c0">for</span> (<span style="color:#c586c0">let</span> i = <span style="color:#b5cea8">0</span>; i &lt; tokens.length; i++) {
    <span style="color:#c586c0">if</span> (tokens[i].entropy > entropyThreshold) {
      <span style="color:#c586c0">if</span> (start === -<span style="color:#b5cea8">1</span>) start = i;
    } <span style="color:#c586c0">else</span> {
      <span style="color:#c586c0">if</span> (start !== -<span style="color:#b5cea8">1</span> && i - start >= windowSize) {
        spans.push({ start, end: i, avgEntropy: avg(tokens, start, i) });
      }
      start = -<span style="color:#b5cea8">1</span>;
    }
  }
  <span style="color:#c586c0">return</span> spans;
}</code></pre>

  <h3>æ–¹æ³• 2: Self-Consistency Check â€” é‡‡æ ·ä¸€è‡´æ€§</h3>
  <div class="bilingual">
    <div class="zh">
      <p><strong>åŸç† (SelfCheckGPT)ï¼š</strong>å¯¹åŒä¸€ä¸ªé—®é¢˜é‡‡æ · N æ¬¡ï¼ˆtemperature > 0ï¼‰ï¼Œå¦‚æœå›ç­”ä¹‹é—´é«˜åº¦ä¸€è‡´ï¼Œåˆ™æ›´å¯èƒ½æ˜¯çœŸå®çŸ¥è¯†ï¼›å¦‚æœä¸ä¸€è‡´ï¼Œåˆ™å¯èƒ½æ˜¯å¹»è§‰ã€‚</p>
      <p><strong>å…³é”®æ´å¯Ÿï¼š</strong>æ¨¡å‹"çŸ¥é“"çš„äº‹å®ä¼šåœ¨å¤šæ¬¡é‡‡æ ·ä¸­ç¨³å®šå‡ºç°ï¼Œè€Œç¼–é€ çš„å†…å®¹æ¯æ¬¡éƒ½ä¸åŒã€‚</p>
    </div>
    <div class="en">
      <p><strong>Principle (SelfCheckGPT):</strong> Sample N responses to the same question (temperature > 0). High consistency across samples indicates real knowledge; inconsistency suggests hallucination.</p>
      <p><strong>Key insight:</strong> Facts the model "knows" appear consistently across samples, while fabrications vary each time.</p>
    </div>
  </div>

<pre><code><span style="color:#569cd6">// SelfCheckGPT-style consistency check</span>
<span style="color:#c586c0">async function</span> <span style="color:#dcdcaa">selfConsistencyCheck</span>(
  prompt: <span style="color:#4ec9b0">string</span>,
  originalResponse: <span style="color:#4ec9b0">string</span>,
  llm: LLMClient,
  numSamples = <span style="color:#b5cea8">5</span>  <span style="color:#569cd6">// è®ºæ–‡ç”¨20ï¼Œç”Ÿäº§ä¸­3-5å°±å¤Ÿ</span>
): Promise&lt;{ score: number; suspiciousClaims: string[] }&gt; {

  <span style="color:#569cd6">// Step 1: å¤šæ¬¡é‡‡æ ·</span>
  <span style="color:#c586c0">const</span> samples = <span style="color:#c586c0">await</span> Promise.all(
    Array(numSamples).fill(null).map(() =>
      llm.generate(prompt, { temperature: <span style="color:#b5cea8">0.7</span> })
    )
  );

  <span style="color:#569cd6">// Step 2: å°†åŸå§‹å›ç­”æ‹†åˆ†ä¸º claims</span>
  <span style="color:#c586c0">const</span> claims = extractClaims(originalResponse);

  <span style="color:#569cd6">// Step 3: ç”¨ NLI æ¨¡å‹æ£€æŸ¥æ¯ä¸ª claim ä¸ samples çš„ä¸€è‡´æ€§</span>
  <span style="color:#c586c0">const</span> scores = <span style="color:#c586c0">await</span> Promise.all(
    claims.map(<span style="color:#c586c0">async</span> (claim) => {
      <span style="color:#c586c0">const</span> nliScores = <span style="color:#c586c0">await</span> Promise.all(
        samples.map(s => nliEntailment(s, claim))
      );
      <span style="color:#569cd6">// å¹³å‡ entailment score, ä½ = å¯èƒ½å¹»è§‰</span>
      <span style="color:#c586c0">return</span> { claim, score: mean(nliScores) };
    })
  );

  <span style="color:#c586c0">const</span> suspicious = scores
    .filter(s => s.score &lt; <span style="color:#b5cea8">0.5</span>)
    .map(s => s.claim);

  <span style="color:#c586c0">return</span> {
    score: mean(scores.map(s => s.score)),
    suspiciousClaims: suspicious
  };
}</code></pre>

  <div class="highlight-blue">
    <strong>âš¡ ç”Ÿäº§ä¼˜åŒ–ï¼š</strong>è®ºæ–‡ç”¨ N=20 é‡‡æ ·ï¼Œä½†å®æµ‹ N=3~5 å·²ç»æœ‰å¾ˆå¥½çš„æ£€æµ‹æ•ˆæœï¼Œæˆæœ¬é™ä½ 75-85%ã€‚ç”¨ NLI å˜ä½“ (DeBERTa) ä»£æ›¿ LLM åšä¸€è‡´æ€§åˆ¤æ–­æ›´ä¾¿å®œã€‚
  </div>

  <h3>æ–¹æ³• 3: NLI Entailment â€” ä¸Šä¸‹æ–‡å¿ å®åº¦æ£€æµ‹</h3>
  <div class="bilingual">
    <div class="zh">
      <p><strong>åŸç†ï¼š</strong>ç”¨ Natural Language Inference æ¨¡å‹åˆ¤æ–­"ç”Ÿæˆå†…å®¹"æ˜¯å¦è¢«"æºæ–‡æ¡£"æ‰€è•´å« (entailed)ã€‚è¿™æ˜¯ RAG åœºæ™¯ä¸‹æ£€æµ‹ faithfulness hallucination çš„æ ¸å¿ƒæ–¹æ³•ã€‚</p>
      <p><strong>ä»£è¡¨æ¨¡å‹ï¼š</strong>HHEM (Hughes Hallucination Evaluation Model, åŸºäº DeBERTa-v3)ã€TRUEã€TrueTeacher</p>
    </div>
    <div class="en">
      <p><strong>Principle:</strong> Use an NLI model to check if "generated content" is entailed by "source documents." This is the core method for detecting faithfulness hallucination in RAG scenarios.</p>
      <p><strong>Key models:</strong> HHEM (Hughes Hallucination Eval Model, DeBERTa-v3 based), TRUE, TrueTeacher</p>
    </div>
  </div>

<pre><code><span style="color:#569cd6">// NLI-based faithfulness check for RAG</span>
<span style="color:#c586c0">interface</span> <span style="color:#4ec9b0">FaithfulnessResult</span> {
  overallScore: <span style="color:#4ec9b0">number</span>;       <span style="color:#569cd6">// 0-1, higher = more faithful</span>
  claimResults: {
    claim: <span style="color:#4ec9b0">string</span>;
    verdict: <span style="color:#ce9178">'supported'</span> | <span style="color:#ce9178">'contradicted'</span> | <span style="color:#ce9178">'unverifiable'</span>;
    score: <span style="color:#4ec9b0">number</span>;
    sourceChunk?: <span style="color:#4ec9b0">string</span>;     <span style="color:#569cd6">// æ”¯æ’‘è¯æ®å‡ºå¤„</span>
  }[];
}

<span style="color:#c586c0">async function</span> <span style="color:#dcdcaa">checkFaithfulness</span>(
  response: <span style="color:#4ec9b0">string</span>,
  sourceChunks: <span style="color:#4ec9b0">string</span>[],
  nliModel: NLIModel  <span style="color:#569cd6">// e.g., HHEM or DeBERTa-MNLI</span>
): Promise&lt;FaithfulnessResult&gt; {

  <span style="color:#569cd6">// Step 1: æ‹†åˆ† response ä¸ºç‹¬ç«‹çš„ claims (atomic facts)</span>
  <span style="color:#c586c0">const</span> claims = <span style="color:#c586c0">await</span> decomposeToClaims(response);
  <span style="color:#569cd6">// "Q1 revenue was $5M, up 20% YoY"
  // â†’ ["Q1 revenue was $5M", "Q1 revenue grew 20% YoY"]</span>

  <span style="color:#569cd6">// Step 2: å¯¹æ¯ä¸ª claim, æ£€æŸ¥æ˜¯å¦è¢«æŸä¸ª source chunk entail</span>
  <span style="color:#c586c0">const</span> results = <span style="color:#c586c0">await</span> Promise.all(
    claims.map(<span style="color:#c586c0">async</span> (claim) => {
      <span style="color:#c586c0">const</span> scores = <span style="color:#c586c0">await</span> Promise.all(
        sourceChunks.map(chunk =>
          nliModel.predict(chunk, claim) <span style="color:#569cd6">// premise, hypothesis</span>
        )
      );
      <span style="color:#c586c0">const</span> bestIdx = argmax(scores.map(s => s.entailment));
      <span style="color:#c586c0">const</span> best = scores[bestIdx];

      <span style="color:#c586c0">return</span> {
        claim,
        verdict: best.entailment > <span style="color:#b5cea8">0.7</span> ? <span style="color:#ce9178">'supported'</span>
               : best.contradiction > <span style="color:#b5cea8">0.7</span> ? <span style="color:#ce9178">'contradicted'</span>
               : <span style="color:#ce9178">'unverifiable'</span>,
        score: best.entailment,
        sourceChunk: sourceChunks[bestIdx]
      };
    })
  );

  <span style="color:#c586c0">return</span> {
    overallScore: mean(results.map(r => r.score)),
    claimResults: results
  };
}</code></pre>

  <h3>æ–¹æ³• 4: LLM-as-Judge â€” ç”¨å¤§æ¨¡å‹åˆ¤å¤§æ¨¡å‹</h3>
  <div class="bilingual">
    <div class="zh">
      <p><strong>åŸç†ï¼š</strong>ç”¨å¦ä¸€ä¸ªï¼ˆé€šå¸¸æ›´å¼ºçš„ï¼‰LLM æ¥è¯„ä¼°ç”Ÿæˆå†…å®¹æ˜¯å¦å­˜åœ¨å¹»è§‰ã€‚çµæ´»åº¦æœ€é«˜ï¼Œå¯ä»¥æ£€æµ‹å„ç§ç±»å‹çš„å¹»è§‰ã€‚</p>
      <p><strong>ç»å…¸æ¡†æ¶ï¼š</strong>G-Evalã€Lynxã€RAGAS çš„ faithfulness æŒ‡æ ‡</p>
      <p><strong>å…³é”®æƒè¡¡ï¼š</strong>å‡†ç¡®åº¦æœ€é«˜ä½†æˆæœ¬ä¹Ÿæœ€é«˜ï¼Œé€‚åˆç¦»çº¿è¯„ä¼°æˆ–é«˜ä»·å€¼åœºæ™¯</p>
    </div>
    <div class="en">
      <p><strong>Principle:</strong> Use another (usually stronger) LLM to evaluate whether generated content contains hallucinations. Most flexible, can detect all types.</p>
      <p><strong>Frameworks:</strong> G-Eval, Lynx, RAGAS faithfulness metric</p>
      <p><strong>Key tradeoff:</strong> Highest accuracy but highest cost; best for offline evaluation or high-value scenarios</p>
    </div>
  </div>

<pre><code><span style="color:#569cd6">// LLM-as-Judge hallucination check</span>
<span style="color:#c586c0">const</span> JUDGE_PROMPT = `You are a hallucination detection expert.

Given the SOURCE DOCUMENTS and the AI RESPONSE, evaluate each claim:
1. Extract all factual claims from the response
2. For each claim, determine:
   - SUPPORTED: directly supported by source documents
   - CONTRADICTED: contradicts the source documents
   - UNVERIFIABLE: cannot be verified from given sources

SOURCE DOCUMENTS:
{context}

AI RESPONSE:
{response}

Output JSON:
{
  "claims": [
    {"text": "...", "verdict": "supported|contradicted|unverifiable", "evidence": "..."}
  ],
  "overall_faithfulness": 0.0-1.0,
  "critical_issues": ["..."]
}`;

<span style="color:#569cd6">// å®é™…è°ƒç”¨</span>
<span style="color:#c586c0">const</span> judgment = <span style="color:#c586c0">await</span> strongerLLM.generate(
  JUDGE_PROMPT
    .replace(<span style="color:#ce9178">'{context}'</span>, sourceChunks.join(<span style="color:#ce9178">'\n---\n'</span>))
    .replace(<span style="color:#ce9178">'{response}'</span>, aiResponse),
  { temperature: <span style="color:#b5cea8">0</span>, response_format: { type: <span style="color:#ce9178">'json_object'</span> } }
);</code></pre>

  <h3>æ–¹æ³• 5: Knowledge Graph Verification â€” ç»“æ„åŒ–çŸ¥è¯†éªŒè¯</h3>
  <div class="bilingual">
    <div class="zh">
      <p><strong>åŸç†ï¼š</strong>å°† LLM è¾“å‡ºè½¬åŒ–ä¸ºä¸‰å…ƒç»„ (subject, predicate, object)ï¼Œç„¶åä¸çŸ¥è¯†å›¾è°±åŒ¹é…éªŒè¯ã€‚æœ€é€‚åˆäº‹å®æ€§éªŒè¯ã€‚</p>
      <p><strong>GraphEval æµç¨‹ï¼š</strong>Response â†’ ä¸‰å…ƒç»„æå– â†’ KG åŒ¹é… â†’ ä¸åŒ¹é…çš„æ ‡è®°ä¸ºå¹»è§‰</p>
    </div>
    <div class="en">
      <p><strong>Principle:</strong> Convert LLM output into triples (subject, predicate, object), then verify against a knowledge graph. Best for factual verification.</p>
      <p><strong>GraphEval flow:</strong> Response â†’ Triple extraction â†’ KG matching â†’ Unmatched = hallucination</p>
    </div>
  </div>

  <h3>æ–¹æ³• 6: Citation Verification â€” å¼•ç”¨è¿½æº¯</h3>
  <div class="bilingual">
    <div class="zh">
      <p><strong>åŸç†ï¼š</strong>å¼ºåˆ¶ LLM ä¸ºæ¯ä¸ª claim ç”Ÿæˆå¼•ç”¨æ ‡è®° [1][2]ï¼Œç„¶åéªŒè¯å¼•ç”¨çš„å†…å®¹æ˜¯å¦çœŸçš„æ”¯æŒè¯¥ claimã€‚</p>
      <p><strong>è¿™æ˜¯ç”Ÿäº§ç³»ç»Ÿä¸­æœ€å®ç”¨çš„æ–¹æ³•ä¹‹ä¸€</strong>â€”â€”æ—¢å¸®åŠ©æ£€æµ‹ï¼Œåˆæå‡ç”¨æˆ·ä¿¡ä»»ï¼ˆå¯è¿½æº¯æ€§ï¼‰ã€‚</p>
    </div>
    <div class="en">
      <p><strong>Principle:</strong> Force the LLM to generate citation markers [1][2] for each claim, then verify if cited content actually supports the claim.</p>
      <p><strong>One of the most practical methods in production</strong>â€”enables both detection and user trust (traceability).</p>
    </div>
  </div>

  <h2>ğŸ›¡ï¸ å…­å±‚é˜²å¾¡ä½“ç³»ï¼šä»é¢„é˜²åˆ°ä¿®å¤</h2>

  <div class="diagram">
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Production Hallucination Defense Layers             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Layer 1: Prompt Engineering (é¢„é˜²)                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ â€¢ "Only answer based on provided context"           â”‚     â”‚
â”‚  â”‚ â€¢ "If unsure, say 'I don't know'"                   â”‚     â”‚
â”‚  â”‚ â€¢ Chain-of-Thought å¼ºåˆ¶æ¨ç†                          â”‚     â”‚
â”‚  â”‚ â€¢ Few-shot ç¤ºä¾‹å±•ç¤ºæ­£ç¡®è¡Œä¸º                           â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                          â†“                                   â”‚
â”‚  Layer 2: Grounded Generation (RAG çº¦æŸ)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ â€¢ å¼ºåˆ¶åŸºäºæ£€ç´¢ç»“æœå›ç­”                                â”‚     â”‚
â”‚  â”‚ â€¢ ç”Ÿæˆæ—¶é™„å¸¦å¼•ç”¨æ ‡è®° [1][2]                           â”‚     â”‚
â”‚  â”‚ â€¢ é™åˆ¶ temperature (0-0.3)                          â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                          â†“                                   â”‚
â”‚  Layer 3: Real-Time Detection (åœ¨çº¿æ£€æµ‹)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ â€¢ Logit entropy probe (å¦‚æœ‰ logit access)           â”‚     â”‚
â”‚  â”‚ â€¢ NLI entailment check (HHEM, ~50ms)                â”‚     â”‚
â”‚  â”‚ â€¢ Citation verification                              â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                          â†“                                   â”‚
â”‚  Layer 4: Self-Correction (è‡ªä¿®å¤)                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ â€¢ æ£€æµ‹åˆ°ä½ç½®ä¿¡ claim â†’ é‡æ–°æ£€ç´¢ + é‡æ–°ç”Ÿæˆ            â”‚     â”‚
â”‚  â”‚ â€¢ Claim-level ä¿®è¡¥è€Œéæ•´ä½“é‡ç”Ÿæˆ                      â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                          â†“                                   â”‚
â”‚  Layer 5: User-Facing Safeguards (ç”¨æˆ·ä¾§)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ â€¢ ç½®ä¿¡åº¦æ ‡è®°ï¼ˆé«˜/ä¸­/ä½ï¼‰                              â”‚     â”‚
â”‚  â”‚ â€¢ æ˜¾ç¤ºå¼•ç”¨æ¥æº                                       â”‚     â”‚
â”‚  â”‚ â€¢ "I'm not sure about..." å£°æ˜                      â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                          â†“                                   â”‚
â”‚  Layer 6: Offline Evaluation (ç¦»çº¿è´¨é‡æŠŠå…³)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ â€¢ LLM-as-Judge æ‰¹é‡è¯„ä¼°                              â”‚     â”‚
â”‚  â”‚ â€¢ RAGAS faithfulness æŒ‡æ ‡ç›‘æ§                        â”‚     â”‚
â”‚  â”‚ â€¢ äººå·¥æŠ½æ ·å®¡æ ¸                                       â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</div>

  <h2>âœ¨ ç”Ÿäº§çº§ç»„åˆæ–¹æ¡ˆ</h2>

  <div class="bilingual">
    <div class="zh">
      <p>å•ä¸€æ–¹æ³•æ— æ³•è§£å†³æ‰€æœ‰å¹»è§‰é—®é¢˜ã€‚ç”Ÿäº§ç³»ç»Ÿéœ€è¦<strong>å¤šå±‚ç»„åˆ</strong>ï¼Œæ ¹æ®åœºæ™¯é€‰æ‹©åˆé€‚çš„æ£€æµ‹ç­–ç•¥ã€‚</p>
    </div>
    <div class="en">
      <p>No single method solves all hallucination problems. Production systems need <strong>multi-layered combinations</strong>, selecting appropriate detection strategies based on the scenario.</p>
    </div>
  </div>

  <h3>åœºæ™¯ A: RAG çŸ¥è¯†åº“é—®ç­”ï¼ˆæœ€å¸¸è§ï¼‰</h3>
<pre><code><span style="color:#569cd6">// RAG Hallucination Guard â€” ç”Ÿäº§çº§å®ç°</span>
<span style="color:#c586c0">async function</span> <span style="color:#dcdcaa">ragWithHallucinationGuard</span>(
  query: <span style="color:#4ec9b0">string</span>,
  retriever: Retriever,
  llm: LLMClient,
  nliModel: NLIModel
) {
  <span style="color:#569cd6">// Step 1: Retrieve</span>
  <span style="color:#c586c0">const</span> chunks = <span style="color:#c586c0">await</span> retriever.search(query, { topK: <span style="color:#b5cea8">5</span> });

  <span style="color:#569cd6">// Step 2: Generate with citation instructions</span>
  <span style="color:#c586c0">const</span> response = <span style="color:#c586c0">await</span> llm.generate({
    system: `Answer ONLY based on the provided documents.
Cite sources as [1], [2], etc.
If the documents don't contain enough information, say "Based on the available documents, I cannot fully answer this."`,
    user: query,
    context: chunks.map((c, i) => `[${i+1}] ${c.text}`).join(<span style="color:#ce9178">'\n'</span>),
    temperature: <span style="color:#b5cea8">0.1</span>  <span style="color:#569cd6">// ä½ temperature å‡å°‘åˆ›é€ æ€§</span>
  });

  <span style="color:#569cd6">// Step 3: NLI faithfulness check (Layer 3)</span>
  <span style="color:#c586c0">const</span> faithfulness = <span style="color:#c586c0">await</span> checkFaithfulness(
    response.text, chunks.map(c => c.text), nliModel
  );

  <span style="color:#569cd6">// Step 4: Handle based on score</span>
  <span style="color:#c586c0">if</span> (faithfulness.overallScore > <span style="color:#b5cea8">0.8</span>) {
    <span style="color:#569cd6">// âœ… é«˜ç½®ä¿¡ï¼šç›´æ¥è¿”å›</span>
    <span style="color:#c586c0">return</span> { response: response.text, confidence: <span style="color:#ce9178">'high'</span>, citations: chunks };
  }

  <span style="color:#c586c0">if</span> (faithfulness.overallScore > <span style="color:#b5cea8">0.5</span>) {
    <span style="color:#569cd6">// âš ï¸ ä¸­ç­‰ï¼šæ ‡è®°å¯ç–‘ claims + è¿”å›</span>
    <span style="color:#c586c0">const</span> warnings = faithfulness.claimResults
      .filter(c => c.verdict !== <span style="color:#ce9178">'supported'</span>)
      .map(c => c.claim);
    <span style="color:#c586c0">return</span> {
      response: response.text,
      confidence: <span style="color:#ce9178">'medium'</span>,
      warnings,   <span style="color:#569cd6">// å‘Šè¯‰ç”¨æˆ·å“ªäº›éƒ¨åˆ†ä¸ç¡®å®š</span>
      citations: chunks
    };
  }

  <span style="color:#569cd6">// âŒ ä½ç½®ä¿¡ï¼šSelf-Correction (Layer 4)</span>
  <span style="color:#c586c0">const</span> corrected = <span style="color:#c586c0">await</span> llm.generate({
    system: `Previous answer may contain inaccuracies. 
Rewrite using ONLY information from the documents. 
Mark uncertain parts with [uncertain].`,
    user: query,
    context: chunks.map((c, i) => `[${i+1}] ${c.text}`).join(<span style="color:#ce9178">'\n'</span>),
    previousAnswer: response.text,
    temperature: <span style="color:#b5cea8">0</span>
  });

  <span style="color:#c586c0">return</span> { response: corrected.text, confidence: <span style="color:#ce9178">'low'</span>, citations: chunks };
}</code></pre>

  <h3>åœºæ™¯ B: å¼€æ”¾åŸŸå¯¹è¯ï¼ˆChatGPT é£æ ¼ï¼‰</h3>
<pre><code><span style="color:#569cd6">// Open-domain hallucination mitigation</span>
<span style="color:#c586c0">async function</span> <span style="color:#dcdcaa">safeOpenDomainChat</span>(query: <span style="color:#4ec9b0">string</span>, llm: LLMClient) {
  <span style="color:#569cd6">// Strategy 1: Query Classification â€” åˆ†æµå¤„ç†</span>
  <span style="color:#c586c0">const</span> queryType = <span style="color:#c586c0">await</span> classifyQuery(query);
  <span style="color:#569cd6">// factual | creative | opinion | instruction</span>

  <span style="color:#c586c0">if</span> (queryType === <span style="color:#ce9178">'factual'</span>) {
    <span style="color:#569cd6">// äº‹å®æ€§é—®é¢˜ â†’ å…ˆæœç´¢ï¼Œå†ç”Ÿæˆ (Grounded)</span>
    <span style="color:#c586c0">const</span> searchResults = <span style="color:#c586c0">await</span> webSearch(query);
    <span style="color:#c586c0">return</span> llm.generate({
      system: <span style="color:#ce9178">`Answer based on search results. Cite sources.`</span>,
      context: searchResults,
      user: query,
      temperature: <span style="color:#b5cea8">0.1</span>
    });
  }

  <span style="color:#c586c0">if</span> (queryType === <span style="color:#ce9178">'creative'</span>) {
    <span style="color:#569cd6">// åˆ›æ„æ€§é—®é¢˜ â†’ æ— éœ€é˜²å¹»è§‰</span>
    <span style="color:#c586c0">return</span> llm.generate({ user: query, temperature: <span style="color:#b5cea8">0.8</span> });
  }

  <span style="color:#569cd6">// Strategy 2: Uncertainty Expression</span>
  <span style="color:#c586c0">return</span> llm.generate({
    system: <span style="color:#ce9178">`If you're not confident about factual claims,
prefix with "I believe" or "I'm not certain, but..."
Never invent specific numbers, dates, or names.`</span>,
    user: query,
    temperature: <span style="color:#b5cea8">0.3</span>
  });
}</code></pre>

  <h2>ğŸ“Š æ£€æµ‹æ–¹æ³•é€‰å‹å¯¹æ¯”</h2>

  <table>
    <tr>
      <th>æ–¹æ³•</th>
      <th>å»¶è¿Ÿ</th>
      <th>æˆæœ¬</th>
      <th>å‡†ç¡®åº¦</th>
      <th>æœ€é€‚åœºæ™¯</th>
      <th>éœ€è¦</th>
    </tr>
    <tr>
      <td>Logit Probe</td>
      <td>~0ms (åŒæ­¥)</td>
      <td>å…è´¹</td>
      <td>â­â­</td>
      <td>åˆç­›/é¢„è­¦</td>
      <td>Logit access</td>
    </tr>
    <tr>
      <td>Self-Consistency</td>
      <td>3-5x gen time</td>
      <td>3-5x ç”Ÿæˆæˆæœ¬</td>
      <td>â­â­â­</td>
      <td>å¼€æ”¾åŸŸ QA</td>
      <td>å¤šæ¬¡é‡‡æ ·</td>
    </tr>
    <tr>
      <td>NLI Entailment</td>
      <td>~50-100ms</td>
      <td>æä½ (å°æ¨¡å‹)</td>
      <td>â­â­â­</td>
      <td>RAG faithfulness</td>
      <td>æºæ–‡æ¡£</td>
    </tr>
    <tr>
      <td>LLM-as-Judge</td>
      <td>1-3s</td>
      <td>é«˜</td>
      <td>â­â­â­â­</td>
      <td>ç¦»çº¿è¯„ä¼°/é«˜ä»·å€¼</td>
      <td>å¼º LLM</td>
    </tr>
    <tr>
      <td>KG Verification</td>
      <td>2-5s</td>
      <td>é«˜ (æ„å»ºKG)</td>
      <td>â­â­â­â­</td>
      <td>å‚ç›´é¢†åŸŸäº‹å®</td>
      <td>çŸ¥è¯†å›¾è°±</td>
    </tr>
    <tr>
      <td>Citation Verify</td>
      <td>~100ms</td>
      <td>ä½</td>
      <td>â­â­â­</td>
      <td>RAG + å¯è¿½æº¯æ€§</td>
      <td>å¼•ç”¨ç”Ÿæˆ</td>
    </tr>
  </table>

  <div class="highlight-green">
    <strong>ğŸ¯ æ¨èç»„åˆ (æ€§ä»·æ¯”æœ€é«˜)ï¼š</strong><br>
    <strong>åœ¨çº¿ï¼š</strong>Prompt Engineering (Layer 1) + Citation Generation (Layer 2) + NLI Check (Layer 3) â€” è¦†ç›– 80% åœºæ™¯ï¼Œå»¶è¿Ÿå¢åŠ  &lt;200ms<br>
    <strong>ç¦»çº¿ï¼š</strong>LLM-as-Judge + RAGAS è¯„ä¼° â€” å®šæœŸæ‰¹é‡è´¨é‡ç›‘æ§
  </div>

  <h2>ğŸ“ Prompt Engineering é˜²å¹»è§‰æœ€ä½³å®è·µ</h2>

  <div class="bilingual">
    <div class="zh">
      <p>Prompt æ˜¯æœ€ä½æˆæœ¬çš„é˜²å¾¡å±‚ï¼Œä½†ä¹Ÿæœ€å®¹æ˜“è¢«å¿½è§†ã€‚ä»¥ä¸‹æ˜¯ç»éªŒè¯æœ‰æ•ˆçš„æ¨¡å¼ï¼š</p>
    </div>
    <div class="en">
      <p>Prompt engineering is the lowest-cost defense layer, but often overlooked. Here are proven effective patterns:</p>
    </div>
  </div>

<pre><code><span style="color:#569cd6">// ğŸ“Œ Pattern 1: Grounding Instruction</span>
<span style="color:#c586c0">const</span> GROUNDED_SYSTEM = `
You are a helpful assistant. Answer questions based ONLY on the 
provided context. Follow these rules strictly:

1. If the answer is in the context, cite the relevant section
2. If the answer is partially in the context, answer what you can
   and explicitly state what's missing
3. If the answer is NOT in the context, say: 
   "I don't have enough information to answer this"
4. NEVER make up facts, statistics, dates, or names
`;

<span style="color:#569cd6">// ğŸ“Œ Pattern 2: Chain-of-Verification (CoVe)</span>
<span style="color:#c586c0">const</span> COVE_PROMPT = `
After generating your answer, verify it:
1. List the key claims you made
2. For each claim, check: "Is this directly from the provided context?"
3. If any claim is not supported, revise or remove it
4. Output your final verified answer
`;

<span style="color:#569cd6">// ğŸ“Œ Pattern 3: Structured Output çº¦æŸ</span>
<span style="color:#c586c0">const</span> STRUCTURED_PROMPT = `
Answer in this exact JSON format:
{
  "answer": "your answer here",
  "confidence": "high|medium|low",
  "sources": ["quote from context that supports this"],
  "caveats": ["anything you're uncertain about"]
}
`;</code></pre>

  <div class="highlight">
    <strong>ğŸ’¡ å…³é”®æ´å¯Ÿï¼š</strong>ç ”ç©¶è¡¨æ˜ï¼Œç®€å•çš„ prompt æŒ‡ä»¤ "If you're not sure, say so" å¯ä»¥å°† GPT-4o çš„å¹»è§‰ç‡ä» 53% é™è‡³ 23%ã€‚è¿™æ˜¯<strong>æŠ•å…¥äº§å‡ºæ¯”æœ€é«˜</strong>çš„é˜²å¾¡æ‰‹æ®µã€‚
  </div>

  <h2>ğŸ“ è¯„ä¼°æŒ‡æ ‡ä¸ç›‘æ§</h2>

  <table>
    <tr>
      <th>æŒ‡æ ‡</th>
      <th>å®šä¹‰</th>
      <th>è®¡ç®—æ–¹å¼</th>
      <th>ç›®æ ‡å€¼</th>
    </tr>
    <tr>
      <td><strong>Faithfulness</strong></td>
      <td>ç”Ÿæˆå†…å®¹å¿ äºæºæ–‡æ¡£çš„æ¯”ä¾‹</td>
      <td>Supported claims / Total claims</td>
      <td>> 0.85</td>
    </tr>
    <tr>
      <td><strong>Hallucination Rate</strong></td>
      <td>åŒ…å«å¹»è§‰çš„å›ç­”æ¯”ä¾‹</td>
      <td>Responses with any contradicted claim / Total</td>
      <td>&lt; 5%</td>
    </tr>
    <tr>
      <td><strong>Abstention Rate</strong></td>
      <td>"æˆ‘ä¸çŸ¥é“" çš„å›ç­”æ¯”ä¾‹</td>
      <td>Refused responses / Total</td>
      <td>10-20% (å¤ªä½=è¿‡åº¦è‡ªä¿¡)</td>
    </tr>
    <tr>
      <td><strong>Citation Precision</strong></td>
      <td>å¼•ç”¨çš„å‡†ç¡®ç‡</td>
      <td>Valid citations / Total citations</td>
      <td>> 0.90</td>
    </tr>
  </table>

<pre><code><span style="color:#569cd6">// ç›‘æ§ Dashboard æ•°æ®æ”¶é›†</span>
<span style="color:#c586c0">interface</span> <span style="color:#4ec9b0">HallucinationMetrics</span> {
  timestamp: Date;
  faithfulnessScore: <span style="color:#4ec9b0">number</span>;
  hallucinationRate: <span style="color:#4ec9b0">number</span>;
  abstentionRate: <span style="color:#4ec9b0">number</span>;
  citationPrecision: <span style="color:#4ec9b0">number</span>;
  avgDetectionLatency: <span style="color:#4ec9b0">number</span>;
  <span style="color:#569cd6">// æŒ‰ç±»å‹ç»†åˆ†</span>
  byType: {
    intrinsic: <span style="color:#4ec9b0">number</span>;   <span style="color:#569cd6">// ä¸ context çŸ›ç›¾</span>
    extrinsic: <span style="color:#4ec9b0">number</span>;   <span style="color:#569cd6">// å‡­ç©ºæ·»åŠ </span>
    factual: <span style="color:#4ec9b0">number</span>;     <span style="color:#569cd6">// äº‹å®é”™è¯¯</span>
  };
}

<span style="color:#569cd6">// Alert: faithfulness è¿ç»­ä¸‹é™ â†’ å¯èƒ½æ˜¯æ•°æ®æºè¿‡æœŸæˆ– prompt drift</span></code></pre>

  <h2>ğŸ¤ é¢è¯•é«˜é¢‘é—®é¢˜</h2>

  <div class="interview">
    <h4>Q1: "å¦‚ä½•åœ¨ RAG ç³»ç»Ÿä¸­æ£€æµ‹å’Œé˜²æ­¢ hallucinationï¼Ÿ" (é«˜é¢‘ï¼)</h4>
    <p><strong>ç­”é¢˜æ¡†æ¶ï¼š</strong></p>
    <ol>
      <li><strong>é¢„é˜²ï¼š</strong>Prompt engineering (grounding instruction + low temperature) + citation generation</li>
      <li><strong>æ£€æµ‹ï¼š</strong>NLI entailment check (HHEM) â€” é€ claim æ£€æŸ¥ä¸æºæ–‡æ¡£çš„ä¸€è‡´æ€§ï¼Œ~50ms å»¶è¿Ÿ</li>
      <li><strong>ä¿®å¤ï¼š</strong>ä½ç½®ä¿¡ claim â†’ é‡æ–°æ£€ç´¢ + claim-level é‡ç”Ÿæˆï¼ˆæ¯”æ•´ä½“é‡ç”Ÿæˆæ›´é«˜æ•ˆï¼‰</li>
      <li><strong>ç”¨æˆ·ä¾§ï¼š</strong>æ˜¾ç¤ºå¼•ç”¨æ¥æº + ç½®ä¿¡åº¦æ ‡è®°ï¼Œè®©ç”¨æˆ·å¯éªŒè¯</li>
      <li><strong>ç¦»çº¿ï¼š</strong>RAGAS faithfulness æŒ‡æ ‡æŒç»­ç›‘æ§ï¼Œè®¾ç½®å‘Šè­¦é˜ˆå€¼</li>
    </ol>
  </div>

  <div class="interview">
    <h4>Q2: "SelfCheckGPT çš„åŸç†æ˜¯ä»€ä¹ˆï¼Ÿä»€ä¹ˆåœºæ™¯é€‚åˆï¼Ÿ"</h4>
    <p><strong>ç­”é¢˜è¦ç‚¹ï¼š</strong></p>
    <ul>
      <li><strong>åŸç†ï¼š</strong>å¯¹åŒä¸€ query é‡‡æ · N æ¬¡ï¼Œç”¨ NLI æ£€æŸ¥å„ claim åœ¨å¤šæ¬¡é‡‡æ ·ä¸­çš„ä¸€è‡´æ€§ã€‚ä¸€è‡´ = çŸ¥è¯†ï¼Œä¸ä¸€è‡´ = å¹»è§‰ã€‚</li>
      <li><strong>é€‚åˆï¼š</strong>æ— æ³•è·å–æºæ–‡æ¡£çš„åœºæ™¯ï¼ˆå¼€æ”¾åŸŸ QAã€é—­å·é—®ç­”ï¼‰ï¼Œå› ä¸ºå®ƒä¸éœ€è¦ ground truth</li>
      <li><strong>ä¸é€‚åˆï¼š</strong>RAG åœºæ™¯ï¼ˆæœ‰æºæ–‡æ¡£æ—¶ç›´æ¥ç”¨ NLI entailment æ›´ä¾¿å®œæ›´å‡†ï¼‰</li>
      <li><strong>ä¼˜åŒ–ï¼š</strong>ç”Ÿäº§ä¸­ N=3-5 å·²å¤Ÿï¼Œç”¨ DeBERTa-NLI ä»£æ›¿ LLM åšä¸€è‡´æ€§åˆ¤æ–­é™æœ¬</li>
    </ul>
  </div>

  <div class="interview">
    <h4>Q3: "Hallucination å’Œ Confabulation æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿå¦‚ä½•åˆ†ç±»ï¼Ÿ"</h4>
    <p><strong>ç­”é¢˜è¦ç‚¹ï¼š</strong></p>
    <ul>
      <li><strong>Intrinsic vs Extrinsicï¼š</strong>ä¸å·²æœ‰ context çŸ›ç›¾ vs æ·»åŠ  context ä¸­ä¸å­˜åœ¨çš„ä¿¡æ¯</li>
      <li><strong>Faithfulness vs Factualityï¼š</strong>ä¸å¿ äºè¾“å…¥ vs ä¸ç¬¦åˆä¸–ç•ŒçŸ¥è¯†â€”â€”RAG æ›´å…³å¿ƒå‰è€…</li>
      <li><strong>æ£€æµ‹éš¾åº¦é€’å¢ï¼š</strong>Intrinsic (NLI å¯è§£) â†’ Faithfulness (NLI + citation) â†’ Extrinsic (éœ€è¦ knowledge source) â†’ Factual (éœ€è¦çŸ¥è¯†åº“/æœç´¢)</li>
      <li>æ ¹æ®åœºæ™¯é€‰æ£€æµ‹ç­–ç•¥ï¼Œä¸è¦ç”¨é”¤å­å»é’‰èºä¸</li>
    </ul>
  </div>

  <div class="interview">
    <h4>Q4: "å¦‚æœç”¨æˆ·æŠ¥å‘Šä½ çš„ AI ç³»ç»Ÿäº§å‡ºäº†å¹»è§‰ï¼Œä½ ä¼šå¦‚ä½•å¤„ç†ï¼Ÿ"</h4>
    <p><strong>ç­”é¢˜æ¡†æ¶ (DIME)ï¼š</strong></p>
    <ol>
      <li><strong>Detectï¼š</strong>æ”¶é›† case â†’ åˆ†ç±»å¹»è§‰ç±»å‹ â†’ åˆ¤æ–­æ˜¯ä¸ªä¾‹è¿˜æ˜¯ç³»ç»Ÿæ€§é—®é¢˜</li>
      <li><strong>Investigateï¼š</strong>æ£€æŸ¥ promptã€æ£€ç´¢ç»“æœã€æ¨¡å‹è¾“å‡ºå„ç¯èŠ‚</li>
      <li><strong>Mitigateï¼š</strong>çŸ­æœŸ â€” åŠ  guardrail / è°ƒ promptï¼›é•¿æœŸ â€” åŠ æ£€æµ‹å±‚ã€æ›´æ–°è¯„ä¼° benchmark</li>
      <li><strong>Evaluateï¼š</strong>æ„å»ºå›å½’æµ‹è¯•é›†ï¼Œç¡®ä¿ä¿®å¤ä¸å¼•å…¥æ–°é—®é¢˜</li>
    </ol>
  </div>

  <h2>ğŸ“š ç³»åˆ—å›é¡¾ä¸å±•æœ›</h2>

  <div class="highlight-blue">
    <strong>LLM ç‰¹æœ‰é—®é¢˜ç³»åˆ—è¿›åº¦ï¼š</strong><br>
    âœ… Day 1: Token é™åˆ¶å¤„ç† â€” å…­å¤§ç­–ç•¥ä»æˆªæ–­åˆ° Context Extension<br>
    âœ… Day 2: æˆæœ¬ä¼˜åŒ– â€” å…­å±‚æ¡†æ¶å®ç° 91% é™æœ¬<br>
    âœ… <strong>Day 3: Hallucination æ£€æµ‹ä¸å¤„ç† (ä»Šå¤©)</strong> â€” å…­å¤§æ£€æµ‹æ–¹æ³• + å…­å±‚é˜²å¾¡ä½“ç³»<br>
    â†’ Day 4: æµå¼è¾“å‡ºæ¶æ„ â€” SSE/WebSocket å®ç° + é”™è¯¯å¤„ç†<br>
    â†’ Day 5: Multi-turn å¯¹è¯çŠ¶æ€ç®¡ç† â€” Context Window ç®¡ç† + è®°å¿†ç­–ç•¥
  </div>

  <div class="follow-up">
    <h3>ğŸ’¬ åç»­è®¨è®º / Follow-up Discussion</h3>
    <p>å¯ä»¥æ·±å…¥è®¨è®ºï¼š</p>
    <ul>
      <li>HHEM vs DeBERTa-MNLI åœ¨å®é™… RAG åœºæ™¯çš„å¯¹æ¯”</li>
      <li>Chain-of-Verification (CoVe) çš„å®é™…æ•ˆæœ</li>
      <li>å¦‚ä½•ä¸ºç‰¹å®šé¢†åŸŸ fine-tune ä¸€ä¸ª hallucination detector</li>
    </ul>
  </div>

</body>
</html>
