<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>2026-02-08 - RAG Advanced Retrieval Strategies</title>
  <style>
    body { font-family: -apple-system, system-ui, sans-serif; max-width: 900px; margin: 0 auto; padding: 20px; line-height: 1.7; color: #3c4043; }
    .bilingual { display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin: 15px 0; }
    .zh { border-left: 3px solid #f9ab00; padding-left: 15px; }
    .en { border-left: 3px solid #1a73e8; padding-left: 15px; }
    h1 { color: #3c4043; border-bottom: 2px solid #f9ab00; padding-bottom: 10px; }
    h2 { color: #1a73e8; margin-top: 35px; }
    h3 { color: #e8710a; }
    .architecture { background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 20px 0; font-family: 'Courier New', monospace; font-size: 13px; white-space: pre; overflow-x: auto; line-height: 1.4; }
    pre { background: #1e1e1e; color: #d4d4d4; padding: 15px; border-radius: 8px; overflow-x: auto; font-size: 13px; }
    .keyword { color: #569cd6; }
    .string { color: #ce9178; }
    .comment { color: #6a9955; }
    .func { color: #dcdcaa; }
    .type { color: #4ec9b0; }
    .highlight { background: #fff3cd; padding: 15px; border-radius: 8px; margin: 15px 0; }
    .highlight h4 { margin-top: 0; color: #856404; }
    .comparison { display: grid; grid-template-columns: 1fr 1fr; gap: 15px; margin: 15px 0; }
    .comparison > div { background: #f8f9fa; padding: 15px; border-radius: 8px; }
    .tag { display: inline-block; padding: 2px 8px; border-radius: 12px; font-size: 12px; margin: 2px; }
    .tag-green { background: #d4edda; color: #155724; }
    .tag-red { background: #f8d7da; color: #721c24; }
    .tag-blue { background: #d1ecf1; color: #0c5460; }
    .interview { background: #e8f5e9; padding: 15px; border-radius: 8px; margin: 15px 0; border-left: 4px solid #4caf50; }
    .interview h4 { color: #2e7d32; margin-top: 0; }
    .follow-up { margin-top: 30px; padding: 15px; border: 1px dashed #dadce0; border-radius: 8px; }
    table { width: 100%; border-collapse: collapse; margin: 15px 0; }
    th, td { border: 1px solid #dadce0; padding: 10px; text-align: left; }
    th { background: #f8f9fa; }
    .series-nav { background: #e3f2fd; padding: 12px; border-radius: 8px; margin: 15px 0; }
  </style>
</head>
<body>
  <h1>ğŸ” RAG Advanced Retrieval Strategies</h1>
  <p>ğŸ“… 2026-02-08 | ğŸ“š RAG ç³»åˆ— Day 3/4 | Phase 1.3</p>
  
  <div class="series-nav">
    <strong>RAG ç³»åˆ—å¯¼èˆª:</strong>
    Day 1: <a href="2026-02-05-rag-pipeline-architecture.html">Pipeline æ¶æ„</a> â†’
    Day 2: <a href="2026-02-07-rag-advanced-chunking.html">Advanced Chunking</a> â†’
    <strong>Day 3: Advanced Retrieval (æœ¬ç¯‡)</strong> â†’
    Day 4: Production RAG
  </div>

  <h2>ğŸ“– ä»Šæ—¥ä¸»é¢˜ / Today's Topic</h2>
  <div class="bilingual">
    <div class="zh">
      <p>Chunking è§£å†³äº†"æ€ä¹ˆå­˜"ï¼Œä»Šå¤©è§£å†³<strong>"æ€ä¹ˆæ‰¾"</strong>ã€‚ç”¨æˆ·çš„ query å¾€å¾€æ¨¡ç³Šã€ä¸å®Œæ•´ï¼Œç›´æ¥æ‹¿å»æ£€ç´¢æ•ˆæœå¾ˆå·®ã€‚Advanced Retrieval çš„æ ¸å¿ƒæ€æƒ³ï¼š<strong>åœ¨æ£€ç´¢ä¹‹å‰ï¼Œå…ˆæ”¹é€  query</strong>ã€‚</p>
      <p>ä»Šå¤©è¦†ç›– 5 ä¸ªå…³é”®æŠ€æœ¯ï¼š</p>
      <ol>
        <li><strong>Multi-Query</strong> â€” ä¸€ä¸ªé—®é¢˜å˜å¤šä¸ª</li>
        <li><strong>HyDE</strong> â€” å…ˆç”Ÿæˆå‡ç­”æ¡ˆå†æ£€ç´¢</li>
        <li><strong>Step-Back Prompting</strong> â€” é—®é¢˜æŠ½è±¡åŒ–</li>
        <li><strong>Self-Query</strong> â€” è‡ªåŠ¨æå– metadata filter</li>
        <li><strong>Multi-Hop Retrieval</strong> â€” è¿­ä»£æ£€ç´¢å¤æ‚é—®é¢˜</li>
      </ol>
    </div>
    <div class="en">
      <p>Chunking solved "how to store". Today we solve <strong>"how to find"</strong>. Users' queries are often vague or incomplete â€” direct retrieval performs poorly. The core idea: <strong>transform the query before retrieval</strong>.</p>
      <p>5 key techniques today:</p>
      <ol>
        <li><strong>Multi-Query</strong> â€” one question â†’ multiple</li>
        <li><strong>HyDE</strong> â€” generate fake answer, then retrieve</li>
        <li><strong>Step-Back Prompting</strong> â€” abstract the question</li>
        <li><strong>Self-Query</strong> â€” auto-extract metadata filters</li>
        <li><strong>Multi-Hop Retrieval</strong> â€” iterative retrieval for complex questions</li>
      </ol>
    </div>
  </div>

  <h2>ğŸ—ï¸ æ•´ä½“æ¶æ„ / Query Transformation Pipeline</h2>
  <div class="architecture">
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚      User Query (åŸå§‹)       â”‚
                         â”‚  "Why is my RAG slow?"       â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼               â–¼               â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Multi-Query â”‚ â”‚   HyDE   â”‚ â”‚  Step-Back     â”‚
            â”‚  (åˆ†è£‚)      â”‚ â”‚  (å‡è®¾)   â”‚ â”‚  (æŠ½è±¡åŒ–)      â”‚
            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚              â”‚               â”‚
         â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”´â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
         â–¼     â–¼     â–¼     â–¼           â”‚    â–¼         â”‚
        Q1    Q2    Q3   HyDocâ†’Embed   â”‚  Abstract Q  â”‚
         â”‚     â”‚     â”‚     â”‚           â”‚    â”‚         â”‚
         â””â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
               â”‚                 â”‚               â”‚
               â–¼                 â–¼               â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚          Vector Store / Retriever        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Self-Query (metadata)  â”‚â—„â”€â”€ å¯ç»„åˆä½¿ç”¨
              â”‚   è¿‡æ»¤ year>2024 ç­‰      â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Multi-Hop (è¿­ä»£æ£€ç´¢)     â”‚â—„â”€â”€ å¤æ‚é—®é¢˜
              â”‚  Round 1 â†’ Round 2 â†’ ... â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Rerank + Generate      â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</div>

  <h2>âœ¨ æŠ€æœ¯è¯¦è§£ / Deep Dive</h2>

  <!-- 1. Multi-Query -->
  <h3>1ï¸âƒ£ Multi-Query Retrieval</h3>
  <div class="bilingual">
    <div class="zh">
      <p><strong>æ ¸å¿ƒæ€æƒ³</strong>ï¼šåŒä¸€ä¸ªé—®é¢˜ï¼Œæ¢å‡ ç§è¯´æ³•å»æ£€ç´¢ï¼Œåˆå¹¶ç»“æœã€‚è§£å†³ç”¨æˆ·æªè¾å’Œæ–‡æ¡£æªè¾ä¸åŒ¹é…çš„é—®é¢˜ã€‚</p>
      <p><strong>ä¸ºä»€ä¹ˆæœ‰æ•ˆ</strong>ï¼šembedding å¯¹åŒä¹‰è¯ä¸æ•æ„Ÿã€‚"æ€§èƒ½å·®"å’Œ"å»¶è¿Ÿé«˜"åœ¨è¯­ä¹‰ç©ºé—´è·ç¦»å¯èƒ½å¾ˆè¿œï¼Œä½†å…¶å®æ˜¯åŒä¸€ä¸ªæ„æ€ã€‚</p>
      <p><strong>å®ç°æ–¹å¼</strong>ï¼šè®© LLM ç”Ÿæˆ 3-5 ä¸ªæ”¹å†™ç‰ˆæœ¬ â†’ åˆ†åˆ«æ£€ç´¢ â†’ åˆå¹¶å»é‡ï¼ˆç”¨ RRF æˆ–å–å¹¶é›†ï¼‰ã€‚</p>
    </div>
    <div class="en">
      <p><strong>Core idea</strong>: Rephrase the same question multiple ways, retrieve for each, merge results. Solves the vocabulary mismatch problem.</p>
      <p><strong>Why it works</strong>: Embeddings can be insensitive to synonyms. "slow performance" vs "high latency" might be far apart in vector space despite meaning the same thing.</p>
      <p><strong>Implementation</strong>: LLM generates 3-5 variants â†’ retrieve each â†’ merge with RRF or union dedup.</p>
    </div>
  </div>
  
  <pre><code><span class="comment">// Multi-Query Retrieval å®ç°</span>
<span class="keyword">async function</span> <span class="func">multiQueryRetrieve</span>(query: <span class="type">string</span>, retriever: <span class="type">Retriever</span>) {
  <span class="comment">// Step 1: LLM ç”Ÿæˆå¤šä¸ªå˜ä½“</span>
  <span class="keyword">const</span> variants = <span class="keyword">await</span> llm.<span class="func">generate</span>({
    prompt: <span class="string">`Generate 3 different versions of this question 
for vector search. Output as JSON array.
Original: ${query}`</span>
  }); <span class="comment">// ["What causes RAG latency?", "How to speed up retrieval?", "RAG performance bottlenecks"]</span>

  <span class="comment">// Step 2: å¹¶è¡Œæ£€ç´¢æ¯ä¸ªå˜ä½“</span>
  <span class="keyword">const</span> allDocs = <span class="keyword">await</span> Promise.<span class="func">all</span>(
    [query, ...variants].<span class="func">map</span>(q => retriever.<span class="func">retrieve</span>(q, { topK: 5 }))
  );

  <span class="comment">// Step 3: RRF èåˆ (Reciprocal Rank Fusion)</span>
  <span class="keyword">return</span> <span class="func">reciprocalRankFusion</span>(allDocs, { k: 60 });
}

<span class="comment">// RRF: score(doc) = Î£ 1/(k + rank_i)</span>
<span class="keyword">function</span> <span class="func">reciprocalRankFusion</span>(rankings: <span class="type">Doc[][]</span>, { k = 60 }) {
  <span class="keyword">const</span> scores = <span class="keyword">new</span> Map&lt;<span class="type">string</span>, <span class="type">number</span>&gt;();
  <span class="keyword">for</span> (<span class="keyword">const</span> ranking <span class="keyword">of</span> rankings) {
    ranking.<span class="func">forEach</span>((doc, rank) => {
      <span class="keyword">const</span> prev = scores.<span class="func">get</span>(doc.id) || 0;
      scores.<span class="func">set</span>(doc.id, prev + 1 / (k + rank + 1));
    });
  }
  <span class="keyword">return</span> [...scores.entries()].<span class="func">sort</span>((a, b) => b[1] - a[1]);
}</code></pre>

  <div class="highlight">
    <h4>ğŸ’¡ LangChain ä¸€è¡Œæå®š</h4>
    <code>const retriever = MultiQueryRetriever.fromLLM({ llm, retriever: baseRetriever });</code>
    <p>å†…éƒ¨è‡ªåŠ¨ç”Ÿæˆå˜ä½“ã€æ£€ç´¢ã€å»é‡åˆå¹¶ã€‚</p>
  </div>

  <!-- 2. HyDE -->
  <h3>2ï¸âƒ£ HyDE (Hypothetical Document Embeddings)</h3>
  <div class="bilingual">
    <div class="zh">
      <p><strong>æ ¸å¿ƒæ€æƒ³</strong>ï¼šç”¨æˆ· query æ˜¯"é—®é¢˜"ï¼Œä½†å‘é‡åº“é‡Œå­˜çš„æ˜¯"ç­”æ¡ˆ"ã€‚ä¸¤è€…è¯­ä¹‰ç©ºé—´ä¸åŒï¼è§£æ³•ï¼šè®© LLM å…ˆç”Ÿæˆä¸€ä¸ª<strong>å‡è®¾æ€§ç­”æ¡ˆ</strong>ï¼Œç”¨å‡ç­”æ¡ˆå»æ£€ç´¢çœŸæ–‡æ¡£ã€‚</p>
      <p><strong>å…³é”®æ´å¯Ÿ</strong>ï¼šå‡ç­”æ¡ˆå¯èƒ½äº‹å®ä¸å¯¹ï¼Œä½†å®ƒçš„<strong>è¯­è¨€æ¨¡å¼</strong>å’ŒçœŸå®æ–‡æ¡£æ›´æ¥è¿‘ã€‚query "What is PagedAttention?" å¯èƒ½åŒ¹é…ä¸åˆ°æ–‡æ¡£ï¼Œä½†ç”Ÿæˆçš„å‡ç­”æ¡ˆ "PagedAttention is a memory management technique that..." å’ŒçœŸæ–‡æ¡£é«˜åº¦ç›¸ä¼¼ã€‚</p>
      <p><strong>é€‚ç”¨åœºæ™¯</strong>ï¼šæŠ€æœ¯æ–‡æ¡£æ£€ç´¢ã€å­¦æœ¯è®ºæ–‡æœç´¢ â€” query å’Œæ–‡æ¡£é£æ ¼å·®å¼‚å¤§çš„åœºæ™¯ã€‚</p>
    </div>
    <div class="en">
      <p><strong>Core idea</strong>: Queries are "questions" but the vector store contains "answers". Different semantic spaces! Solution: have LLM generate a <strong>hypothetical answer</strong>, use it to retrieve real documents.</p>
      <p><strong>Key insight</strong>: The fake answer may be factually wrong, but its <strong>language patterns</strong> closely match real documents. "What is X?" won't match docs, but "X is a technique that..." will.</p>
      <p><strong>Best for</strong>: Technical docs, academic papers â€” anywhere query style differs from document style.</p>
    </div>
  </div>

  <pre><code><span class="comment">// HyDE å®ç°</span>
<span class="keyword">async function</span> <span class="func">hydeRetrieve</span>(query: <span class="type">string</span>) {
  <span class="comment">// Step 1: ç”Ÿæˆå‡è®¾æ€§æ–‡æ¡£</span>
  <span class="keyword">const</span> hypothetical = <span class="keyword">await</span> llm.<span class="func">generate</span>({
    prompt: <span class="string">`Write a short technical document that answers this question.
Don't worry about accuracy â€” focus on the writing style and terminology.
Question: ${query}`</span>
  });

  <span class="comment">// Step 2: ç”¨å‡æ–‡æ¡£çš„ embedding æ£€ç´¢</span>
  <span class="keyword">const</span> embedding = <span class="keyword">await</span> <span class="func">embed</span>(hypothetical); <span class="comment">// NOT the query!</span>
  <span class="keyword">const</span> docs = <span class="keyword">await</span> vectorStore.<span class="func">similaritySearch</span>(embedding, { topK: 5 });
  
  <span class="keyword">return</span> docs;
}

<span class="comment">// âš ï¸ æƒè¡¡: å¤šä¸€æ¬¡ LLM è°ƒç”¨ = æ›´å¤šå»¶è¿Ÿ + æˆæœ¬</span>
<span class="comment">// âœ… é€‚åˆ: ç”¨æˆ· query çŸ­/æ¨¡ç³Š, æ–‡æ¡£ä¸“ä¸šæ€§å¼º</span>
<span class="comment">// âŒ ä¸é€‚åˆ: ç”¨æˆ· query æœ¬èº«å°±å¾ˆå…·ä½“çš„åœºæ™¯</span></code></pre>

  <div class="comparison">
    <div>
      <h4>âœ… HyDE é€‚ç”¨</h4>
      <p>Query: "attention mechanism"</p>
      <p>â†’ ç”Ÿæˆ: "The attention mechanism allows models to focus on relevant parts of the input sequence by computing weighted sums..."</p>
      <p>â†’ åŒ¹é…åˆ° Transformer è®ºæ–‡ç›¸å…³æ®µè½</p>
    </div>
    <div>
      <h4>âŒ HyDE ä¸é€‚ç”¨</h4>
      <p>Query: "List all errors in log file X from Jan 5"</p>
      <p>â†’ LLM æ— æ³•ç”Ÿæˆæœ‰æ„ä¹‰çš„å‡æ–‡æ¡£</p>
      <p>â†’ ç›´æ¥æ£€ç´¢ + metadata filter æ›´å¥½</p>
    </div>
  </div>

  <!-- 3. Step-Back Prompting -->
  <h3>3ï¸âƒ£ Step-Back Prompting</h3>
  <div class="bilingual">
    <div class="zh">
      <p><strong>æ ¸å¿ƒæ€æƒ³</strong>ï¼šæŠŠå…·ä½“é—®é¢˜æŠ½è±¡æˆæ›´é€šç”¨çš„é—®é¢˜ã€‚å…·ä½“é—®é¢˜æ£€ç´¢èŒƒå›´å¤ªçª„ï¼ŒæŠ½è±¡é—®é¢˜èƒ½æ‰¾åˆ°æ›´å¤šç›¸å…³ä¸Šä¸‹æ–‡ã€‚</p>
      <p><strong>ä¾‹å­</strong>ï¼š"ä¸ºä»€ä¹ˆ vLLM ç”¨ PagedAttention æ¯” continuous batching å¿«ï¼Ÿ" â†’ æŠ½è±¡: "LLM æ¨ç†ä¸­æœ‰å“ªäº›å†…å­˜ç®¡ç†ç­–ç•¥ï¼Ÿ" â†’ æ£€ç´¢åˆ°æ›´å…¨é¢çš„èƒŒæ™¯çŸ¥è¯†ã€‚</p>
      <p>æ¥è‡ª Google DeepMind 2023 å¹´è®ºæ–‡ï¼Œç®€å•ä½†éå¸¸æœ‰æ•ˆã€‚</p>
    </div>
    <div class="en">
      <p><strong>Core idea</strong>: Abstract a specific question into a more general one. Specific queries have narrow retrieval scope; abstract queries find broader context.</p>
      <p><strong>Example</strong>: "Why is PagedAttention faster than continuous batching in vLLM?" â†’ Abstract: "What memory management strategies exist for LLM inference?" â†’ retrieves comprehensive background.</p>
      <p>From Google DeepMind 2023 paper. Simple but remarkably effective.</p>
    </div>
  </div>

  <pre><code><span class="comment">// Step-Back Prompting</span>
<span class="keyword">async function</span> <span class="func">stepBackRetrieve</span>(query: <span class="type">string</span>) {
  <span class="comment">// Step 1: ç”ŸæˆæŠ½è±¡ç‰ˆé—®é¢˜</span>
  <span class="keyword">const</span> abstractQuery = <span class="keyword">await</span> llm.<span class="func">generate</span>({
    prompt: <span class="string">`Given this specific question, generate a more general "step-back" 
question that would help retrieve useful background knowledge.
Specific: ${query}
Step-back question:`</span>
  });

  <span class="comment">// Step 2: åŒæ—¶æ£€ç´¢åŸå§‹ + æŠ½è±¡é—®é¢˜</span>
  <span class="keyword">const</span> [specificDocs, backgroundDocs] = <span class="keyword">await</span> Promise.<span class="func">all</span>([
    retriever.<span class="func">retrieve</span>(query, { topK: 3 }),
    retriever.<span class="func">retrieve</span>(abstractQuery, { topK: 3 })
  ]);

  <span class="comment">// Step 3: åˆå¹¶ â€” èƒŒæ™¯çŸ¥è¯† + å…·ä½“ç»†èŠ‚</span>
  <span class="keyword">return</span> [...backgroundDocs, ...specificDocs];
}</code></pre>

  <!-- 4. Self-Query -->
  <h3>4ï¸âƒ£ Self-Query Retrieval</h3>
  <div class="bilingual">
    <div class="zh">
      <p><strong>æ ¸å¿ƒæ€æƒ³</strong>ï¼šç”¨æˆ· query é‡Œç»å¸¸åŒ…å«<strong>ç»“æ„åŒ–è¿‡æ»¤æ¡ä»¶</strong>ï¼ˆæ—¥æœŸã€ç±»å‹ã€ä½œè€…ç­‰ï¼‰ï¼Œä½† vector search åªåšè¯­ä¹‰åŒ¹é…ï¼Œä¼šå¿½ç•¥è¿™äº›æ¡ä»¶ã€‚Self-Query è®© LLM è‡ªåŠ¨æŠŠ query æ‹†æˆï¼šè¯­ä¹‰æŸ¥è¯¢ + metadata filterã€‚</p>
      <p><strong>ä¾‹å­</strong>ï¼š"2024å¹´ä¹‹åå…³äº RAG çš„è®ºæ–‡" â†’ è¯­ä¹‰: "RAG papers" + Filter: <code>year >= 2024</code></p>
      <p>è¿™æ˜¯ <strong>æœ€å®ç”¨</strong> çš„ retrieval ä¼˜åŒ–ä¹‹ä¸€ï¼Œå‡ ä¹æ‰€æœ‰ç”Ÿäº§ RAG éƒ½éœ€è¦ã€‚</p>
    </div>
    <div class="en">
      <p><strong>Core idea</strong>: Queries often contain <strong>structured filter conditions</strong> (dates, types, authors), but vector search only does semantic matching. Self-Query auto-splits the query into: semantic search + metadata filter.</p>
      <p><strong>Example</strong>: "RAG papers after 2024" â†’ Semantic: "RAG papers" + Filter: <code>year >= 2024</code></p>
      <p>One of the <strong>most practical</strong> retrieval optimizations. Almost every production RAG needs this.</p>
    </div>
  </div>

  <pre><code><span class="comment">// Self-Query: LLM è‡ªåŠ¨æå– filter</span>
<span class="keyword">async function</span> <span class="func">selfQueryRetrieve</span>(query: <span class="type">string</span>, schema: <span class="type">MetadataSchema</span>) {
  <span class="comment">// Step 1: LLM è§£æ query â†’ ç»“æ„åŒ–</span>
  <span class="keyword">const</span> parsed = <span class="keyword">await</span> llm.<span class="func">generate</span>({
    prompt: <span class="string">`Given user query and available metadata fields, extract:
1. A semantic search query (for vector search)
2. Metadata filters (for structured filtering)

Available fields: ${JSON.stringify(schema)}
User query: "${query}"

Output JSON: { "semanticQuery": "...", "filters": {...} }`</span>
  });
  <span class="comment">// â†’ { semanticQuery: "RAG techniques", filters: { year: { "$gte": 2024 }, type: "paper" } }</span>

  <span class="comment">// Step 2: æ‰§è¡Œå¸¦ filter çš„å‘é‡æ£€ç´¢</span>
  <span class="keyword">return</span> vectorStore.<span class="func">similaritySearch</span>(parsed.semanticQuery, {
    topK: 10,
    filter: parsed.filters  <span class="comment">// Pinecone/Weaviate/pgvector éƒ½æ”¯æŒ</span>
  });
}

<span class="comment">// LangChain: SelfQueryRetriever å†…ç½®æ”¯æŒ</span>
<span class="keyword">const</span> retriever = SelfQueryRetriever.<span class="func">fromLLM</span>({
  llm,
  vectorStore,
  documentContents: <span class="string">"Technical blog posts about AI"</span>,
  attributeInfo: [
    { name: <span class="string">"year"</span>, type: <span class="string">"number"</span>, description: <span class="string">"Publication year"</span> },
    { name: <span class="string">"author"</span>, type: <span class="string">"string"</span>, description: <span class="string">"Author name"</span> },
    { name: <span class="string">"topic"</span>, type: <span class="string">"string"</span>, description: <span class="string">"Main topic"</span> },
  ]
});</code></pre>

  <!-- 5. Multi-Hop -->
  <h3>5ï¸âƒ£ Multi-Hop Retrieval</h3>
  <div class="bilingual">
    <div class="zh">
      <p><strong>æ ¸å¿ƒæ€æƒ³</strong>ï¼šæœ‰äº›é—®é¢˜éœ€è¦<strong>å¤šæ­¥æ¨ç†</strong>ï¼Œä¸€æ¬¡æ£€ç´¢ä¸å¤Ÿã€‚Multi-Hop è¿­ä»£æ£€ç´¢ï¼šç¬¬ä¸€è½®çš„ç»“æœæŒ‡å¯¼ç¬¬äºŒè½®çš„ queryã€‚</p>
      <p><strong>ä¾‹å­</strong>ï¼š"DeepSeek çš„ CEO åœ¨å“ªä¸ªå¤§å­¦è¯»çš„åšå£«ï¼Ÿ"</p>
      <ol>
        <li>Round 1: æ£€ç´¢ "DeepSeek CEO" â†’ å¾—åˆ° "æ¢æ–‡å³°"</li>
        <li>Round 2: æ£€ç´¢ "æ¢æ–‡å³° åšå£« å¤§å­¦" â†’ å¾—åˆ°ç­”æ¡ˆ</li>
      </ol>
      <p>è¿™ä¹Ÿæ˜¯ç°åœ¨ <strong>Agentic RAG</strong> çš„æ ¸å¿ƒæ¨¡å¼ â€” Agent å†³å®šè¦ä¸è¦ç»§ç»­æ£€ç´¢ã€‚</p>
    </div>
    <div class="en">
      <p><strong>Core idea</strong>: Some questions require <strong>multi-step reasoning</strong>. Multi-Hop iterates: results from round 1 inform the query for round 2.</p>
      <p><strong>Example</strong>: "Where did DeepSeek's CEO get his PhD?"</p>
      <ol>
        <li>Round 1: Retrieve "DeepSeek CEO" â†’ "Liang Wenfeng"</li>
        <li>Round 2: Retrieve "Liang Wenfeng PhD university" â†’ answer</li>
      </ol>
      <p>This is the core pattern of <strong>Agentic RAG</strong> â€” the agent decides whether to keep retrieving.</p>
    </div>
  </div>

  <pre><code><span class="comment">// Multi-Hop: è¿­ä»£æ£€ç´¢ + LLM åˆ¤æ–­æ˜¯å¦éœ€è¦ç»§ç»­</span>
<span class="keyword">async function</span> <span class="func">multiHopRetrieve</span>(query: <span class="type">string</span>, maxHops = 3) {
  <span class="keyword">let</span> context: <span class="type">Doc[]</span> = [];
  <span class="keyword">let</span> currentQuery = query;

  <span class="keyword">for</span> (<span class="keyword">let</span> hop = 0; hop < maxHops; hop++) {
    <span class="comment">// æ£€ç´¢</span>
    <span class="keyword">const</span> docs = <span class="keyword">await</span> retriever.<span class="func">retrieve</span>(currentQuery, { topK: 3 });
    context.<span class="func">push</span>(...docs);

    <span class="comment">// LLM åˆ¤æ–­: å¤Ÿäº†å—ï¼Ÿ</span>
    <span class="keyword">const</span> judgment = <span class="keyword">await</span> llm.<span class="func">generate</span>({
      prompt: <span class="string">`Original question: ${query}
Retrieved so far: ${summarize(context)}

Can you answer the question with current information?
If YES â†’ output { "done": true, "answer": "..." }
If NO â†’ output { "done": false, "nextQuery": "..." }`</span>
    });

    <span class="keyword">if</span> (judgment.done) <span class="keyword">break</span>;
    currentQuery = judgment.nextQuery; <span class="comment">// ä¸‹ä¸€è·³</span>
  }

  <span class="keyword">return</span> context;
}</code></pre>

  <h2>ğŸ“Š æŠ€æœ¯å¯¹æ¯” / Comparison</h2>
  <table>
    <tr>
      <th>æŠ€æœ¯</th>
      <th>è§£å†³çš„é—®é¢˜</th>
      <th>é¢å¤– LLM è°ƒç”¨</th>
      <th>å»¶è¿Ÿå½±å“</th>
      <th>é€‚ç”¨åœºæ™¯</th>
    </tr>
    <tr>
      <td><strong>Multi-Query</strong></td>
      <td>è¯æ±‡ä¸åŒ¹é…</td>
      <td>1 æ¬¡</td>
      <td>ä¸­ (å¤šæ¬¡æ£€ç´¢)</td>
      <td>é€šç”¨ï¼Œé»˜è®¤æ¨è</td>
    </tr>
    <tr>
      <td><strong>HyDE</strong></td>
      <td>query-doc é£æ ¼å·®å¼‚</td>
      <td>1 æ¬¡</td>
      <td>ä½ (1æ¬¡æ£€ç´¢)</td>
      <td>æŠ€æœ¯/å­¦æœ¯æ–‡æ¡£</td>
    </tr>
    <tr>
      <td><strong>Step-Back</strong></td>
      <td>é—®é¢˜å¤ªå…·ä½“/å¤ªçª„</td>
      <td>1 æ¬¡</td>
      <td>ä¸­ (2æ¬¡æ£€ç´¢)</td>
      <td>éœ€è¦èƒŒæ™¯çŸ¥è¯†</td>
    </tr>
    <tr>
      <td><strong>Self-Query</strong></td>
      <td>ç»“æ„åŒ–æ¡ä»¶è¢«å¿½ç•¥</td>
      <td>1 æ¬¡</td>
      <td>ä½</td>
      <td>æœ‰ metadata çš„ç³»ç»Ÿ</td>
    </tr>
    <tr>
      <td><strong>Multi-Hop</strong></td>
      <td>å¤šæ­¥æ¨ç†</td>
      <td>N æ¬¡</td>
      <td>é«˜</td>
      <td>å¤æ‚é—®é¢˜</td>
    </tr>
  </table>

  <h2>ğŸ”§ ç”Ÿäº§å®è·µ / Production Patterns</h2>

  <div class="highlight">
    <h4>ğŸ¯ ç»„åˆä½¿ç”¨ç­–ç•¥ (æ¨è)</h4>
    <p>è¿™äº›æŠ€æœ¯<strong>ä¸æ˜¯äº’æ–¥çš„</strong>ï¼Œç”Ÿäº§ç³»ç»Ÿé€šå¸¸ç»„åˆä½¿ç”¨ï¼š</p>
    <ol>
      <li><strong>Self-Query</strong> (å¿…é€‰) â€” å‡ ä¹æ‰€æœ‰ç³»ç»Ÿéƒ½éœ€è¦ metadata filtering</li>
      <li><strong>Multi-Query</strong> (æ¨è) â€” æˆæœ¬ä½ã€æ•ˆæœå¥½ã€é€šç”¨æ€§å¼º</li>
      <li><strong>HyDE/Step-Back</strong> (æŒ‰éœ€) â€” æ ¹æ®æ–‡æ¡£ç±»å‹é€‰æ‹©</li>
      <li><strong>Multi-Hop</strong> (å¤æ‚åœºæ™¯) â€” åªåœ¨éœ€è¦å¤šæ­¥æ¨ç†æ—¶å¯ç”¨</li>
    </ol>
  </div>

  <pre><code><span class="comment">// ç”Ÿäº§çº§ Retrieval Pipeline</span>
<span class="keyword">async function</span> <span class="func">productionRetrieve</span>(query: <span class="type">string</span>) {
  <span class="comment">// 1. Self-Query: æå– filter</span>
  <span class="keyword">const</span> { semanticQuery, filters } = <span class="keyword">await</span> <span class="func">extractFilters</span>(query);

  <span class="comment">// 2. Multi-Query: ç”Ÿæˆå˜ä½“</span>
  <span class="keyword">const</span> variants = <span class="keyword">await</span> <span class="func">generateVariants</span>(semanticQuery, 3);

  <span class="comment">// 3. å¹¶è¡Œæ£€ç´¢æ‰€æœ‰å˜ä½“ (å¸¦ filter)</span>
  <span class="keyword">const</span> results = <span class="keyword">await</span> Promise.<span class="func">all</span>(
    variants.<span class="func">map</span>(q => vectorStore.<span class="func">search</span>(q, { filter: filters, topK: 5 }))
  );

  <span class="comment">// 4. RRF èåˆ</span>
  <span class="keyword">const</span> merged = <span class="func">reciprocalRankFusion</span>(results);

  <span class="comment">// 5. Rerank (Day 1 è®²è¿‡)</span>
  <span class="keyword">return</span> reranker.<span class="func">rerank</span>(query, merged, { topK: 5 });
}</code></pre>

  <h2>ğŸ¤ é¢è¯•é¢˜ / Interview Questions</h2>

  <div class="interview">
    <h4>Q1: ä½ çš„ RAG ç³»ç»Ÿæ£€ç´¢æ•ˆæœå·®ï¼Œä½ ä¼šæ€ä¹ˆä¼˜åŒ–ï¼Ÿ</h4>
    <p><strong>æ ‡å‡†ç­”æ¡ˆæ¡†æ¶ï¼š</strong></p>
    <ol>
      <li><strong>å…ˆè¯Šæ–­</strong>ï¼šæ£€ç´¢ç»“æœ vs ç”¨æˆ·æœŸæœ› â€” æ˜¯æ‰¾ä¸åˆ° (recall) è¿˜æ˜¯æ‰¾é”™äº† (precision)ï¼Ÿ</li>
      <li><strong>Recall ä½</strong>ï¼šMulti-Query æ‰©å¤§æ£€ç´¢èŒƒå›´ã€HyDE æ¡¥æ¥è¯­ä¹‰é¸¿æ²Ÿã€Hybrid Search (BM25 + Vector)</li>
      <li><strong>Precision ä½</strong>ï¼šSelf-Query åŠ  metadata filterã€Rerankingã€æ”¹è¿› Chunking ç­–ç•¥</li>
      <li><strong>å¤æ‚æŸ¥è¯¢</strong>ï¼šStep-Back è·å–èƒŒæ™¯ã€Multi-Hop åˆ†æ­¥æ¨ç†</li>
      <li><strong>æˆæœ¬æƒè¡¡</strong>ï¼šæ¯ç§ä¼˜åŒ–éƒ½å¢åŠ  LLM è°ƒç”¨ï¼Œè¦æ ¹æ® latency budget é€‰æ‹©</li>
    </ol>
  </div>

  <div class="interview">
    <h4>Q2: HyDE çš„å±€é™æ€§æ˜¯ä»€ä¹ˆï¼Ÿä»€ä¹ˆæ—¶å€™ä¸åº”è¯¥ç”¨ï¼Ÿ</h4>
    <p><strong>ç­”</strong>ï¼š</p>
    <ul>
      <li>ä¾èµ– LLM å¯¹é¢†åŸŸçš„äº†è§£ â€” å¦‚æœ LLM å®Œå…¨ä¸æ‡‚è¯¥é¢†åŸŸï¼Œç”Ÿæˆçš„å‡æ–‡æ¡£æ²¡ç”¨</li>
      <li>å¢åŠ ä¸€æ¬¡ LLM è°ƒç”¨å»¶è¿Ÿ (é€šå¸¸ 200-500ms)</li>
      <li>å¯¹ç²¾ç¡®æŸ¥è¯¢ (exact match, æ—¥æœŸ, ID) åè€Œæœ‰å®³ â€” ä¼šå¼•å…¥å™ªéŸ³</li>
      <li>å¯¹å·²ç»å¾ˆå…·ä½“çš„ query æ”¹å–„ä¸å¤§ â€” ROI ä¸é«˜</li>
      <li><strong>æœ€ä½³å®è·µ</strong>ï¼šå®ç° query classifierï¼ŒçŸ­/ç²¾ç¡® query ç›´æ¥æ£€ç´¢ï¼Œé•¿/æ¨¡ç³Š query èµ° HyDE</li>
    </ul>
  </div>

  <div class="interview">
    <h4>Q3: è®¾è®¡ä¸€ä¸ª Agentic RAG ç³»ç»Ÿ â€” å®ƒå’Œä¼ ç»Ÿ RAG æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ</h4>
    <p><strong>ç­”</strong>ï¼š</p>
    <ul>
      <li><strong>ä¼ ç»Ÿ RAG</strong>: å›ºå®šæµç¨‹ (Retrieve â†’ Generate)ï¼Œä¸€æ¬¡æ£€ç´¢</li>
      <li><strong>Agentic RAG</strong>: Agent åŠ¨æ€å†³ç­– â€” è¦ä¸è¦æ£€ç´¢ï¼Ÿæ£€ç´¢ä»€ä¹ˆï¼Ÿå¤Ÿä¸å¤Ÿï¼Ÿè¦ä¸è¦å†æ¥ä¸€è½®ï¼Ÿ</li>
      <li>æ ¸å¿ƒç»„ä»¶ï¼šRouter (é€‰æ•°æ®æº) + Multi-Hop (è¿­ä»£) + Self-Reflection (è´¨é‡åˆ¤æ–­)</li>
      <li>å®ç°ï¼šæŠŠ retriever ä½œä¸º Tool ç»™ Agentï¼ŒAgent ç”¨ ReAct loop å†³å®šè°ƒç”¨</li>
      <li>æƒè¡¡ï¼šæ›´å¼ºå¤§ä½†å»¶è¿Ÿæ›´é«˜ã€æ›´éš¾é¢„æµ‹ã€éœ€è¦æ›´å¥½çš„ LLM</li>
    </ul>
  </div>

  <h2>ğŸ“š å¯å­¦ä¹ çš„æ¨¡å¼ / Patterns to Apply</h2>
  <div class="highlight">
    <h4>Pattern 1: Query Understanding Layer</h4>
    <p>æ‰€æœ‰é«˜çº§æ£€ç´¢éƒ½åœ¨åšåŒä¸€ä»¶äº‹ï¼šåœ¨æ£€ç´¢ä¹‹å‰åŠ ä¸€ä¸ª "query understanding" å±‚ã€‚è¿™ä¸ªæ¨¡å¼é€‚ç”¨äºä»»ä½•æœç´¢ç³»ç»Ÿï¼Œä¸åªæ˜¯ RAGã€‚</p>
  </div>
  <div class="highlight">
    <h4>Pattern 2: LLM as Query Optimizer</h4>
    <p>ä¼ ç»Ÿæœç´¢ç”¨è§„åˆ™åš query expansionï¼Œç°åœ¨ç”¨ LLMã€‚æ›´çµæ´»ä½†æ›´è´µã€‚å…³é”®å†³ç­–ï¼šå“ªäº›æŸ¥è¯¢å€¼å¾—è¿™ä¸ªé¢å¤–æˆæœ¬ï¼Ÿâ†’ ç”¨ classifier è·¯ç”±ã€‚</p>
  </div>
  <div class="highlight">
    <h4>Pattern 3: Iterative Refinement</h4>
    <p>Multi-Hop çš„ "æ£€ç´¢ â†’ åˆ¤æ–­ â†’ å†æ£€ç´¢" å¾ªç¯æ˜¯ Agent çš„æ ¸å¿ƒæ¨¡å¼ã€‚ä¸åªæ˜¯æ£€ç´¢ â€” ä»»ä½•éœ€è¦å¤šæ­¥ä¿¡æ¯æ”¶é›†çš„ä»»åŠ¡éƒ½é€‚ç”¨ã€‚</p>
  </div>

  <div class="follow-up">
    <h3>ğŸ’¬ åç»­è®¨è®º / Follow-up Discussion</h3>
    <p>æ˜å¤© Day 4 (æœ€åä¸€ç¯‡): <strong>Production RAG</strong> â€” è¯„ä¼°æŒ‡æ ‡ã€ç¼“å­˜ç­–ç•¥ã€æˆæœ¬ä¼˜åŒ–ã€Observabilityã€‚RAG ç³»åˆ—å®Œç»“ï¼</p>
    <p>æœ‰é—®é¢˜éšæ—¶é—®æˆ‘ âœ¨</p>
  </div>
</body>
</html>