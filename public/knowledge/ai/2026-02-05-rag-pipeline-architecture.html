<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <title>2026-02-05 - RAG System Design: Complete Pipeline Architecture</title>
  <style>
    body { font-family: -apple-system, system-ui, sans-serif; max-width: 900px; margin: 0 auto; padding: 20px; line-height: 1.6; }
    .bilingual { display: grid; grid-template-columns: 1fr 1fr; gap: 20px; }
    .zh { border-left: 3px solid #f9ab00; padding-left: 15px; }
    .en { border-left: 3px solid #1a73e8; padding-left: 15px; }
    h1 { color: #3c4043; border-bottom: 2px solid #f9ab00; padding-bottom: 10px; }
    h2 { color: #1a73e8; margin-top: 30px; }
    h3 { color: #5f6368; }
    .architecture { background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 20px 0; font-family: monospace; white-space: pre; overflow-x: auto; font-size: 13px; }
    pre { background: #1e1e1e; color: #d4d4d4; padding: 15px; border-radius: 8px; overflow-x: auto; font-size: 13px; }
    code { background: #f1f3f4; padding: 2px 6px; border-radius: 4px; font-size: 14px; }
    .highlight { background: #fff3cd; padding: 15px; border-radius: 8px; margin: 15px 0; }
    .tip { background: #e8f5e9; padding: 15px; border-radius: 8px; margin: 15px 0; border-left: 4px solid #4caf50; }
    .warning { background: #fff3e0; padding: 15px; border-radius: 8px; margin: 15px 0; border-left: 4px solid #ff9800; }
    .interview { background: #e3f2fd; padding: 15px; border-radius: 8px; margin: 15px 0; border-left: 4px solid #2196f3; }
    table { border-collapse: collapse; width: 100%; margin: 15px 0; }
    th, td { border: 1px solid #dadce0; padding: 10px; text-align: left; }
    th { background: #f8f9fa; }
    .series-badge { background: #1a73e8; color: white; padding: 4px 10px; border-radius: 12px; font-size: 12px; }
    .tag { display: inline-block; background: #e8f0fe; color: #1a73e8; padding: 2px 8px; border-radius: 4px; font-size: 12px; margin-right: 5px; }
  </style>
</head>
<body>
  <p><span class="series-badge">RAG ç³»åˆ— Day 1</span> <span class="tag">Phase 1.3</span> <span class="tag">é¢è¯•é«˜é¢‘</span></p>
  
  <h1>ğŸ” RAG System Design: Complete Pipeline Architecture</h1>
  <p>Retrieval-Augmented Generation ç³»ç»Ÿè®¾è®¡å…¨è§£</p>

  <h2>ğŸ“– ä»€ä¹ˆæ˜¯ RAGï¼Ÿ / What is RAG?</h2>
  <div class="bilingual">
    <div class="zh">
      <p><strong>Retrieval-Augmented Generation</strong> æ˜¯è§£å†³ LLM çŸ¥è¯†å±€é™æ€§çš„æ ¸å¿ƒæ¶æ„æ¨¡å¼ã€‚</p>
      <p>LLM çš„é—®é¢˜ï¼š</p>
      <ul>
        <li>çŸ¥è¯†æˆªæ­¢æ—¥æœŸ (training cutoff)</li>
        <li>æ— æ³•è®¿é—®ç§æœ‰/å®æ—¶æ•°æ®</li>
        <li>å¹»è§‰ (hallucination)</li>
        <li>æ— æ³•å¼•ç”¨æ¥æº</li>
      </ul>
      <p>RAG çš„è§£å†³æ–¹æ¡ˆï¼š<strong>å…ˆæ£€ç´¢ï¼Œå†ç”Ÿæˆ</strong>ã€‚æŠŠç›¸å…³æ–‡æ¡£ä½œä¸ºä¸Šä¸‹æ–‡å–‚ç»™ LLMï¼Œè®©å®ƒåŸºäºçœŸå®æ•°æ®å›ç­”ã€‚</p>
    </div>
    <div class="en">
      <p><strong>Retrieval-Augmented Generation</strong> is the core architectural pattern for addressing LLM knowledge limitations.</p>
      <p>LLM problems:</p>
      <ul>
        <li>Training cutoff date</li>
        <li>No access to private/real-time data</li>
        <li>Hallucinations</li>
        <li>Cannot cite sources</li>
      </ul>
      <p>RAG solution: <strong>Retrieve first, then generate</strong>. Feed relevant documents as context to let LLM answer based on real data.</p>
    </div>
  </div>

  <h2>ğŸ—ï¸ æ•´ä½“æ¶æ„ / Overall Architecture</h2>
  
  <div class="architecture">
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        RAG System Architecture                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    OFFLINE PIPELINE (Indexing)                   â”‚   â”‚
â”‚  â”‚                                                                   â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚  Data    â”‚â”€â”€â”€â–¶â”‚  Chunk   â”‚â”€â”€â”€â–¶â”‚ Embeddingâ”‚â”€â”€â”€â–¶â”‚  Vector  â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  Source  â”‚    â”‚  Split   â”‚    â”‚  Model   â”‚    â”‚   Store  â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â”‚      â”‚                                                â”‚          â”‚   â”‚
â”‚  â”‚      â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚          â”‚   â”‚
â”‚  â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Metadata â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚   â”‚
â”‚  â”‚                   â”‚  Store   â”‚                                   â”‚   â”‚
â”‚  â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    ONLINE PIPELINE (Query)                       â”‚   â”‚
â”‚  â”‚                                                                   â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚  User    â”‚â”€â”€â”€â–¶â”‚  Query   â”‚â”€â”€â”€â–¶â”‚  Hybrid  â”‚â”€â”€â”€â–¶â”‚ Reranker â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  Query   â”‚    â”‚ Embeddingâ”‚    â”‚ Retrievalâ”‚    â”‚          â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â”‚                                                        â”‚         â”‚   â”‚
â”‚  â”‚                                                        â–¼         â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚ Response â”‚â—€â”€â”€â”€â”‚   LLM    â”‚â—€â”€â”€â”€â”‚  Prompt  â”‚â—€â”€â”€â”€â”‚  Context â”‚   â”‚   â”‚
â”‚  â”‚  â”‚          â”‚    â”‚ Generate â”‚    â”‚ Template â”‚    â”‚ Assembly â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  </div>

  <h2>ğŸ“¥ Offline Pipeline: æ•°æ®æ‘„å…¥ä¸ç´¢å¼•</h2>
  
  <h3>Step 1: æ•°æ®åŠ è½½ (Data Loading)</h3>
  <div class="bilingual">
    <div class="zh">
      <p>æ”¯æŒå¤šç§æ•°æ®æºï¼š</p>
      <ul>
        <li><strong>ç»“æ„åŒ–</strong>: PDF, DOCX, HTML, Markdown</li>
        <li><strong>éç»“æ„åŒ–</strong>: ç½‘é¡µçˆ¬å–, API æ•°æ®</li>
        <li><strong>æ•°æ®åº“</strong>: SQL, NoSQL, æ—¥å¿—ç³»ç»Ÿ</li>
      </ul>
      <p>å…³é”®å†³ç­–ï¼š<strong>å¢é‡ vs å…¨é‡æ›´æ–°</strong>ã€‚ç”Ÿäº§ç¯å¢ƒå¿…é¡»æ”¯æŒå¢é‡ç´¢å¼•ã€‚</p>
    </div>
    <div class="en">
      <p>Support multiple data sources:</p>
      <ul>
        <li><strong>Structured</strong>: PDF, DOCX, HTML, Markdown</li>
        <li><strong>Unstructured</strong>: Web scraping, API data</li>
        <li><strong>Databases</strong>: SQL, NoSQL, log systems</li>
      </ul>
      <p>Key decision: <strong>Incremental vs Full rebuild</strong>. Production must support incremental indexing.</p>
    </div>
  </div>

  <h3>Step 2: æ–‡æ¡£åˆ†å— (Chunking) â­</h3>
  
  <div class="highlight">
    <strong>ğŸ¯ Chunking æ˜¯ RAG æœ€å…³é”®çš„è®¾è®¡å†³ç­–ä¹‹ä¸€ï¼</strong>
    <p>Chunk å¤ªå¤§ï¼šå™ªéŸ³å¤šï¼Œretrieval ä¸ç²¾ç¡®ï¼Œæµªè´¹ token</p>
    <p>Chunk å¤ªå°ï¼šä¸¢å¤±ä¸Šä¸‹æ–‡ï¼Œè¯­ä¹‰ä¸å®Œæ•´</p>
  </div>

  <table>
    <tr>
      <th>ç­–ç•¥</th>
      <th>ä¼˜ç‚¹</th>
      <th>ç¼ºç‚¹</th>
      <th>é€‚ç”¨åœºæ™¯</th>
    </tr>
    <tr>
      <td><strong>Fixed Size</strong><br>å›ºå®šé•¿åº¦</td>
      <td>ç®€å•ã€å¯é¢„æµ‹</td>
      <td>åˆ‡æ–­è¯­ä¹‰</td>
      <td>ç»“æ„åŒ–æ–‡æ¡£</td>
    </tr>
    <tr>
      <td><strong>Recursive</strong><br>é€’å½’åˆ†å‰²</td>
      <td>ä¿ç•™ç»“æ„</td>
      <td>ä¾èµ–åˆ†éš”ç¬¦</td>
      <td>Markdown, ä»£ç </td>
    </tr>
    <tr>
      <td><strong>Semantic</strong><br>è¯­ä¹‰åˆ†å—</td>
      <td>ä¿æŒè¯­ä¹‰å®Œæ•´</td>
      <td>è®¡ç®—å¼€é”€å¤§</td>
      <td>é•¿ç¯‡æ–‡ç« </td>
    </tr>
    <tr>
      <td><strong>Parent-Child</strong><br>çˆ¶å­åˆ†å—</td>
      <td>æ£€ç´¢ç»†ç²’åº¦<br>ä¸Šä¸‹æ–‡å®Œæ•´</td>
      <td>å¤æ‚åº¦é«˜</td>
      <td>ç²¾åº¦è¦æ±‚é«˜</td>
    </tr>
  </table>

  <pre><code>// Recursive Chunking ä¼ªä»£ç 
function recursiveChunk(text: string, chunkSize: number): string[] {
  const separators = ["\n\n", "\n", ". ", " "];  // æŒ‰ä¼˜å…ˆçº§
  
  for (const sep of separators) {
    const splits = text.split(sep);
    const chunks = mergeSplits(splits, chunkSize, sep);
    if (chunks.every(c => c.length <= chunkSize)) {
      return chunks;
    }
  }
  
  // Fallback: å¼ºåˆ¶æŒ‰å­—ç¬¦åˆ‡åˆ†
  return splitByChars(text, chunkSize);
}

// Parent-Child Chunking
interface Chunk {
  id: string;
  content: string;      // å° chunk ç”¨äºæ£€ç´¢
  parentId?: string;    // æŒ‡å‘å¤§ chunk
  parent?: string;      // å¤§ chunk å†…å®¹ç”¨äºç”Ÿæˆ
}

// æ£€ç´¢æ—¶: ç”¨å° chunk çš„ embedding åŒ¹é…
// ç”Ÿæˆæ—¶: è¿”å›å¯¹åº”çš„ parent chunk ç»™ LLM</code></pre>

  <div class="tip">
    <strong>ğŸ’¡ Best Practice: Chunk Overlap</strong>
    <p>è®¾ç½® 10-20% çš„é‡å  (overlap)ï¼Œé¿å…åœ¨è¾¹ç•Œå¤„ä¸¢å¤±å…³é”®ä¿¡æ¯ã€‚</p>
    <p>ä¾‹å¦‚ï¼šchunk_size=500, overlap=100</p>
  </div>

  <h3>Step 3: å‘é‡åŒ– (Embedding)</h3>
  <div class="bilingual">
    <div class="zh">
      <p><strong>Embedding æ¨¡å‹é€‰æ‹©</strong>æ˜¯æˆæœ¬ä¸è´¨é‡çš„æƒè¡¡ï¼š</p>
      <table>
        <tr><th>æ¨¡å‹</th><th>ç»´åº¦</th><th>ç‰¹ç‚¹</th></tr>
        <tr><td>OpenAI text-embedding-3-small</td><td>1536</td><td>æ€§ä»·æ¯”é«˜</td></tr>
        <tr><td>OpenAI text-embedding-3-large</td><td>3072</td><td>æœ€é«˜è´¨é‡</td></tr>
        <tr><td>Cohere embed-v3</td><td>1024</td><td>å¤šè¯­è¨€å¼º</td></tr>
        <tr><td>BGE-M3</td><td>1024</td><td>å¼€æºé¦–é€‰</td></tr>
        <tr><td>Voyage AI</td><td>1024</td><td>ä»£ç ä¸“ç”¨</td></tr>
      </table>
    </div>
    <div class="en">
      <p><strong>Embedding model selection</strong> is a cost vs quality trade-off:</p>
      <p>Key factors:</p>
      <ul>
        <li>Dimension size affects storage & latency</li>
        <li>Domain-specific models for code/legal/medical</li>
        <li>Multilingual support if needed</li>
        <li>Local vs API (cost, latency, privacy)</li>
      </ul>
    </div>
  </div>

  <h3>Step 4: å‘é‡å­˜å‚¨ (Vector Store)</h3>
  
  <table>
    <tr>
      <th>æ•°æ®åº“</th>
      <th>ç±»å‹</th>
      <th>æœ€é€‚åˆåœºæ™¯</th>
      <th>ç‰¹ç‚¹</th>
    </tr>
    <tr>
      <td><strong>Pinecone</strong></td>
      <td>Managed</td>
      <td>å¿«é€Ÿä¸Šæ‰‹ã€Serverless</td>
      <td>å…è¿ç»´ï¼Œè´µ</td>
    </tr>
    <tr>
      <td><strong>Weaviate</strong></td>
      <td>Self-hosted/Cloud</td>
      <td>Hybrid Search</td>
      <td>å†…ç½® BM25 + Vector</td>
    </tr>
    <tr>
      <td><strong>Chroma</strong></td>
      <td>Embedded</td>
      <td>å¼€å‘/å°å‹é¡¹ç›®</td>
      <td>ç®€å•ï¼ŒåµŒå…¥åº”ç”¨</td>
    </tr>
    <tr>
      <td><strong>pgvector</strong></td>
      <td>PostgreSQL æ‰©å±•</td>
      <td>å·²æœ‰ PG åŸºç¡€è®¾æ–½</td>
      <td>äº‹åŠ¡æ”¯æŒ</td>
    </tr>
    <tr>
      <td><strong>Qdrant</strong></td>
      <td>Self-hosted/Cloud</td>
      <td>é«˜æ€§èƒ½è¿‡æ»¤</td>
      <td>Rust å®ç°ï¼Œå¿«</td>
    </tr>
    <tr>
      <td><strong>Milvus</strong></td>
      <td>Self-hosted</td>
      <td>å¤§è§„æ¨¡ (10B+)</td>
      <td>åˆ†å¸ƒå¼ï¼Œå¤æ‚</td>
    </tr>
  </table>

  <h2>ğŸ” Online Pipeline: æŸ¥è¯¢ä¸ç”Ÿæˆ</h2>

  <h3>Step 1: Query å¤„ç†</h3>
  <div class="bilingual">
    <div class="zh">
      <p><strong>Query Transformation</strong> æ˜¯æå‡æ£€ç´¢è´¨é‡çš„å…³é”®ï¼š</p>
      <ol>
        <li><strong>Query Rewriting</strong>: è®© LLM æ”¹å†™ç”¨æˆ·é—®é¢˜ï¼Œä½¿å…¶æ›´é€‚åˆæ£€ç´¢</li>
        <li><strong>Query Expansion</strong>: ç”Ÿæˆå¤šä¸ªç›¸å…³æŸ¥è¯¢ï¼Œå¢åŠ å¬å›ç‡</li>
        <li><strong>HyDE</strong>: å…ˆç”Ÿæˆå‡è®¾ç­”æ¡ˆï¼Œç”¨ç­”æ¡ˆåšæ£€ç´¢</li>
      </ol>
    </div>
    <div class="en">
      <p><strong>Query Transformation</strong> is key to improving retrieval quality:</p>
      <ol>
        <li><strong>Query Rewriting</strong>: LLM rewrites user question for better retrieval</li>
        <li><strong>Query Expansion</strong>: Generate multiple related queries for recall</li>
        <li><strong>HyDE</strong>: Generate hypothetical answer first, retrieve with it</li>
      </ol>
    </div>
  </div>

  <pre><code>// HyDE (Hypothetical Document Embeddings)
async function hydeRetrieval(query: string) {
  // Step 1: LLM ç”Ÿæˆå‡è®¾æ€§ç­”æ¡ˆ
  const hypotheticalAnswer = await llm.generate(`
    Write a paragraph that would answer: "${query}"
    Be specific and detailed.
  `);
  
  // Step 2: ç”¨å‡è®¾ç­”æ¡ˆåšæ£€ç´¢ï¼ˆè¯­ä¹‰æ›´æ¥è¿‘çœŸå®æ–‡æ¡£ï¼‰
  const embedding = await embed(hypotheticalAnswer);
  const docs = await vectorStore.search(embedding, topK: 10);
  
  return docs;
}</code></pre>

  <h3>Step 2: Hybrid Retrieval â­</h3>
  
  <div class="highlight">
    <strong>ğŸ¯ æœ€ä½³å®è·µï¼šHybrid Search = Vector + Keyword</strong>
    <p>çº¯å‘é‡æ£€ç´¢çš„é—®é¢˜ï¼šå¯¹ä¸“æœ‰åè¯ã€IDã€ç²¾ç¡®åŒ¹é…ä¸å‹å¥½</p>
    <p>çº¯å…³é”®è¯çš„é—®é¢˜ï¼šæ— æ³•ç†è§£è¯­ä¹‰åŒä¹‰è¯</p>
    <p>è§£å†³æ–¹æ¡ˆï¼šä¸¤è€…ç»“åˆï¼Œåˆ†æ•°èåˆ</p>
  </div>

  <pre><code>// Hybrid Search with RRF (Reciprocal Rank Fusion)
async function hybridSearch(query: string, topK: number = 10) {
  // å¹¶è¡Œæ‰§è¡Œä¸¤ç§æ£€ç´¢
  const [vectorResults, bm25Results] = await Promise.all([
    vectorStore.search(await embed(query), topK * 2),
    bm25Index.search(query, topK * 2)
  ]);
  
  // RRF åˆ†æ•°èåˆ
  const k = 60;  // RRF å¸¸æ•°
  const scores = new Map&lt;string, number&gt;();
  
  vectorResults.forEach((doc, rank) => {
    const score = 1 / (k + rank + 1);
    scores.set(doc.id, (scores.get(doc.id) || 0) + score);
  });
  
  bm25Results.forEach((doc, rank) => {
    const score = 1 / (k + rank + 1);
    scores.set(doc.id, (scores.get(doc.id) || 0) + score);
  });
  
  // æŒ‰èåˆåˆ†æ•°æ’åº
  return Array.from(scores.entries())
    .sort((a, b) => b[1] - a[1])
    .slice(0, topK)
    .map(([id]) => getDocument(id));
}</code></pre>

  <h3>Step 3: Reranking</h3>
  <div class="bilingual">
    <div class="zh">
      <p><strong>ä¸¤é˜¶æ®µæ£€ç´¢</strong>æ˜¯ç”Ÿäº§ç³»ç»Ÿçš„æ ‡å‡†åšæ³•ï¼š</p>
      <ol>
        <li><strong>Stage 1 - å¬å›</strong>: å¿«é€Ÿæ£€ç´¢ top-100 å€™é€‰ï¼ˆæ¯«ç§’çº§ï¼‰</li>
        <li><strong>Stage 2 - ç²¾æ’</strong>: Cross-encoder é‡æ’ top-10ï¼ˆç™¾æ¯«ç§’çº§ï¼‰</li>
      </ol>
      <p>Cross-encoder æ¯” bi-encoder æ›´å‡†ï¼Œä½†æ›´æ…¢ã€‚æ‰€ä»¥åªç”¨äºç²¾æ’ã€‚</p>
    </div>
    <div class="en">
      <p><strong>Two-stage retrieval</strong> is standard in production:</p>
      <ol>
        <li><strong>Stage 1 - Recall</strong>: Fast retrieve top-100 candidates (ms)</li>
        <li><strong>Stage 2 - Rerank</strong>: Cross-encoder rerank top-10 (100ms)</li>
      </ol>
      <p>Cross-encoder is more accurate but slower. Use only for reranking.</p>
    </div>
  </div>

  <pre><code>// Reranking with Cohere or Cross-encoder
async function rerankResults(query: string, documents: Document[]) {
  // Option 1: Cohere Rerank API
  const reranked = await cohere.rerank({
    query,
    documents: documents.map(d => d.content),
    model: "rerank-english-v3.0",
    topN: 5
  });
  
  // Option 2: Local cross-encoder (e.g., sentence-transformers)
  // const reranked = await crossEncoder.rank(query, documents);
  
  return reranked.results.map(r => documents[r.index]);
}</code></pre>

  <h3>Step 4: Context Assembly & Prompt</h3>
  
  <pre><code>// Context Assembly æœ€ä½³å®è·µ
function assembleContext(docs: Document[], tokenBudget: number): string {
  let context = "";
  let usedTokens = 0;
  
  for (const doc of docs) {
    const docTokens = countTokens(doc.content);
    if (usedTokens + docTokens > tokenBudget) break;
    
    // åŒ…å«æ¥æºä¿¡æ¯ï¼Œä¾¿äºå¼•ç”¨
    context += `[Source: ${doc.metadata.source}]\n${doc.content}\n\n`;
    usedTokens += docTokens;
  }
  
  return context;
}

// RAG Prompt Template
const ragPrompt = `You are a helpful assistant. Answer the question based ONLY on the provided context.
If the context doesn't contain the answer, say "I don't have enough information to answer this."

Context:
{context}

Question: {question}

Instructions:
1. Answer based only on the context provided
2. If citing specific information, mention the source
3. If uncertain, express your uncertainty
4. Be concise but complete

Answer:`;</code></pre>

  <div class="warning">
    <strong>âš ï¸ å¸¸è§é™·é˜±ï¼šLost in the Middle</strong>
    <p>LLM å¯¹é•¿ context ä¸­é—´ä½ç½®çš„ä¿¡æ¯å…³æ³¨åº¦ä½ã€‚è§£å†³æ–¹æ¡ˆï¼š</p>
    <ul>
      <li>æŠŠæœ€ç›¸å…³çš„ chunks æ”¾åœ¨å¼€å¤´å’Œç»“å°¾</li>
      <li>æ§åˆ¶ context é•¿åº¦ï¼Œå®å°‘å‹¿å¤š</li>
      <li>ä½¿ç”¨ citation å¼ºåˆ¶ LLM å…³æ³¨æ‰€æœ‰æ¥æº</li>
    </ul>
  </div>

  <h2>ğŸ“Š è¯„ä¼°æŒ‡æ ‡ / Evaluation Metrics</h2>
  
  <div class="bilingual">
    <div class="zh">
      <p>RAG éœ€è¦è¯„ä¼°ä¸¤ä¸ªç»´åº¦ï¼š</p>
      <p><strong>æ£€ç´¢è´¨é‡</strong>ï¼š</p>
      <ul>
        <li>Recall@K - K ä¸ªç»“æœä¸­åŒ…å«æ­£ç¡®æ–‡æ¡£çš„æ¯”ä¾‹</li>
        <li>MRR - æ­£ç¡®æ–‡æ¡£çš„å¹³å‡å€’æ•°æ’å</li>
        <li>NDCG - æ’åºè´¨é‡</li>
      </ul>
      <p><strong>ç”Ÿæˆè´¨é‡</strong>ï¼š</p>
      <ul>
        <li>Faithfulness - ç­”æ¡ˆæ˜¯å¦åŸºäºæ£€ç´¢å†…å®¹</li>
        <li>Answer Relevance - ç­”æ¡ˆæ˜¯å¦å›ç­”äº†é—®é¢˜</li>
        <li>Context Relevance - æ£€ç´¢çš„å†…å®¹æ˜¯å¦ç›¸å…³</li>
      </ul>
    </div>
    <div class="en">
      <p>RAG needs evaluation on two dimensions:</p>
      <p><strong>Retrieval Quality</strong>:</p>
      <ul>
        <li>Recall@K - Fraction of relevant docs in top-K</li>
        <li>MRR - Mean Reciprocal Rank</li>
        <li>NDCG - Normalized Discounted Cumulative Gain</li>
      </ul>
      <p><strong>Generation Quality</strong>:</p>
      <ul>
        <li>Faithfulness - Is answer grounded in context?</li>
        <li>Answer Relevance - Does it answer the question?</li>
        <li>Context Relevance - Is retrieved content relevant?</li>
      </ul>
    </div>
  </div>

  <h2>ğŸ¯ é¢è¯•å¸¸è§é—®é¢˜ / Interview Questions</h2>
  
  <div class="interview">
    <h4>Q1: è®¾è®¡ä¸€ä¸ªä¼ä¸šçŸ¥è¯†åº“ RAG ç³»ç»Ÿï¼Œéœ€è¦è€ƒè™‘å“ªäº›æ–¹é¢ï¼Ÿ</h4>
    <p><strong>å‚è€ƒç­”æ¡ˆæ¡†æ¶</strong>ï¼š</p>
    <ol>
      <li><strong>æ•°æ®æ‘„å…¥</strong>ï¼šæ”¯æŒå¤šæ ¼å¼ï¼ˆPDFã€DOCXã€ç½‘é¡µï¼‰ï¼Œå¢é‡æ›´æ–°ï¼Œæƒé™æ§åˆ¶</li>
      <li><strong>Chunking</strong>ï¼šæ ¹æ®æ–‡æ¡£ç±»å‹é€‰æ‹©ç­–ç•¥ï¼ŒParent-Child æé«˜ç²¾åº¦</li>
      <li><strong>æ£€ç´¢</strong>ï¼šHybrid Search (BM25 + Vector)ï¼ŒMetadata è¿‡æ»¤ï¼ˆéƒ¨é—¨ã€æ—¶é—´ï¼‰</li>
      <li><strong>Reranking</strong>ï¼šCross-encoder ç²¾æ’ top 10</li>
      <li><strong>Generation</strong>ï¼šCitation è¦æ±‚ï¼Œæ‹’ç­”æœºåˆ¶ï¼Œæµå¼è¾“å‡º</li>
      <li><strong>è¯„ä¼°</strong>ï¼šå»ºç«‹ golden setï¼Œå®šæœŸè¯„ä¼° retrieval + generation</li>
    </ol>
  </div>

  <div class="interview">
    <h4>Q2: å¦‚ä½•å¤„ç† RAG ä¸­çš„ Hallucinationï¼Ÿ</h4>
    <p><strong>å‚è€ƒç­”æ¡ˆ</strong>ï¼š</p>
    <ol>
      <li><strong>æ£€ç´¢é˜¶æ®µ</strong>ï¼šæé«˜æ£€ç´¢è´¨é‡ï¼Œç¡®ä¿è¿”å›ç›¸å…³å†…å®¹</li>
      <li><strong>Prompt è®¾è®¡</strong>ï¼šå¼ºè°ƒ "only answer based on context"ï¼Œè¦æ±‚å¼•ç”¨æ¥æº</li>
      <li><strong>åå¤„ç†</strong>ï¼šNLI æ¨¡å‹éªŒè¯ç­”æ¡ˆæ˜¯å¦ä¸ context ä¸€è‡´</li>
      <li><strong>æ‹’ç­”æœºåˆ¶</strong>ï¼šconfidence ä½æ—¶æ˜ç¡®è¯´ "ä¸ç¡®å®š"</li>
      <li><strong>Citation</strong>ï¼šè¦æ±‚ inline citationï¼Œç”¨æˆ·å¯éªŒè¯</li>
    </ol>
  </div>

  <div class="interview">
    <h4>Q3: Chunk Size å¦‚ä½•é€‰æ‹©ï¼Ÿ</h4>
    <p><strong>å‚è€ƒç­”æ¡ˆ</strong>ï¼š</p>
    <ul>
      <li>é€šç”¨ï¼š500-1000 tokensï¼Œoverlap 10-20%</li>
      <li>ç²¾ç¡®é—®ç­”ï¼šå° chunk (200-300)ï¼ŒParent-Child æ¶æ„</li>
      <li>é•¿æ–‡æ¡£æ€»ç»“ï¼šå¤§ chunk (1500-2000)</li>
      <li>æœ€ä½³å®è·µï¼šA/B æµ‹è¯•ï¼Œç”¨è¯„ä¼°æŒ‡æ ‡é€‰æœ€ä¼˜</li>
    </ul>
  </div>

  <div class="interview">
    <h4>Q4: ä¸ºä»€ä¹ˆè¦ç”¨ Hybrid Search è€Œä¸æ˜¯çº¯ Vector Searchï¼Ÿ</h4>
    <p><strong>å‚è€ƒç­”æ¡ˆ</strong>ï¼š</p>
    <ul>
      <li>Vector Search å¯¹ä¸“æœ‰åè¯ã€IDã€ç²¾ç¡®åŒ¹é…ä¸å‹å¥½ï¼ˆ"iPhone 15" vs "iPhone 14"ï¼‰</li>
      <li>å…³é”®è¯æœç´¢å¯¹åŒä¹‰è¯ã€è¯­ä¹‰ç†è§£ä¸å‹å¥½</li>
      <li>Hybrid = ä¸¤è€…ä¼˜åŠ¿äº’è¡¥</li>
      <li>RRF æ˜¯å¸¸ç”¨çš„åˆ†æ•°èåˆæ–¹æ³•</li>
    </ul>
  </div>

  <h2>ğŸ“š RAG ç³»åˆ—é¢„å‘Š / Series Preview</h2>
  
  <table>
    <tr>
      <th>Day</th>
      <th>ä¸»é¢˜</th>
      <th>é‡ç‚¹</th>
    </tr>
    <tr>
      <td><strong>Day 1 (ä»Šå¤©)</strong></td>
      <td>RAG Pipeline å®Œæ•´æ¶æ„</td>
      <td>Offline/Online Pipeline, æ•´ä½“è®¾è®¡</td>
    </tr>
    <tr>
      <td>Day 2</td>
      <td>Advanced Chunking</td>
      <td>Semantic, Parent-Child, Agentic Chunking</td>
    </tr>
    <tr>
      <td>Day 3</td>
      <td>Advanced Retrieval</td>
      <td>Query Transformation, Self-Query, Multi-hop</td>
    </tr>
    <tr>
      <td>Day 4</td>
      <td>Production RAG</td>
      <td>Evaluation, Caching, Cost Optimization</td>
    </tr>
  </table>

  <div class="follow-up">
    <h3>ğŸ’¬ åç»­è®¨è®º / Follow-up Discussion</h3>
    <p>ä»»ä½•é—®é¢˜éƒ½å¯ä»¥é—®æˆ‘ï¼Œæˆ‘ä¼šè¡¥å……åœ¨è¿™é‡Œï¼</p>
    <ul>
      <li>æƒ³æ·±å…¥æŸä¸ªå…·ä½“ç»„ä»¶ï¼Ÿ</li>
      <li>æƒ³çœ‹å®é™…é¡¹ç›®æ¡ˆä¾‹ï¼Ÿ</li>
      <li>å¯¹ Aspen é¡¹ç›®æœ‰ RAG éœ€æ±‚ï¼Ÿ</li>
    </ul>
  </div>

  <hr>
  <p style="color: #5f6368; font-size: 14px;">
    ğŸ“… 2026-02-05 | ğŸ¤– Generated by Friday | ğŸ“ Phase 1.3 RAG ç³»ç»Ÿè®¾è®¡
  </p>
</body>
</html>
