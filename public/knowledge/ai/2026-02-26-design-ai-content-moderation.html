<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <title>2026-02-26 - è®¾è®¡ AI å†…å®¹å®¡æ ¸ç³»ç»Ÿ</title>
  <style>
    body { font-family: -apple-system, system-ui, sans-serif; max-width: 900px; margin: 0 auto; padding: 20px; line-height: 1.8; color: #1a1a1a; }
    .bilingual { display: grid; grid-template-columns: 1fr 1fr; gap: 20px; }
    .zh { border-left: 3px solid #f9ab00; padding-left: 15px; }
    .en { border-left: 3px solid #1a73e8; padding-left: 15px; }
    h1 { color: #3c4043; border-bottom: 2px solid #e8eaed; padding-bottom: 10px; }
    h2 { color: #1a73e8; margin-top: 40px; }
    h3 { color: #5f6368; }
    .architecture { background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 20px 0; }
    pre { background: #1e1e1e; color: #d4d4d4; padding: 15px; border-radius: 8px; overflow-x: auto; font-size: 13px; }
    code { font-family: 'SF Mono', Monaco, monospace; }
    .highlight { background: #fff3cd; padding: 15px; border-radius: 8px; margin: 15px 0; }
    .highlight-blue { background: #e8f0fe; padding: 15px; border-radius: 8px; margin: 15px 0; }
    .highlight-green { background: #e6f4ea; padding: 15px; border-radius: 8px; margin: 15px 0; }
    .highlight-red { background: #fce8e6; padding: 15px; border-radius: 8px; margin: 15px 0; }
    .diagram { background: #f0f0f0; padding: 20px; border-radius: 8px; margin: 20px 0; font-family: monospace; font-size: 13px; white-space: pre; overflow-x: auto; line-height: 1.4; }
    .interview { background: #fce8e6; padding: 15px; border-radius: 8px; margin: 15px 0; }
    .tag { display: inline-block; background: #e8eaed; padding: 2px 8px; border-radius: 4px; font-size: 12px; margin: 2px; }
    table { border-collapse: collapse; width: 100%; margin: 15px 0; }
    th, td { border: 1px solid #dadce0; padding: 10px; text-align: left; }
    th { background: #f8f9fa; }
    .series-nav { background: #e8f0fe; padding: 15px; border-radius: 8px; margin: 20px 0; }
    .metric { font-size: 24px; font-weight: bold; color: #1a73e8; }
    .warning { background: #fef9e7; border-left: 4px solid #f39c12; padding: 15px; border-radius: 4px; margin: 15px 0; }
    .success { background: #e6f4ea; border-left: 4px solid #34a853; padding: 15px; border-radius: 4px; margin: 15px 0; }
  </style>
</head>
<body>

<div class="series-nav">
  <strong>ğŸ“‹ AI System Design é¢è¯•é¢˜ç³»åˆ— | Phase 2.1 æœ€ç»ˆç¯‡ ğŸ‰</strong><br>
  <a href="2026-02-10-design-chatgpt-system.html">Day 1: è®¾è®¡ ChatGPT</a> â†’
  <a href="2026-02-11-design-recommendation-system.html">Day 2: è®¾è®¡æ¨èç³»ç»Ÿ</a> â†’
  <a href="2026-02-12-design-semantic-search-engine.html">Day 3: è®¾è®¡è¯­ä¹‰æœç´¢å¼•æ“</a> â†’
  <a href="2026-02-13-design-rag-knowledge-base.html">Day 4: è®¾è®¡ RAG çŸ¥è¯†åº“</a> â†’
  <a href="2026-02-14-design-ai-code-review-system.html">Day 5: è®¾è®¡ AI Code Review</a> â†’
  <strong>Day 6: è®¾è®¡ AI å†…å®¹å®¡æ ¸ç³»ç»Ÿ ğŸ¯</strong>
</div>

<h1>ğŸ›¡ï¸ è®¾è®¡ AI å†…å®¹å®¡æ ¸ç³»ç»Ÿ â€” System Design</h1>
<p><span class="tag">AI System Design</span> <span class="tag">Content Moderation</span> <span class="tag">Multi-Modal</span> <span class="tag">BERT</span> <span class="tag">CLIP</span> <span class="tag">Human-in-the-Loop</span> <span class="tag">é¢è¯•é«˜é¢‘</span></p>
<p>å‚è€ƒäº§å“: Meta/Facebook Content Review, YouTube Harmful Content Detection, TikTok Safety, Twitter/X Trust &amp; Safety</p>

<h2>ğŸ“– é¢˜ç›® / Problem Statement</h2>
<div class="bilingual">
  <div class="zh">
    <p><strong>é¢è¯•å®˜ï¼š</strong>è¯·è®¾è®¡ä¸€ä¸ª AI å†…å®¹å®¡æ ¸ç³»ç»Ÿï¼Œåƒ Facebook/Meta é‚£æ ·ï¼Œåœ¨å¹³å°æ¯å¤© 100 äº¿+ æ¡å†…å®¹ä¸­ï¼Œè‡ªåŠ¨æ£€æµ‹å¹¶å¤„ç†è¿è§„å†…å®¹ï¼ˆæš´åŠ›ã€è‰²æƒ…ã€ä»‡æ¨è¨€è®ºã€åƒåœ¾ä¿¡æ¯ã€CSAM ç­‰ï¼‰ã€‚</p>
    <p><strong>æ ¸å¿ƒéœ€æ±‚ï¼š</strong></p>
    <ul>
      <li>æ¯å¤©å¤„ç† 1000 äº¿+ æ¡å†…å®¹ï¼ˆæ–‡å­—ã€å›¾ç‰‡ã€è§†é¢‘ã€éŸ³é¢‘ï¼‰</li>
      <li>ä¸Šä¼ æ—¶é¢„å®¡æ ¸å»¶è¿Ÿ &lt;500msï¼ˆç”¨æˆ·æ„ŸçŸ¥ï¼‰</li>
      <li>å¤šæ¨¡æ€æ”¯æŒï¼šæ–‡æœ¬ã€å›¾ç‰‡ï¼ˆ1000ä¸‡/å¤©ï¼‰ã€è§†é¢‘ã€éŸ³é¢‘</li>
      <li>å¤šè¯­è¨€æ”¯æŒï¼ˆ100+ ç§è¯­è¨€ï¼‰</li>
      <li>æ”¯æŒäººå·¥å¤æ ¸é˜Ÿåˆ— + ç”³è¯‰æœºåˆ¶</li>
      <li>æ”¯æŒæ”¿ç­–ç‰ˆæœ¬ç®¡ç†ï¼ˆå„åœ°åŒºæ³•è§„ä¸åŒï¼‰</li>
      <li>è¯¯åˆ¤ç‡ &lt;0.1%ï¼Œå¬å›ç‡ &gt;99.9%ï¼ˆCSAMï¼‰</li>
    </ul>
  </div>
  <div class="en">
    <p><strong>Interviewer:</strong> Design an AI content moderation system like Facebook/Meta â€” one that can automatically detect and handle violating content (violence, nudity, hate speech, spam, CSAM, etc.) across 100B+ pieces of content per day.</p>
    <p><strong>Core requirements:</strong></p>
    <ul>
      <li>100B+ pieces/day (text, image, video, audio)</li>
      <li>Upload-gate pre-screening latency &lt;500ms</li>
      <li>Multi-modal: text, images (10M/day), video, audio</li>
      <li>100+ language support</li>
      <li>Human review queue + appeals mechanism</li>
      <li>Policy versioning (different jurisdictions)</li>
      <li>False positive rate &lt;0.1%, recall &gt;99.9% (CSAM)</li>
    </ul>
  </div>
</div>

<h2>ğŸ—ï¸ é«˜å±‚æ¶æ„ / High-Level Architecture</h2>

<div class="diagram">
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           CLIENT UPLOAD LAYER                                  â”‚
â”‚   Mobile App / Web Browser / Third-Party API                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚ Upload Request
                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     API GATEWAY / UPLOAD SERVICE                               â”‚
â”‚   Rate Limiting â”‚ Auth â”‚ Content Hashing (SHA-256 + pHash) â”‚ Dedup             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                  â”‚
               â–¼                  â–¼
    [Known-Bad Hash DB]    [New Content â†’ Pipeline]
    (PhotoDNA / CSAM)       immediate block
               â”‚                  â”‚
               â”‚    SYNC (<500ms) â–¼
               â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚   â”‚     PRE-SCREEN GATE (Real-Time)           â”‚
               â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
               â”‚   â”‚  â”‚ Text    â”‚ â”‚  Image   â”‚ â”‚  Video   â”‚  â”‚
               â”‚   â”‚  â”‚ FastTextâ”‚ â”‚  CLIP /  â”‚ â”‚  Frame   â”‚  â”‚
               â”‚   â”‚  â”‚ Distil  â”‚ â”‚  CNN     â”‚ â”‚  Sample  â”‚  â”‚
               â”‚   â”‚  â”‚ BERT    â”‚ â”‚  pHash   â”‚ â”‚  + Audio â”‚  â”‚
               â”‚   â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚
               â”‚   â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
               â”‚   â”‚            Combined Score                 â”‚
               â”‚   â”‚     HIGH RISK â†’ Block / Flag              â”‚
               â”‚   â”‚     LOW RISK  â†’ Allow (async review)      â”‚
               â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                         â”‚
               â”‚         ASYNC â–¼         â”‚ PUBLISH TO PLATFORM
               â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚   â”‚     DEEP ANALYSIS PIPELINE (Async)        â”‚
               â”‚   â”‚                                          â”‚
               â”‚   â”‚  Context Engine   Policy Engine          â”‚
               â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
               â”‚   â”‚  â”‚ User Historyâ”‚  â”‚ Harm Taxonomy DB â”‚  â”‚
               â”‚   â”‚  â”‚ Network     â”‚  â”‚ Region Rules     â”‚  â”‚
               â”‚   â”‚  â”‚ Account Age â”‚  â”‚ Policy Versions  â”‚  â”‚
               â”‚   â”‚  â”‚ Prior Viol. â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
               â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
               â”‚   â”‚                                          â”‚
               â”‚   â”‚  Multi-Modal Fusion Model                â”‚
               â”‚   â”‚  (Text + Image + Context â†’ Decision)     â”‚
               â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                  â”‚
               â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚          â”‚  Decision Engine  â”‚
               â”‚          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
               â”‚          â”‚  â”‚ ALLOW       â”‚  â”‚
               â”‚          â”‚  â”‚ RESTRICT    â”‚  â”‚  â† apply label/limit reach
               â”‚          â”‚  â”‚ REMOVE      â”‚  â”‚
               â”‚          â”‚  â”‚ HUMAN_QUEUE â”‚  â”‚
               â”‚          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
               â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                  â”‚
               â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚          â”‚  HUMAN REVIEW SYSTEM          â”‚
               â”‚          â”‚  Priority Queue (sev Ã— viral) â”‚
               â”‚          â”‚  Reviewer Tool UI             â”‚
               â”‚          â”‚  QA Sampling + Calibration    â”‚
               â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                           â”‚
               â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
               â””â”€â”€â”€â”€ APPEALS â”€â”€â”€â”€â”€â”€â”€â”‚   ACTION    â”‚
                                    â”‚   LOGGING   â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</div>

<div class="highlight-blue">
  <strong>ğŸ’¡ é¢è¯•å…³é”®å¼€åœºç™½ï¼š</strong>å…ˆæ¾„æ¸…åœºæ™¯å’Œçº¦æŸã€‚<br>
  "å†…å®¹å®¡æ ¸ç³»ç»Ÿçš„æ ¸å¿ƒçŸ›ç›¾æ˜¯ï¼šè¯¯åˆ¤å¸¦æ¥çš„ç”¨æˆ·ä¼¤å®³ vs æ¼åˆ¤å¸¦æ¥çš„å¹³å°ä¼¤å®³ã€‚ä¸åŒå†…å®¹ç±»å‹æœ‰ä¸åŒçš„å®¹å¿åº¦â€”â€”CSAM è¦æ±‚æ¥è¿‘ 100% å¬å›ï¼ˆå®å¯é”™æ€ï¼‰ï¼Œè€Œå¹½é»˜ä¸ä»‡æ¨è¨€è®ºçš„è¾¹ç•Œåˆ™éœ€è¦ä¸Šä¸‹æ–‡åˆ¤æ–­ã€‚"
</div>

<h2>ğŸ“Š å®¹é‡ä¼°ç®— / Capacity Estimation</h2>

<div class="bilingual">
  <div class="zh">
    <h3>Meta è§„æ¨¡ä¼°ç®—</h3>
    <ul>
      <li><strong>å†…å®¹æ€»é‡ï¼š</strong>100B æ¡/å¤© â‰ˆ 1.16M QPS</li>
      <li><strong>å›¾ç‰‡ï¼š</strong>10M/å¤© â‰ˆ 115 QPSï¼ˆæ·±åº¦åˆ†æï¼‰</li>
      <li><strong>è§†é¢‘ï¼š</strong>1M/å¤© â‰ˆ 11.5 QPSï¼ˆå¸§æŠ½å–+åˆ†æï¼‰</li>
      <li><strong>ä¸Šä¼ é¢„å®¡æ ¸ SLAï¼š</strong>&lt;500ms P99</li>
      <li><strong>æ·±åº¦å¼‚æ­¥åˆ†æï¼š</strong>&lt;30s å®Œæˆ</li>
      <li><strong>äººå·¥å®¡æ ¸é˜Ÿåˆ—ï¼š</strong>æ¯å¤©çº¦ 1%â†’100M éœ€è¦äººå·¥ä»‹å…¥ï¼ˆä½†å®é™…äººå·¥å®¡æ ¸çº¦ 1500ä¸‡/å‘¨ï¼‰</li>
      <li><strong>å­˜å‚¨ï¼š</strong>æ¯æ¡å†³ç­–è®°å½• ~1KB â†’ 100GB/å¤©å†³ç­–æ—¥å¿—</li>
    </ul>
    <h3>æœºå™¨èµ„æº</h3>
    <ul>
      <li>è½»é‡ FastText æ¨¡å‹ï¼š1M QPS éœ€ ~2000 CPU æ ¸</li>
      <li>BERT åˆ†ç±»å™¨ï¼ˆå¼‚æ­¥ï¼‰ï¼š~1000 GPU å®ä¾‹ï¼ˆA100ï¼‰</li>
      <li>å›¾ç‰‡ CNN/CLIPï¼š~500 GPU å®ä¾‹</li>
      <li>è§†é¢‘å¸§æŠ½å–ï¼šCPU å¯†é›†å‹ï¼Œ~500 é«˜æ ¸æ•°å®ä¾‹</li>
    </ul>
  </div>
  <div class="en">
    <h3>Meta-Scale Estimation</h3>
    <ul>
      <li><strong>Total content:</strong> 100B/day â‰ˆ 1.16M QPS</li>
      <li><strong>Images:</strong> 10M/day â‰ˆ 115 QPS (deep analysis)</li>
      <li><strong>Video:</strong> 1M/day â‰ˆ 11.5 QPS (frame extract + analysis)</li>
      <li><strong>Upload gate SLA:</strong> &lt;500ms P99</li>
      <li><strong>Async deep analysis:</strong> &lt;30s to complete</li>
      <li><strong>Human review queue:</strong> ~1% flagged = 1B/day; actual human review ~15M/week</li>
      <li><strong>Storage:</strong> ~1KB per decision record â†’ 100GB/day decision logs</li>
    </ul>
    <h3>Hardware Resources</h3>
    <ul>
      <li>Lightweight FastText: 1M QPS â†’ ~2000 CPU cores</li>
      <li>BERT classifiers (async): ~1000 GPU instances (A100)</li>
      <li>Image CNN/CLIP: ~500 GPU instances</li>
      <li>Video frame extraction: CPU-intensive, ~500 high-core servers</li>
    </ul>
  </div>
</div>

<div class="diagram">
  æ€è€ƒé¢˜ç­”æ¡ˆï¼šè¯¯åˆ¤ç‡ 0.1% Ã— DAU 10äº¿ Ã— æ¯äººå‘å¸–1æ¡ = æ¯å¤© 100ä¸‡æ¡å†…å®¹è¢«é”™è¯¯ä¸‹æ¶ï¼
  â†“
  å¿…é¡»æœ‰é«˜æ•ˆç”³è¯‰ç³»ç»Ÿï¼å¦åˆ™ç”¨æˆ·æµå¤±ä¸å¯é¿å…ã€‚
</div>

<h2>ğŸš¦ å¤šé˜¶æ®µå®¡æ ¸ Pipeline / Multi-Stage Moderation Pipeline</h2>

<div class="bilingual">
  <div class="zh">
    <h3>ä¸‰é˜¶æ®µè®¾è®¡</h3>
    <p>å†…å®¹å®¡æ ¸ä¸èƒ½åªé ä¸€ä¸ªæ¨¡å‹ã€‚å…³é”®æ˜¯<strong>é€Ÿåº¦ä¸å‡†ç¡®æ€§çš„åˆ†å±‚æƒè¡¡</strong>ï¼š</p>
    <ol>
      <li><strong>Stage 1ï¼šä¸Šä¼ é—¨æ§ (åŒæ­¥, &lt;500ms)</strong> â€” å¿«é€Ÿè½»é‡æ¨¡å‹ï¼Œå®ˆä½æ˜æ˜¾è¿è§„</li>
      <li><strong>Stage 2ï¼šæ·±åº¦å¼‚æ­¥åˆ†æ (å¼‚æ­¥, &lt;30s)</strong> â€” é‡å‹æ¨¡å‹+ä¸Šä¸‹æ–‡ï¼Œé«˜ç²¾åº¦å†³ç­–</li>
      <li><strong>Stage 3ï¼šäººå·¥å¤æ ¸ (å¼‚æ­¥, æŒ‰ SLA åˆ†çº§)</strong> â€” å¤„ç†è¾¹ç¼˜æ¡ˆä¾‹å’Œç”³è¯‰</li>
    </ol>
  </div>
  <div class="en">
    <h3>Three-Stage Design</h3>
    <p>Content moderation cannot rely on a single model. The key is <strong>layered speed-accuracy tradeoff</strong>:</p>
    <ol>
      <li><strong>Stage 1: Upload Gate (sync, &lt;500ms)</strong> â€” Fast lightweight models, block obvious violations</li>
      <li><strong>Stage 2: Deep Async Analysis (async, &lt;30s)</strong> â€” Heavy models + context, high-precision decisions</li>
      <li><strong>Stage 3: Human Review (async, SLA-tiered)</strong> â€” Edge cases and appeals</li>
    </ol>
  </div>
</div>

<div class="diagram">
  Stage 1: Upload Gate (Sync, &lt;500ms)
  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Input Content
       â”‚
       â”œâ”€â”€â”€ Hash Lookup â”€â”€â”€â”€â”€â”€â–º Known-Bad DB (PhotoDNA/CSAM hashes) â†’ BLOCK immediately
       â”‚
       â”œâ”€â”€â”€ Text FastText â”€â”€â”€â–º 99 language classifier, confidence â‰¥ 0.95 â†’ BLOCK
       â”‚
       â”œâ”€â”€â”€ Image pHash â”€â”€â”€â”€â”€â–º Near-duplicate matching vs flagged image DB
       â”‚
       â””â”€â”€â”€ Image FastCNN â”€â”€â–º MobileNet/EfficientNet-Lite, <100ms â†’ High-confidence NSFW/Violence

  Decision matrix:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Score            â”‚ Action                              â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ â‰¥ 0.95           â”‚ BLOCK (don't publish, alert user)   â”‚
  â”‚ 0.7 ~ 0.95       â”‚ ALLOW + FLAG for async deep review  â”‚
  â”‚ < 0.7            â”‚ ALLOW (may still get async review)  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  Stage 2: Deep Analysis (Async, &lt;30s)
  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Content + Stage 1 Score + User Context
       â”‚
       â”œâ”€â”€â”€ BERT Fine-tuned Classifier (multilingual)
       â”‚     â””â”€ Hate Speech / Harassment / Radicalization
       â”‚
       â”œâ”€â”€â”€ CLIP-based Image Analysis
       â”‚     â””â”€ Semantic understanding: "protest sign" vs "hate symbol"
       â”‚
       â”œâ”€â”€â”€ Multi-modal Fusion Model
       â”‚     â””â”€ Cross-modal consistency: text says "recipe" but image shows violence
       â”‚
       â”œâ”€â”€â”€ Context Engine
       â”‚     â””â”€ User history, account age, network graph
       â”‚
       â””â”€â”€â”€ Policy Engine
             â””â”€ Region-specific rules, harm taxonomy lookup

  Decision â†’ { ALLOW, SOFT_RESTRICT, REMOVE, HUMAN_QUEUE, ESCALATE }

  Stage 3: Human Review Queue
  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Priority = Severity Ã— Virality Ã— Account_Risk_Score
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ P0       â”‚ CSAM, terrorism incitement â†’ 15min SLA  â”‚
  â”‚ P1       â”‚ Violence/Graphic â†’ 2hr SLA              â”‚
  â”‚ P2       â”‚ Hate speech / Harassment â†’ 24hr SLA     â”‚
  â”‚ P3       â”‚ Spam / General â†’ 48hr SLA               â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</div>

<h2>ğŸ¤– ML æ¨¡å‹è®¾è®¡ / ML Model Architecture</h2>

<h3>ğŸ“ æ–‡æœ¬å®¡æ ¸æ¨¡å‹</h3>

<div class="bilingual">
  <div class="zh">
    <p><strong>ä¸¤çº§æ–‡æœ¬åˆ†ç±»æ¶æ„ï¼š</strong></p>
    <ul>
      <li><strong>Stage 1 (Fast)ï¼š</strong>FastText + n-gramï¼Œå»¶è¿Ÿ &lt;5msï¼Œæ”¯æŒ 176 ç§è¯­è¨€ï¼Œç”¨äºåˆç­›</li>
      <li><strong>Stage 2 (Accurate)ï¼š</strong>XLM-RoBERTa Large fine-tunedï¼Œå¤šæ ‡ç­¾åˆ†ç±»ï¼ˆæ¯æ¡å†…å®¹å¯åŒæ—¶å±äºå¤šä¸ªç±»åˆ«ï¼‰</li>
    </ul>
    <p><strong>å…³é”®æŒ‘æˆ˜ï¼š</strong></p>
    <ul>
      <li>å¯¹æŠ—æ€§å˜ä½“ï¼šleet speakï¼ˆh4teï¼‰ï¼ŒUnicode æ··æ·†ï¼ˆÎ—ateï¼‰ï¼Œæ•…æ„æ‹¼å†™é”™è¯¯</li>
      <li>è§£å†³ï¼šCharacter-level CNN + Unicode normalization + åŒä¹‰è¯å¢å¼º</li>
      <li>éšè¯­å’Œæš—è¯­éšæ—¶é—´å˜åŒ– â†’ æŒç»­åœ¨çº¿å­¦ä¹ </li>
    </ul>
  </div>
  <div class="en">
    <p><strong>Two-tier text classification:</strong></p>
    <ul>
      <li><strong>Stage 1 (Fast):</strong> FastText + n-gram, &lt;5ms latency, 176 languages, initial screening</li>
      <li><strong>Stage 2 (Accurate):</strong> XLM-RoBERTa Large fine-tuned, multi-label classification (content can belong to multiple categories simultaneously)</li>
    </ul>
    <p><strong>Key challenges:</strong></p>
    <ul>
      <li>Adversarial variants: leet speak (h4te), Unicode obfuscation (Î—ate), intentional misspellings</li>
      <li>Solution: Character-level CNN + Unicode normalization + synonym augmentation</li>
      <li>Slang/dog-whistles evolve â†’ continuous online learning</li>
    </ul>
  </div>
</div>

<pre><code># æ–‡æœ¬åˆ†ç±»å™¨æ¶æ„ï¼ˆfine-tuned XLM-RoBERTaï¼‰
class ContentClassifier(nn.Module):
    def __init__(self, model_name="xlm-roberta-large", num_labels=12):
        super().__init__()
        self.encoder = AutoModel.from_pretrained(model_name)
        self.dropout = nn.Dropout(0.1)
        # å¤šæ ‡ç­¾åˆ†ç±»ï¼šæ¯ä¸ªæ ‡ç­¾ç‹¬ç«‹ sigmoidï¼ˆä¸äº’æ–¥ï¼‰
        self.classifier = nn.Linear(self.encoder.config.hidden_size, num_labels)
        self.harm_taxonomy = [
            "hate_speech", "violence", "nudity_sexual",
            "nudity_non_sexual", "harassment", "spam",
            "misinformation", "self_harm", "terrorism",
            "csam", "dangerous_activity", "drug_content"
        ]
    
    def forward(self, input_ids, attention_mask, context_embedding=None):
        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)
        pooled = outputs.last_hidden_state[:, 0, :]  # [CLS] token
        
        # æ³¨å…¥ç”¨æˆ·ä¸Šä¸‹æ–‡åµŒå…¥ï¼ˆå¯é€‰ï¼‰
        if context_embedding is not None:
            pooled = torch.cat([pooled, context_embedding], dim=-1)
            pooled = self.context_proj(pooled)
        
        logits = self.classifier(self.dropout(pooled))
        probs = torch.sigmoid(logits)  # å¤šæ ‡ç­¾ï¼Œå„æ ‡ç­¾ç‹¬ç«‹æ¦‚ç‡
        return probs  # shape: [batch, 12]

# æ¨ç†ï¼šæ‰¹é‡å¤„ç†ä»¥æé«˜ GPU åˆ©ç”¨ç‡
def batch_classify_text(texts: List[str], batch_size=64) -> List[Dict]:
    results = []
    for batch in chunks(texts, batch_size):
        inputs = tokenizer(batch, truncation=True, max_length=512,
                          padding=True, return_tensors="pt")
        with torch.no_grad():
            probs = model(**inputs)
        
        for text, prob in zip(batch, probs):
            violations = {
                label: float(p) 
                for label, p in zip(model.harm_taxonomy, prob)
                if p > 0.3  # ä½é˜ˆå€¼ç”¨äºæ ‡è®°ï¼Œé«˜é˜ˆå€¼ç”¨äºæ‰§è¡Œ
            }
            results.append({"text": text[:100], "violations": violations})
    return results
</code></pre>

<h3>ğŸ–¼ï¸ å›¾åƒå®¡æ ¸æ¨¡å‹</h3>

<div class="bilingual">
  <div class="zh">
    <p><strong>å›¾åƒä¸‰å±‚é˜²çº¿ï¼š</strong></p>
    <ol>
      <li><strong>æ„ŸçŸ¥å“ˆå¸Œ (pHash/PhotoDNA)ï¼š</strong>O(1) æŸ¥æ‰¾å·²çŸ¥è¿è§„å†…å®¹ï¼ŒæŠ—è½»å¾®ç¼–è¾‘å˜å½¢ï¼ˆå‹ç¼©ã€è£å‰ªï¼‰</li>
      <li><strong>CNN åˆ†ç±»å™¨ (EfficientNet-B4)ï¼š</strong>è§†è§‰å†…å®¹åˆ†ç±»ï¼ŒNSFW/æš´åŠ›/ä»‡æ¨ç¬¦å·</li>
      <li><strong>CLIP-based è¯­ä¹‰ç†è§£ï¼š</strong>ç†è§£å›¾ç‰‡è¯­ä¹‰å’Œæ–‡å­—+å›¾ç‰‡çš„ç»„åˆå«ä¹‰</li>
    </ol>
    <p><strong>CLIP çš„æ ¸å¿ƒä»·å€¼ï¼š</strong>å¯ä»¥åš Zero-shot æ£€æµ‹æ–°çš„ä¼¤å®³ç±»å‹ï¼Œæ— éœ€é‡æ–°è®­ç»ƒã€‚ä¾‹å¦‚æ–°å…´çš„ä»‡æ¨ç¬¦å·ã€æ”¿æ²»æ¢—å›¾ã€‚</p>
  </div>
  <div class="en">
    <p><strong>Three-layer image defense:</strong></p>
    <ol>
      <li><strong>Perceptual Hash (pHash/PhotoDNA):</strong> O(1) lookup for known violations, robust to minor edits (compression, cropping)</li>
      <li><strong>CNN classifier (EfficientNet-B4):</strong> Visual content classification â€” NSFW/violence/hate symbols</li>
      <li><strong>CLIP-based semantic understanding:</strong> Understand image semantics and text+image combined meaning</li>
    </ol>
    <p><strong>CLIP's key value:</strong> Zero-shot detection of new harm types without retraining. E.g., emerging hate symbols, political memes.</p>
  </div>
</div>

<pre><code># CLIP-based å†…å®¹å®¡æ ¸
import clip
import torch
from PIL import Image

class CLIPModerator:
    def __init__(self):
        self.model, self.preprocess = clip.load("ViT-L/14", device="cuda")
        
        # ä¼¤å®³ç±»åˆ«çš„æ–‡æœ¬æè¿°ï¼ˆZero-shotï¼‰
        self.harm_prompts = {
            "hate_symbol": [
                "an image containing hate symbols or extremist imagery",
                "a photo with white supremacist symbols",
                "neo-nazi propaganda imagery"
            ],
            "violence": [
                "graphic violence or gore",
                "people fighting or being harmed",
                "blood and injury"
            ],
            "safe": [
                "a normal everyday photo",
                "a family friendly image",
                "a safe and appropriate picture"
            ]
        }
        
        # é¢„è®¡ç®—æ–‡æœ¬åµŒå…¥ï¼ˆç¦»çº¿ï¼Œåªåšä¸€æ¬¡ï¼‰
        self.text_embeddings = self._precompute_text_embeddings()
    
    def _precompute_text_embeddings(self):
        embeddings = {}
        for category, prompts in self.harm_prompts.items():
            tokens = clip.tokenize(prompts).to("cuda")
            with torch.no_grad():
                text_feat = self.model.encode_text(tokens)
                text_feat /= text_feat.norm(dim=-1, keepdim=True)
            embeddings[category] = text_feat.mean(dim=0)  # å¹³å‡å¤šä¸ª prompt
        return embeddings
    
    def moderate(self, image: Image.Image) -> Dict[str, float]:
        image_input = self.preprocess(image).unsqueeze(0).to("cuda")
        
        with torch.no_grad():
            image_feat = self.model.encode_image(image_input)
            image_feat /= image_feat.norm(dim=-1, keepdim=True)
        
        scores = {}
        for category, text_feat in self.text_embeddings.items():
            similarity = (100.0 * image_feat @ text_feat.unsqueeze(0).T).item()
            scores[category] = float(torch.sigmoid(torch.tensor(similarity / 10)))
        
        return scores  # {"hate_symbol": 0.02, "violence": 0.85, "safe": 0.12}
</code></pre>

<h3>ğŸ¬ è§†é¢‘å®¡æ ¸ç­–ç•¥</h3>

<div class="bilingual">
  <div class="zh">
    <p>è§†é¢‘ = å›¾åƒåºåˆ— + éŸ³é¢‘ã€‚ä¸èƒ½é€å¸§å¤„ç†ï¼Œè¦æ™ºèƒ½é‡‡æ ·ï¼š</p>
    <ul>
      <li><strong>å…³é”®å¸§æŠ½å–ï¼š</strong>Scene Change Detection (ä½™å¼¦è·ç¦» &gt;0.3 â†’ æ–°åœºæ™¯)ï¼Œå¹³å‡æ¯30ç§’1å¸§</li>
      <li><strong>éŸ³é¢‘åˆ†æï¼š</strong>Whisper è½¬å½• â†’ æ–‡æœ¬åˆ†ç±»ï¼›åŒæ—¶åšå£°å­¦åˆ†æï¼ˆæªå£°ã€å°–å«å£°ï¼‰</li>
      <li><strong>æ—¶åºæ¨¡å‹ï¼š</strong>VIDEO-BERT / TimeSformer æ£€æµ‹è·¨å¸§çš„è¿ç»­åŠ¨ä½œï¼ˆæ‰“æ–—åºåˆ—ï¼‰</li>
      <li><strong>å®æ—¶é™åˆ¶ï¼š</strong>ç›´æ’­å†…å®¹ â†’ å¼ºåˆ¶ä½¿ç”¨è½»é‡æ¨¡å‹ï¼Œå®¹å¿æ›´é«˜è¯¯åˆ¤ç‡</li>
    </ul>
  </div>
  <div class="en">
    <p>Video = image sequence + audio. Can't process every frame â€” smart sampling required:</p>
    <ul>
      <li><strong>Keyframe extraction:</strong> Scene change detection (cosine distance &gt;0.3 = new scene), ~1 frame per 30 seconds on average</li>
      <li><strong>Audio analysis:</strong> Whisper transcription â†’ text classification; acoustic analysis for gunshots, screams</li>
      <li><strong>Temporal models:</strong> VIDEO-BERT / TimeSformer for cross-frame action detection (fight sequences)</li>
      <li><strong>Live stream constraint:</strong> Must use lightweight models, tolerate higher false positive rate</li>
    </ul>
  </div>
</div>

<h3>ğŸ”€ å¤šæ¨¡æ€èåˆ / Multi-Modal Fusion</h3>

<div class="highlight">
  <strong>ğŸ”‘ é¢è¯•äº®ç‚¹ï¼šæ–‡æœ¬+å›¾ç‰‡ çš„"è¯­ä¹‰çŸ›ç›¾"æ£€æµ‹</strong><br>
  ä¸€å¼ æ­£å¸¸é£æ™¯å›¾é…ä¸Šä»‡æ¨è¨€è®ºæ–‡å­— â†’ æ¯ä¸ªæ¨¡æ€å•ç‹¬çœ‹éƒ½"å®‰å…¨"ï¼Œä½†ç»„åˆèµ·æ¥å°±æ˜¯è¿è§„å†…å®¹ã€‚<br>
  <strong>è§£å†³æ–¹æ¡ˆï¼š</strong>ç”¨ Fusion Attention å±‚å¯¹è·¨æ¨¡æ€ä¿¡å·åšäº¤å‰æ³¨æ„åŠ›ï¼Œæ£€æµ‹æ¨¡æ€é—´ä¸€è‡´æ€§åˆ†æ•°ã€‚
  å¦‚æœæ–‡æœ¬ embedding å’Œå›¾ç‰‡ embedding çš„ä½™å¼¦ç›¸ä¼¼åº¦å¾ˆä½ï¼ˆè¯­ä¹‰çŸ›ç›¾ï¼‰ï¼Œåˆ™æå‡é£é™©å¾—åˆ†ã€‚
</div>

<pre><code># å¤šæ¨¡æ€èåˆå†³ç­–
class MultiModalFusion(nn.Module):
    def __init__(self, text_dim=768, image_dim=768, context_dim=64):
        super().__init__()
        # è·¨æ¨¡æ€æ³¨æ„åŠ›
        self.cross_attention = nn.MultiheadAttention(
            embed_dim=768, num_heads=8, batch_first=True
        )
        self.fusion_proj = nn.Linear(text_dim + image_dim + context_dim, 256)
        self.final_classifier = nn.Linear(256, len(HARM_CATEGORIES))
        
    def forward(self, text_emb, image_emb, context_emb):
        # Cross-modal attention: text attends to image
        attended, _ = self.cross_attention(
            query=text_emb.unsqueeze(1),
            key=image_emb.unsqueeze(1),
            value=image_emb.unsqueeze(1)
        )
        
        # è®¡ç®—æ¨¡æ€ä¸€è‡´æ€§ï¼ˆä½ä¸€è‡´æ€§ = é«˜é£é™©ï¼‰
        consistency = F.cosine_similarity(text_emb, image_emb)
        inconsistency_risk = torch.clamp(1.0 - consistency, min=0)
        
        # èåˆæ‰€æœ‰ä¿¡å·
        fused = torch.cat([
            attended.squeeze(1), image_emb, context_emb
        ], dim=-1)
        
        logits = self.final_classifier(self.fusion_proj(fused))
        
        # ä¸ä¸€è‡´æ€§ boostï¼šæå‡è·¨æ¨¡æ€çŸ›ç›¾å†…å®¹çš„é£é™©åˆ†
        logits = logits * (1 + 0.3 * inconsistency_risk.unsqueeze(-1))
        
        return torch.sigmoid(logits)
</code></pre>

<h2>ğŸ“‹ ä¼¤å®³åˆ†ç±»ä¸æ”¿ç­–å¼•æ“ / Harm Taxonomy &amp; Policy Engine</h2>

<div class="bilingual">
  <div class="zh">
    <h3>ä¼¤å®³åˆ†ç±»å±‚æ¬¡ (Harm Taxonomy)</h3>
    <p>ä¼¤å®³åˆ†ç±»å¿…é¡»æ˜¯åˆ†å±‚çš„ï¼Œé¢è¯•æ—¶è¦å±•ç¤ºå±‚æ¬¡ç»“æ„ï¼š</p>
  </div>
  <div class="en">
    <h3>Harm Taxonomy (Hierarchical)</h3>
    <p>Harm taxonomy must be hierarchical. Show the structure in interviews:</p>
  </div>
</div>

<div class="diagram">
Level 0: Zero-Tolerance (Always Remove, No Appeal for Primary Content)
  â”œâ”€â”€ CSAM (Child Sexual Abuse Material)
  â””â”€â”€ Terrorism / ISIS Recruitment (Active Incitement)

Level 1: High Severity (Remove, Fast Human Review if Uncertain)
  â”œâ”€â”€ Graphic Violence (real gore, torture)
  â”œâ”€â”€ Adult Sexual Content (explicit, non-consensual imagery)
  â”œâ”€â”€ Suicide/Self-Harm (instructional, glorifying)
  â””â”€â”€ Dangerous Weapons (trafficking, illegal arms sales)

Level 2: Context-Dependent (Restrict / Label / Review)
  â”œâ”€â”€ Hate Speech
  â”‚    â”œâ”€â”€ Slurs + Dehumanization â†’ Remove
  â”‚    â”œâ”€â”€ Stereotypes + Mockery â†’ Label + Limit Reach
  â”‚    â””â”€â”€ Satire / Counter-speech â†’ Allow with context
  â”œâ”€â”€ Misinformation
  â”‚    â”œâ”€â”€ Medical misinfo (vaccine, health) â†’ Label + Reduce distribution
  â”‚    â”œâ”€â”€ Election misinfo â†’ Escalated review
  â”‚    â””â”€â”€ Satire labeled as real â†’ Label
  â””â”€â”€ Violence (non-graphic)
       â”œâ”€â”€ News coverage of conflict â†’ Allow
       â””â”€â”€ Glorification / Celebration â†’ Remove

Level 3: Policy-Variable (Rules Differ by Region/Platform)
  â”œâ”€â”€ Nudity (art vs pornography, cultural context)
  â”œâ”€â”€ Drug content (legality varies by jurisdiction)
  â”œâ”€â”€ Political content (restricted in some regions)
  â””â”€â”€ Religious content (blasphemy laws vary)
</div>

<div class="bilingual">
  <div class="zh">
    <h3>æ”¿ç­–å¼•æ“è®¾è®¡</h3>
    <p>æ”¿ç­– â‰  æ¨¡å‹ã€‚æ”¿ç­–æ˜¯å¯ç‰ˆæœ¬åŒ–çš„ä¸šåŠ¡è§„åˆ™ï¼Œå¿…é¡»èƒ½åœ¨ä¸é‡è®­æ¨¡å‹çš„æƒ…å†µä¸‹æ›´æ–°ï¼š</p>
    <pre><code># æ”¿ç­–è§„åˆ™ç¤ºä¾‹ï¼ˆYAML å®šä¹‰ï¼Œç‰ˆæœ¬åŒ–å­˜å‚¨ï¼‰
policy_version: "2026-02-26-v3.1"
jurisdiction: "EU"  # GDPR + DSA åˆè§„
rules:
  hate_speech:
    threshold_remove: 0.85
    threshold_restrict: 0.60
    context_boost:
      - condition: "account_violations > 3"
        multiplier: 1.3
      - condition: "content_virality > 10000"
        multiplier: 1.5
    exemptions:
      - "counter_speech_detected == true"
      - "verified_news_organization == true"
  nudity:
    threshold_remove: 0.90
    age_gate_threshold: 0.70  # 18+ label
    exemptions:
      - "art_museum_verified == true"
      - "breastfeeding_context_detected == true"
</code></pre>
  </div>
  <div class="en">
    <h3>Policy Engine Design</h3>
    <p>Policy â‰  Model. Policy is versioned business rules that must be updatable without model retraining:</p>
    <ul>
      <li><strong>Policy Store:</strong> Git-versioned YAML + approval workflow (legal review)</li>
      <li><strong>Regional Rules:</strong> EU (DSA), US (Section 230), India, etc.</li>
      <li><strong>Rollback capability:</strong> Any policy version can be rolled back in &lt;5 minutes</li>
      <li><strong>A/B testing:</strong> New policies canary-tested on 1% traffic before full rollout</li>
      <li><strong>Audit trail:</strong> Every decision logged with policy version used</li>
    </ul>
  </div>
</div>

<h2>ğŸŒ ä¸Šä¸‹æ–‡ç³»ç»Ÿ / Context System</h2>

<div class="bilingual">
  <div class="zh">
    <p><strong>åŒä¸€æ¡å†…å®¹ï¼Œåœ¨ä¸åŒä¸Šä¸‹æ–‡ä¸‹ï¼Œæ­£ç¡®å†³ç­–å¯ä»¥å®Œå…¨ä¸åŒã€‚</strong>è¿™æ˜¯å†…å®¹å®¡æ ¸æœ€éš¾çš„éƒ¨åˆ†ã€‚</p>
    <h3>ç”¨æˆ·ä¸Šä¸‹æ–‡ä¿¡å·</h3>
    <ul>
      <li><strong>è´¦å·å¹´é¾„ï¼š</strong>æ–°è´¦å·ï¼ˆ&lt;30å¤©ï¼‰+ é«˜é£é™©å†…å®¹ â†’ æå‡ 1.4x é£é™©åˆ†</li>
      <li><strong>å†å²è¿è§„ï¼š</strong>3æ¬¡è¿è§„å†…è´¦å· â†’ æ›´ä¸¥æ ¼é˜ˆå€¼ï¼›åå¤è¿è§„ â†’ é™çº§/å°ç¦</li>
      <li><strong>æ ¸å®çŠ¶æ€ï¼š</strong>è®¤è¯æ–°é—»æœºæ„ã€å­¦æœ¯è´¦å·äº«æœ‰è±å…</li>
      <li><strong>åœ°ç†ä½ç½®ï¼š</strong>åŒä¸€å†…å®¹åœ¨ä¸åŒå›½å®¶é€‚ç”¨ä¸åŒæ”¿ç­–</li>
      <li><strong>å…³ç³»ç½‘ç»œï¼š</strong>ç§èŠ vs å…¬å¼€å¸–å­ï¼Œå—ä¼—æ˜¯å¦æœ‰æœªæˆå¹´äºº</li>
    </ul>
    <h3>ååŒè¡Œä¸ºæ£€æµ‹ï¼ˆCoordinated Inauthentic Behaviorï¼‰</h3>
    <p>æ£€æµ‹æœ‰ç»„ç»‡çš„è¿è§„æ´»åŠ¨ï¼ˆå¦‚ä¿¡æ¯æˆ˜ï¼‰ï¼Œéœ€è¦å›¾åˆ†æï¼š</p>
    <ul>
      <li>å¤šä¸ªè´¦å·åœ¨çŸ­æ—¶é—´å†…å‘å¸ƒå‡ ä¹ç›¸åŒå†…å®¹ â†’ è¯†åˆ«ä¸»è´¦å·ï¼Œæ‰¹é‡å¤„ç†</li>
      <li>è½¬å‘ç½‘ç»œå¼‚å¸¸å¯†é›† â†’ å¯èƒ½æ˜¯æœºå™¨äººå†œåœº</li>
      <li>å›¾ç¥ç»ç½‘ç»œ (GNN) æ£€æµ‹ç¤¾åŒºç»“æ„å¼‚å¸¸</li>
    </ul>
  </div>
  <div class="en">
    <p><strong>The same content can warrant completely different decisions depending on context.</strong> This is the hardest part of content moderation.</p>
    <h3>User Context Signals</h3>
    <ul>
      <li><strong>Account age:</strong> New account (&lt;30 days) + high-risk content â†’ 1.4x risk multiplier</li>
      <li><strong>Violation history:</strong> Accounts with 3+ violations â†’ stricter thresholds; repeat offenders â†’ downgrade/ban</li>
      <li><strong>Verification status:</strong> Certified news orgs, academic accounts have exemptions</li>
      <li><strong>Geolocation:</strong> Same content, different policies in different countries</li>
      <li><strong>Network context:</strong> Private DM vs public post; audience includes minors</li>
    </ul>
    <h3>Coordinated Inauthentic Behavior Detection</h3>
    <p>Detecting organized violation campaigns (e.g., info warfare) requires graph analysis:</p>
    <ul>
      <li>Multiple accounts posting nearly identical content â†’ identify lead account, batch process</li>
      <li>Abnormally dense retweet networks â†’ possible bot farm</li>
      <li>Graph Neural Networks (GNN) for community structure anomaly detection</li>
    </ul>
  </div>
</div>

<pre><code># ç”¨æˆ·é£é™©ä¸Šä¸‹æ–‡å¼•æ“
class UserContextEngine:
    def __init__(self, redis_client, graph_db):
        self.redis = redis_client      # çƒ­ç‚¹æ•°æ®ç¼“å­˜ï¼ˆè´¦å·ç‰¹å¾ï¼‰
        self.graph_db = graph_db       # å…³ç³»å›¾æ•°æ®åº“ï¼ˆNeo4jï¼‰
    
    def get_user_risk_profile(self, user_id: str) -> UserRiskProfile:
        cache_key = f"user_risk:{user_id}"
        cached = self.redis.get(cache_key)
        if cached:
            return UserRiskProfile.parse_raw(cached)
        
        # ä»å¤šä¸ªæ•°æ®æºèšåˆç”¨æˆ·ç‰¹å¾
        profile = UserRiskProfile(
            account_age_days=self._get_account_age(user_id),
            violation_count_90d=self._get_violations(user_id, days=90),
            violation_severity_max=self._get_max_severity(user_id),
            is_verified_journalist=self._check_verification(user_id, "journalist"),
            is_verified_government=self._check_verification(user_id, "government"),
            network_risk_score=self._get_network_risk(user_id),  # GNN score
            geo_country=self._get_user_country(user_id),
            coordinated_behavior_flag=self._check_coordinated(user_id)
        )
        
        # ç¼“å­˜ 5 åˆ†é’Ÿï¼ˆé¢‘ç¹æ›´æ–°çš„ä¿¡å·ï¼‰
        self.redis.setex(cache_key, 300, profile.json())
        return profile
    
    def compute_context_multiplier(self, profile: UserRiskProfile) -> float:
        multiplier = 1.0
        
        # æ–°è´¦å·é«˜é£é™© boost
        if profile.account_age_days < 30:
            multiplier *= 1.4
        
        # å†å²è¿è§„ boost
        if profile.violation_count_90d >= 3:
            multiplier *= 1.3
        elif profile.violation_count_90d >= 1:
            multiplier *= 1.15
        
        # ä¸¥é‡è¿è§„å†å²ï¼ˆå¦‚ä¹‹å‰ CSAM ç›¸å…³ï¼‰â†’ æœ€ä¸¥æ ¼é˜ˆå€¼
        if profile.violation_severity_max == "LEVEL_0":
            multiplier *= 2.0
        
        # ååŒè¡Œä¸º â†’ ç«‹å³ escalate
        if profile.coordinated_behavior_flag:
            multiplier *= 3.0  # ç›´æ¥è¿› P0 é˜Ÿåˆ—
        
        # è®¤è¯è´¦å· discount
        if profile.is_verified_journalist or profile.is_verified_government:
            multiplier *= 0.7
        
        return min(multiplier, 5.0)  # cap at 5x
</code></pre>

<h2>ğŸ‘¤ Human-in-the-Loop è®¾è®¡</h2>

<div class="bilingual">
  <div class="zh">
    <h3>ä¸ºä»€ä¹ˆäººå·¥å®¡æ ¸ä¸å¯æˆ–ç¼ºï¼Ÿ</h3>
    <p>ML æ¨¡å‹åšä¸åˆ°çš„äº‹æƒ…ï¼š</p>
    <ul>
      <li>è®½åˆº/åè®½ï¼šæ­£é¢è¯æ±‡ç”¨äºè´¬ä½ â†’ æ¨¡å‹è¯¯åˆ¤</li>
      <li>è¯­å¢ƒå¹½é»˜ï¼šé»‘è‰²å¹½é»˜ vs çœŸå®æš´åŠ›å¨èƒ</li>
      <li>æ–‡åŒ–ç‰¹å¼‚æ€§ï¼šæŸäº›è¯æ±‡/æ‰‹åŠ¿åœ¨ç‰¹å®šæ–‡åŒ–ä¸­çš„å«ä¹‰</li>
      <li>æ–°å…´ä¼¤å®³ç±»å‹ï¼šé¦–æ¬¡å‡ºç°ï¼Œæ¨¡å‹æœªè§è¿‡</li>
      <li>ç”³è¯‰å¤æ ¸ï¼šè¢«æŠ•è¯‰ç”¨æˆ·çš„ç”³è¯‰å¿…é¡»æœ‰äººå·¥å‚ä¸</li>
    </ul>
    <h3>äººå·¥å®¡æ ¸çš„æŒ‘æˆ˜</h3>
    <ul>
      <li><strong>è®¤çŸ¥è´Ÿè·é—®é¢˜ï¼š</strong>å®¡æ ¸å‘˜æ¯å¤©è¦çœ‹å¤§é‡æš´åŠ›/æ€§/ä»‡æ¨å†…å®¹ï¼ŒèŒä¸šåˆ›ä¼¤</li>
      <li>Meta æ¯å¤©æœ‰ ~15000 ååˆåŒå®¡æ ¸å‘˜åˆ†å¸ƒå…¨çƒ</li>
      <li>å¹³å‡æ¯ä¸ªå®¡æ ¸å‘˜æ¯å°æ—¶å¤„ç† ~200 æ¡å†…å®¹</li>
    </ul>
  </div>
  <div class="en">
    <h3>Why Human Review Is Indispensable?</h3>
    <p>Things ML models can't reliably handle:</p>
    <ul>
      <li>Sarcasm/irony: positive words used to belittle â†’ model misclassifies</li>
      <li>Contextual humor: dark humor vs real threats of violence</li>
      <li>Cultural specificity: words/gestures with specific cultural meaning</li>
      <li>Emerging harm types: first occurrences, unseen by model</li>
      <li>Appeals review: human participation required for appeals</li>
    </ul>
    <h3>Human Review Challenges</h3>
    <ul>
      <li><strong>Cognitive load:</strong> Reviewers see massive amounts of violent/sexual/hateful content daily â€” occupational trauma</li>
      <li>Meta employs ~15,000 contract content reviewers worldwide</li>
      <li>Average reviewer handles ~200 pieces/hour</li>
    </ul>
  </div>
</div>

<div class="diagram">
  äººå·¥å®¡æ ¸ä¼˜å…ˆçº§é˜Ÿåˆ— (Priority Queue Design)
  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  Priority Score = Severity_Weight Ã— log(1 + Virality) Ã— Account_Risk_Multiplier Ã— Time_Urgency

  Severity Weights:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ å†…å®¹ç±»å‹             â”‚ Weight â”‚ äººå·¥ SLA                             â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ CSAM                 â”‚ 1000   â”‚ 15åˆ†é’Ÿï¼ˆå…¨å¤©å€™ï¼‰                     â”‚
  â”‚ Terrorism incitement â”‚ 500    â”‚ 30åˆ†é’Ÿ                               â”‚
  â”‚ Credible death threatâ”‚ 300    â”‚ 1å°æ—¶                                â”‚
  â”‚ Graphic violence     â”‚ 100    â”‚ 2å°æ—¶                                â”‚
  â”‚ Hate speech          â”‚ 50     â”‚ 24å°æ—¶                               â”‚
  â”‚ Misinformation       â”‚ 30     â”‚ 48å°æ—¶                               â”‚
  â”‚ Spam                 â”‚ 10     â”‚ 72å°æ—¶ / æ‰¹å¤„ç†                      â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  Virality Factor: 
  - 0 shares: log(1) = 0 (viral multiplier = 1)
  - 1K shares: log(1001) â‰ˆ 7 
  - 1M shares: log(1M+1) â‰ˆ 14 (viral content always escalated)

  å®¡æ ¸å‘˜å·¥å…· UI è®¾è®¡è¦ç‚¹ï¼š
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ [Content Display]        â”‚ [User Profile]            â”‚
  â”‚ - Original text/image    â”‚ - Account age             â”‚
  â”‚ - Context (thread/page)  â”‚ - Prior violations        â”‚
  â”‚ - Translation            â”‚ - Verification status     â”‚
  â”‚                          â”‚ - Network risk score      â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ [ML Signals]             â”‚ [Policy Reference]        â”‚
  â”‚ - Model scores           â”‚ - Relevant policy         â”‚
  â”‚ - Similar past cases     â”‚ - Comparable decisions    â”‚
  â”‚ - Confidence level       â”‚ - Edge case guidance      â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ [Decision] ALLOW â”‚ RESTRICT â”‚ REMOVE â”‚ ESCALATE      â”‚
  â”‚ [Reason Code] (required) + Free text                â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</div>

<div class="highlight-red">
  <strong>âš ï¸ è®¤çŸ¥è´Ÿè·ç¼“è§£æªæ–½ï¼ˆé¢è¯•å¿…æï¼‰ï¼š</strong>
  <ul>
    <li>å¼ºåˆ¶ä¼‘æ¯åˆ¶åº¦ï¼šæ¯å°æ—¶æœ€å¤šå®¡æ ¸45åˆ†é’Ÿï¼Œä¸èƒ½è¿ç»­å®¡æ ¸ä¸¥é‡å†…å®¹</li>
    <li>å†…å®¹ç±»å‹è½®æ¢ï¼šä¸è®©åŒä¸€å®¡æ ¸å‘˜è¿ç»­å¤„ç†åŒç±»å‹é«˜å¼ºåº¦å†…å®¹</li>
    <li>å¿ƒç†æ”¯æŒèµ„æºï¼šEAPï¼ˆEmployee Assistance Programï¼‰éšæ—¶å¯ç”¨</li>
    <li>æ¸è¿›å¼æš´éœ²ï¼šæ–°å®¡æ ¸å‘˜ä»ä½ä¸¥é‡åº¦å†…å®¹å¼€å§‹ï¼Œé€æ­¥å‡çº§</li>
    <li>å†…å®¹æ¨¡ç³Šå¤„ç†ï¼šè‡ªåŠ¨é™ä½ä¸¥é‡å†…å®¹çš„è§†è§‰æ¸…æ™°åº¦ï¼ˆblurringï¼‰</li>
  </ul>
</div>

<h2>âš¡ å®æ—¶ vs å¼‚æ­¥å†³ç­– / Real-time vs Async</h2>

<table>
  <thead>
    <tr>
      <th>é˜¶æ®µ</th>
      <th>æ¨¡å¼</th>
      <th>å»¶è¿Ÿ SLA</th>
      <th>ä½¿ç”¨åœºæ™¯</th>
      <th>æŠ€æœ¯é€‰å‹</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ä¸Šä¼ é—¨æ§</td>
      <td>åŒæ­¥</td>
      <td>&lt;500ms P99</td>
      <td>é˜»æ­¢æ˜æ˜¾è¿è§„ä¸Šä¼ </td>
      <td>FastText + pHash + Redis ç¼“å­˜</td>
    </tr>
    <tr>
      <td>è¯„è®º/å¸–å­å‘å¸ƒ</td>
      <td>åŒæ­¥</td>
      <td>&lt;200ms P99</td>
      <td>å‘å¸–å‰å¿«é€Ÿå®¡æ ¸</td>
      <td>è½»é‡ DistilBERT + è§„åˆ™å¼•æ“</td>
    </tr>
    <tr>
      <td>æ·±åº¦åˆ†æ</td>
      <td>å¼‚æ­¥</td>
      <td>&lt;30s P95</td>
      <td>å·²å‘å¸ƒå†…å®¹çš„ç²¾ç¡®å®¡æ ¸</td>
      <td>Kafka â†’ GPU Worker Pool</td>
    </tr>
    <tr>
      <td>è§†é¢‘åˆ†æ</td>
      <td>å¼‚æ­¥</td>
      <td>&lt;5min P95</td>
      <td>ä¸Šä¼ åè§†é¢‘é€æ®µåˆ†æ</td>
      <td>Spark + GPU Cluster</td>
    </tr>
    <tr>
      <td>äººå·¥å¤æ ¸</td>
      <td>å¼‚æ­¥</td>
      <td>åˆ†çº§ SLA</td>
      <td>è¾¹ç¼˜æ¡ˆä¾‹ + ç”³è¯‰</td>
      <td>ä¼˜å…ˆçº§é˜Ÿåˆ— + å®¡æ ¸å·¥å…·</td>
    </tr>
    <tr>
      <td>ç›´æ’­å†…å®¹</td>
      <td>æµå¼</td>
      <td>&lt;2s per segment</td>
      <td>ç›´æ’­å®æ—¶æ£€æµ‹</td>
      <td>Flink + è½»é‡æ¨¡å‹ï¼ˆä¸èƒ½ç”¨é‡æ¨¡å‹ï¼‰</td>
    </tr>
    <tr>
      <td>å†å²å†…å®¹é‡å®¡</td>
      <td>æ‰¹é‡</td>
      <td>å¤©çº§</td>
      <td>æ”¿ç­–æ›´æ–°åå›æº¯å®¡æ ¸</td>
      <td>MapReduce / Spark Batch</td>
    </tr>
  </tbody>
</table>

<div class="highlight-blue">
  <strong>ğŸ’¡ æ”¿ç­–æ›´æ–°çš„æŒ‘æˆ˜ï¼š</strong>å½“æ”¿ç­–å˜åŒ–æ—¶ï¼Œéœ€è¦å¯¹å†å²å†…å®¹è¿›è¡Œå›æº¯å®¡æ ¸ï¼ˆRetroactive Reviewï¼‰ã€‚
  ä¾‹å¦‚ï¼šæ–°å¢ä¸€ç§ä»‡æ¨ç¬¦å·åˆ°ç¦æ­¢åˆ—è¡¨ï¼Œéœ€è¦æ‰«æè¿‡å»æ‰€æœ‰å›¾ç‰‡ã€‚
  è§£å†³æ–¹æ¡ˆï¼šæ¯å¤©ä½å³°æœŸï¼ˆå‡Œæ™¨ï¼‰è·‘ Spark æ‰¹å¤„ç† jobï¼Œå¤„ç†å¢é‡å˜åŒ–çš„æ”¿ç­–è¦†ç›–èŒƒå›´ã€‚
</div>

<h2>âš–ï¸ ç”³è¯‰ä¸æ­£å½“ç¨‹åº / Appeals &amp; Due Process</h2>

<div class="bilingual">
  <div class="zh">
    <h3>ç”³è¯‰ç³»ç»Ÿè®¾è®¡</h3>
    <p>è§„æ¨¡é—®é¢˜ï¼šè¯¯åˆ¤ç‡ 0.1% Ã— 100B æ¡/å¤© = <strong>æ¯å¤© 1 äº¿æ¡å†…å®¹è¢«é”™è¯¯å¤„ç†</strong>ã€‚
    å¤§å¤šæ•°å¹³å°åªæœ‰ &lt;0.1% çš„è¢«å¤„ç†ç”¨æˆ·ä¼šæèµ·ç”³è¯‰ï¼Œä½†ç»å¯¹æ•°é‡ä»ç„¶å·¨å¤§ã€‚</p>
    <p><strong>ç”³è¯‰æµç¨‹ï¼š</strong></p>
    <ol>
      <li>ç”¨æˆ·æäº¤ç”³è¯‰ â†’ è‡ªåŠ¨åˆ†ç±»ï¼ˆåˆ†æç”³è¯‰æ–‡å­— + åŸå§‹å†…å®¹ï¼‰</li>
      <li>ML å¿«é€Ÿå¤æ ¸ï¼šç½®ä¿¡åº¦ &gt;0.9 çš„é”™è¯¯å†³ç­– â†’ è‡ªåŠ¨æ¢å¤ï¼ˆæ— éœ€äººå·¥ï¼‰</li>
      <li>å‰©ä½™æ¡ˆä¾‹ â†’ äººå·¥å¤æ ¸é˜Ÿåˆ—ï¼ˆç‹¬ç«‹äºåŸå§‹å®¡æ ¸å‘˜ï¼‰</li>
      <li>é«˜å½±å“åŠ›è´¦å·ç”³è¯‰ â†’ ä¼˜å…ˆå¤„ç† + é«˜çº§å®¡æ ¸å‘˜</li>
    </ol>
    <h3>å‡å°‘è¯¯åˆ¤çš„ç³»ç»Ÿçº§ç­–ç•¥</h3>
    <ul>
      <li><strong>å…ˆé™çº§ï¼Œåç§»é™¤ï¼š</strong>å¯¹ä¸ç¡®å®šå†…å®¹å…ˆå‡å°‘åˆ†å‘ï¼ˆReduce Reachï¼‰ï¼Œå†å†³å®šæ˜¯å¦ç§»é™¤</li>
      <li><strong>å†…å®¹æ ‡ç­¾ï¼š</strong>åœ¨ä¸ç§»é™¤çš„æƒ…å†µä¸‹ï¼ŒåŠ è­¦å‘Šæ ‡ç­¾ï¼ˆ"Contains Sensitive Content"ï¼‰</li>
      <li><strong>åˆ†çº§å¤„ç½šï¼š</strong>é¦–æ¬¡è¿è§„ â†’ æç¤ºï¼›å¤šæ¬¡è¿è§„ â†’ é™æµï¼›ä¸¥é‡è¿è§„ â†’ å°ç¦</li>
    </ul>
  </div>
  <div class="en">
    <h3>Appeals System Design</h3>
    <p>Scale problem: 0.1% false positive rate Ã— 100B/day = <strong>100M pieces incorrectly actioned per day</strong>.
    Most platforms see &lt;0.1% of actioned users filing appeals â€” but the absolute number is still enormous.</p>
    <p><strong>Appeals flow:</strong></p>
    <ol>
      <li>User submits appeal â†’ auto-classify (analyze appeal text + original content)</li>
      <li>ML quick re-review: high-confidence wrong decisions (â‰¥0.9) â†’ auto-restore (no human needed)</li>
      <li>Remaining cases â†’ human review queue (different reviewer than original)</li>
      <li>High-profile account appeals â†’ priority processing + senior reviewer</li>
    </ol>
    <h3>System-Level Strategies to Reduce False Positives</h3>
    <ul>
      <li><strong>Downrank before remove:</strong> For uncertain content, reduce distribution first before deciding on removal</li>
      <li><strong>Content labels:</strong> Add warning labels without removal ("Contains Sensitive Content")</li>
      <li><strong>Graduated enforcement:</strong> First violation â†’ notification; multiple violations â†’ throttle; severe â†’ ban</li>
    </ul>
  </div>
</div>

<div class="diagram">
  ç”³è¯‰ç³»ç»Ÿæ¶æ„
  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  User Appeal Submission
         â”‚
         â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Auto-Classification of Appeal                   â”‚
  â”‚  - Appeal text analysis (NLP)                   â”‚
  â”‚  - Original content re-scoring                  â”‚
  â”‚  - Category: Wrong Label / New Context / Policy â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                           â”‚
           â–¼                           â–¼
  [High Confidence Error]      [Borderline / Unclear]
  ML re-score &gt; 0.9 for          â”‚
  opposite decision               â”‚
           â”‚                     â–¼
           â–¼              [Human Review Queue]
  [Auto Restore]           - Different reviewer
  + Notify User            - Blind review (no original decision shown)
  + Log for Model Training - Must cite specific policy
           â”‚                     â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â–¼
              [Final Decision]
              REINSTATE / UPHOLD REMOVAL
                      â”‚
                      â”œâ”€â”€ User Notification (with reason)
                      â”œâ”€â”€ Policy Education Resource
                      â””â”€â”€ Log to ML Training Dataset
                          (confirmed errors improve model)
</div>

<h2>ğŸ‹ï¸ æ¨¡å‹è®­ç»ƒä¸æŒç»­æ”¹è¿›</h2>

<div class="bilingual">
  <div class="zh">
    <h3>è®­ç»ƒæ•°æ®æ¥æº</h3>
    <ul>
      <li><strong>äººå·¥æ ‡æ³¨ï¼ˆGolden Setï¼‰ï¼š</strong>ä¸“èŒæ ‡æ³¨å›¢é˜Ÿï¼Œæ¯ç±»åˆ« 50K+ æ ·æœ¬ï¼Œå®šæœŸæ ¡å‡†</li>
      <li><strong>åé¦ˆå¾ªç¯ï¼š</strong>å®¡æ ¸å‘˜å†³ç­– + ç”³è¯‰ç»“æœ â†’ æŒç»­æ ‡æ³¨æ•°æ®</li>
      <li><strong>ä¸»åŠ¨å­¦ä¹ ï¼š</strong>æ¨¡å‹ä¸ç¡®å®šçš„æ ·æœ¬ï¼ˆç½®ä¿¡åº¦ 0.4-0.6ï¼‰ä¼˜å…ˆé€äººå·¥æ ‡æ³¨</li>
      <li><strong>åˆæˆæ•°æ®ï¼š</strong>å¯¹ä½é¢‘ä¼¤å®³ç±»åˆ«ï¼ˆå¦‚ CSAM å‘¨è¾¹å†…å®¹ï¼‰ç”Ÿæˆåˆæˆè´Ÿä¾‹</li>
    </ul>
    <h3>æ¨¡å‹æ›´æ–°èŠ‚å¥</h3>
    <ul>
      <li><strong>Shadow Modeï¼š</strong>æ–°æ¨¡å‹å…ˆåœ¨å½±å­æ¨¡å¼è¿è¡Œï¼Œå¯¹æ¯”å†³ç­–å·®å¼‚</li>
      <li><strong>Canary Deployï¼š</strong>å…ˆå¯¹ 1% æµé‡ç”Ÿæ•ˆï¼Œç›‘æ§ FP/FN å˜åŒ–</li>
      <li><strong>Rollback Triggerï¼š</strong>FP ç‡æå‡ &gt;0.05% æˆ– FN ç‡æå‡ &gt;0.01% â†’ è‡ªåŠ¨å›æ»š</li>
    </ul>
  </div>
  <div class="en">
    <h3>Training Data Sources</h3>
    <ul>
      <li><strong>Human annotation (Golden Set):</strong> Dedicated annotation teams, 50K+ samples per category, regular calibration</li>
      <li><strong>Feedback loops:</strong> Reviewer decisions + appeal outcomes â†’ continuous labeling data</li>
      <li><strong>Active learning:</strong> Model-uncertain samples (confidence 0.4-0.6) prioritized for human annotation</li>
      <li><strong>Synthetic data:</strong> Generate synthetic negative examples for rare harm categories</li>
    </ul>
    <h3>Model Update Cadence</h3>
    <ul>
      <li><strong>Shadow mode:</strong> New model runs in shadow mode first, comparing decision deltas</li>
      <li><strong>Canary deploy:</strong> 1% traffic first, monitor FP/FN changes</li>
      <li><strong>Rollback trigger:</strong> FP rate increase &gt;0.05% or FN rate increase &gt;0.01% â†’ auto-rollback</li>
    </ul>
  </div>
</div>

<h2>ğŸ“ ç³»ç»Ÿå…³é”®æŒ‡æ ‡ / Key Metrics</h2>

<table>
  <thead>
    <tr><th>æŒ‡æ ‡</th><th>å«ä¹‰</th><th>ç›®æ ‡å€¼</th><th>æƒè¡¡</th></tr>
  </thead>
  <tbody>
    <tr>
      <td>Prevalence</td>
      <td>è¿è§„å†…å®¹åœ¨å¹³å°çš„å­˜åœ¨ç‡</td>
      <td>è¶Šä½è¶Šå¥½</td>
      <td>æ ¸å¿ƒä¸šåŠ¡æŒ‡æ ‡ï¼ŒMeta å…¬å¼€æŠ«éœ²</td>
    </tr>
    <tr>
      <td>Recall (Sensitivity)</td>
      <td>å®é™…è¿è§„å†…å®¹è¢«æ£€å‡ºçš„æ¯”ä¾‹</td>
      <td>CSAM: &gt;99.9% | ä»‡æ¨: &gt;95%</td>
      <td>è¶Šé«˜ï¼Œæ¼æ£€è¶Šå°‘</td>
    </tr>
    <tr>
      <td>Precision</td>
      <td>è¢«æ ‡è®°å†…å®¹ä¸­çœŸæ­£è¿è§„çš„æ¯”ä¾‹</td>
      <td>&gt;90%ï¼ˆé™ä½äººå·¥è´Ÿæ‹…ï¼‰</td>
      <td>è¶Šé«˜ï¼Œè¯¯åˆ¤è¶Šå°‘</td>
    </tr>
    <tr>
      <td>False Positive Rate</td>
      <td>æ­£å¸¸å†…å®¹è¢«é”™è¯¯ä¸‹æ¶ç‡</td>
      <td>&lt;0.1%</td>
      <td>ç›´æ¥å½±å“ç”¨æˆ·ä½“éªŒ</td>
    </tr>
    <tr>
      <td>Proactive Rate</td>
      <td>åœ¨ç”¨æˆ·ä¸¾æŠ¥å‰ä¸»åŠ¨å‘ç°çš„æ¯”ä¾‹</td>
      <td>&gt;97%ï¼ˆæš´åŠ›ï¼‰/ &gt;99%ï¼ˆCSAMï¼‰</td>
      <td>Meta 2023å¹´ï¼šæš´åŠ›å†…å®¹97%ä¸»åŠ¨å‘ç°</td>
    </tr>
    <tr>
      <td>Upload Gate Latency</td>
      <td>ä¸Šä¼ é¢„å®¡æ ¸å»¶è¿Ÿ</td>
      <td>&lt;500ms P99</td>
      <td>ç”¨æˆ·ä½“éªŒ vs å®‰å…¨</td>
    </tr>
    <tr>
      <td>Human Review SLA</td>
      <td>äººå·¥å®¡æ ¸å®Œæˆæ—¶é—´</td>
      <td>P0: 15min / P1: 2h</td>
      <td>èµ„æºæˆæœ¬ vs å†…å®¹å±å®³æ—¶é—´</td>
    </tr>
    <tr>
      <td>Appeal Overturn Rate</td>
      <td>ç”³è¯‰åè¢«æ¨ç¿»çš„å†³ç­–æ¯”ä¾‹</td>
      <td>&lt;5%ï¼ˆæ¨¡å‹æ”¹è¿›ä¿¡å·ï¼‰</td>
      <td>è¶Šé«˜è¯´æ˜æ¨¡å‹è¶Šå·®</td>
    </tr>
  </tbody>
</table>

<h2>ğŸ¯ 4é“é¢è¯•é«˜é¢‘é—®é¢˜ / Top Interview Q&amp;A</h2>

<div class="interview">
  <h3>Q1: å¦‚ä½•åœ¨æ¯«ç§’çº§å»¶è¿Ÿå†…å®ç°å›¾ç‰‡å®¡æ ¸ï¼Ÿ</h3>
  <div class="bilingual">
    <div class="zh">
      <p><strong>æ¨¡å‹ç­”æ¡ˆï¼ˆåˆ†ä¸‰å±‚å›ç­”ï¼‰ï¼š</strong></p>
      <p><strong>ç¬¬ä¸€å±‚ï¼šå“ˆå¸ŒæŸ¥æ‰¾ï¼ˆ&lt;1msï¼‰</strong><br>
      å¯¹æ‰€æœ‰å›¾ç‰‡è®¡ç®— pHashï¼ˆæ„ŸçŸ¥å“ˆå¸Œï¼‰ï¼Œä¸å·²çŸ¥è¿è§„å›¾ç‰‡åº“æ¯”å¯¹ã€‚åªéœ€ä¸€æ¬¡ Redis lookupï¼Œæ— éœ€ä»»ä½•æ¨ç†ã€‚è¿™èƒ½å¤„ç†æ‰ ~80% çš„é‡å¤è¿è§„å›¾ç‰‡ï¼ˆè¿è§„è€…å¾€å¾€å¤ç”¨ç›¸åŒå›¾ç‰‡ï¼‰ã€‚
      PhotoDNA å°±æ˜¯ Microsoft ä¸“é—¨ä¸ºè¿™ä¸ªé—®é¢˜å¼€å‘çš„å·¥ä¸šçº§æ–¹æ¡ˆã€‚</p>
      <p><strong>ç¬¬äºŒå±‚ï¼šè½»é‡ CNNï¼ˆ&lt;100msï¼‰</strong><br>
      MobileNet æˆ– EfficientNet-Liteï¼Œæ¨¡å‹ &lt;10MBï¼Œå¯ä»¥éƒ¨ç½²åœ¨ CPU ä¸Šã€‚è¿™å±‚å¤„ç†æ–°å›¾ç‰‡çš„é«˜ç½®ä¿¡åº¦è¿è§„æ£€æµ‹ã€‚</p>
      <p><strong>ç¬¬ä¸‰å±‚ï¼šä¸è¦æ±‚åŒæ­¥ï¼ˆè®¾è®¡è½¬å˜ï¼‰</strong><br>
      å…³é”®æ´å¯Ÿï¼šä¸Šä¼ é—¨æ§ä¸éœ€è¦"100% å‡†ç¡®"ï¼Œåªéœ€è¦æŒ¡ä½æ˜æ˜¾è¿è§„ã€‚ä¸ç¡®å®šçš„å†…å®¹å…ˆæ”¾è¿‡ï¼Œå¼‚æ­¥è·‘é‡å‹æ¨¡å‹ï¼Œå‘ç°é—®é¢˜å†æ‰§è¡Œã€‚è¿™æ ·ç”¨æˆ·çœ‹åˆ°çš„å»¶è¿Ÿæ˜¯ Stage 1 çš„å»¶è¿Ÿï¼Œè€Œéæœ€ç»ˆå†³ç­–çš„å»¶è¿Ÿã€‚</p>
    </div>
    <div class="en">
      <p><strong>Model Answer (three layers):</strong></p>
      <p><strong>Layer 1: Hash lookup (&lt;1ms)</strong><br>
      Compute pHash for all images, compare against known-violation image DB. Just one Redis lookup, no inference needed. Handles ~80% of repeat violating images (bad actors reuse images).
      PhotoDNA is Microsoft's industrial solution for exactly this.</p>
      <p><strong>Layer 2: Lightweight CNN (&lt;100ms)</strong><br>
      MobileNet or EfficientNet-Lite, &lt;10MB model, CPU-deployable. Handles high-confidence violation detection for new images.</p>
      <p><strong>Layer 3: Don't require synchronous (design shift)</strong><br>
      Key insight: the upload gate doesn't need "100% accuracy" â€” it just needs to block obvious violations. Let uncertain content through, run heavy models async, act when found. Users perceive Stage 1 latency, not final decision latency.</p>
    </div>
  </div>
</div>

<div class="interview">
  <h3>Q2: CSAM æ£€æµ‹ç³»ç»Ÿå¦‚ä½•è®¾è®¡ï¼Ÿä¸ºä»€ä¹ˆå®ƒä¸å…¶ä»–å†…å®¹ç±»åˆ«ä¸åŒï¼Ÿ</h3>
  <div class="bilingual">
    <div class="zh">
      <p><strong>CSAM çš„ç‰¹æ®Šæ€§ï¼ˆå…³é”®è¦è¯´æ˜ï¼‰ï¼š</strong></p>
      <ul>
        <li><strong>æ³•å¾‹ä¹‰åŠ¡ï¼š</strong>åœ¨ç¾å›½ï¼ŒNCMECï¼ˆå›½å®¶å¤±è¸ªå’Œå—å‰¥å‰Šå„¿ç«¥ä¸­å¿ƒï¼‰æ˜¯æ³•å®šæŠ¥å‘Šæ–¹ã€‚å‘ç° CSAM å¿…é¡»ç«‹å³æŠ¥å‘Šï¼Œä¸æ˜¯é€‰æ‹©é¢˜ã€‚</li>
        <li><strong>é›¶å®¹å¿ï¼š</strong>æ²¡æœ‰"ç½®ä¿¡åº¦é˜ˆå€¼"é—®é¢˜â€”â€”ä¸€æ—¦å‘ç°ï¼Œç«‹å³è¡ŒåŠ¨ï¼ˆç§»é™¤å†…å®¹ã€å°ç¦è´¦å·ã€æŠ¥å‘Šå½“å±€ï¼‰ã€‚å®å¯å¤§é‡è¯¯æŠ¥ï¼Œä¸èƒ½æ¼æŠ¥ã€‚</li>
        <li><strong>å“ˆå¸Œæ•°æ®åº“ï¼š</strong>NCMEC ç»´æŠ¤å…¨çƒ CSAM å“ˆå¸Œæ•°æ®åº“ï¼ˆPhotoDNAï¼‰ã€‚ä¸Šä¼ æ—¶æ‰€æœ‰å›¾ç‰‡ä¸è¯¥æ•°æ®åº“æ¯”å¯¹ï¼ŒO(1) æ£€æµ‹ã€‚</li>
        <li><strong>ä¸»åŠ¨æ£€æµ‹ï¼š</strong>ä¸ä»…æ£€æµ‹å·²çŸ¥ CSAMï¼Œè¿˜è¦æ£€æµ‹æœªçŸ¥çš„ï¼ˆå¯èƒ½æ˜¯æ–°ç”Ÿæˆçš„ï¼‰ã€‚éœ€è¦å¹´é¾„ä¼°è®¡æ¨¡å‹ + NSFW æ¨¡å‹çš„ç»„åˆã€‚</li>
        <li><strong>å®¡æ ¸å‘˜ä¿æŠ¤ï¼š</strong>è‡ªåŠ¨æ¨¡ç³ŠåŒ– CSAMï¼Œä¸¥æ ¼é™åˆ¶æŸ¥çœ‹æƒé™ï¼ˆåªæœ‰ç»è¿‡ç‰¹åˆ«åŸ¹è®­çš„å®¡æ ¸å‘˜ï¼‰ï¼Œä¿æŠ¤ä»–ä»¬å…å—èŒä¸šåˆ›ä¼¤ã€‚</li>
      </ul>
    </div>
    <div class="en">
      <p><strong>Why CSAM is different (must state this):</strong></p>
      <ul>
        <li><strong>Legal obligation:</strong> In the US, NCMEC is the statutory reporting entity. Discovered CSAM must be immediately reported â€” not optional.</li>
        <li><strong>Zero tolerance:</strong> No confidence threshold debate â€” once detected, immediate action (remove, ban, report authorities). False positives are acceptable; false negatives are not.</li>
        <li><strong>Hash database:</strong> NCMEC maintains a global CSAM hash database (PhotoDNA). All images checked on upload, O(1) detection.</li>
        <li><strong>Proactive detection:</strong> Must detect unknown CSAM (potentially newly generated), not just known hashes. Requires age estimation + NSFW model combination.</li>
        <li><strong>Reviewer protection:</strong> Auto-blur CSAM, strict access controls (only specially trained reviewers), protecting from occupational trauma.</li>
      </ul>
    </div>
  </div>
</div>

<div class="interview">
  <h3>Q3: æ”¿ç­–åœ¨ä¸åŒåœ°åŒºä¸åŒæ—¶ï¼Œå¦‚ä½•ç®¡ç†ç³»ç»Ÿå¤æ‚åº¦ï¼Ÿ</h3>
  <div class="bilingual">
    <div class="zh">
      <p><strong>å…³é”®è®¾è®¡ï¼šæ”¿ç­–ä¸æ¨¡å‹è§£è€¦</strong></p>
      <p>æ¨¡å‹è¾“å‡ºçš„æ˜¯"ç½®ä¿¡åº¦åˆ†æ•°"ï¼ˆcontent-level signalï¼‰ï¼Œæ”¿ç­–å¼•æ“è´Ÿè´£å°†åˆ†æ•°è½¬åŒ–ä¸º"å†³ç­–"ï¼ˆactionï¼‰ã€‚æ”¿ç­–å¯ä»¥éšæ—¶æ›´æ”¹è€Œä¸éœ€è¦é‡è®­æ¨¡å‹ã€‚</p>
      <pre><code># åœ°åŒºè·¯ç”±è®¾è®¡
def get_policy_for_content(user_country: str, content_type: str) -> Policy:
    # æ”¿ç­–ä¼˜å…ˆçº§ï¼šè´¦å·å½’å±åœ° > å†…å®¹å‘å¸ƒåœ° > å¹³å°é»˜è®¤
    policy_key = f"policy:{user_country}:{content_type}"
    policy = policy_store.get(policy_key) 
    return policy or policy_store.get(f"policy:default:{content_type}")

# EU DSA è¦æ±‚ï¼šå¯¹é‡è¦å¹³å°æ¯å­£åº¦æŠ¥å‘Š Prevalence
# å°åº¦ï¼šè¦æ±‚ 24hr å†…å“åº”æ”¿åºœåˆ å¸–è¯·æ±‚
# å¾·å›½ NetzDGï¼šç‰¹å®šå†…å®¹ 24hr å†…å¿…é¡»åˆ é™¤ï¼ˆè¿è€…ç½šæ¬¾ï¼‰
      </code></pre>
      <p><strong>Policy-as-Code æ¶æ„ï¼š</strong>æ‰€æœ‰æ”¿ç­–ä»¥ YAML å®šä¹‰ï¼Œå­˜å‚¨åœ¨ Git ä»“åº“ï¼Œé€šè¿‡ CI/CD éƒ¨ç½²ï¼Œæ”¯æŒæŒ‰å›½å®¶ã€å¹³å°äº§å“çº¿ã€ç”¨æˆ·ç¾¤ä½“åˆ†å±‚ã€‚æ¯æ¬¡æ”¿ç­–å˜æ›´éƒ½æœ‰å®¡è®¡æ—¥å¿—å’Œæ³•åŠ¡å®¡æ‰¹ã€‚</p>
    </div>
    <div class="en">
      <p><strong>Key design: Decouple policy from models</strong></p>
      <p>Models output "confidence scores" (content-level signals). The policy engine translates scores into "decisions" (actions). Policies can change anytime without model retraining.</p>
      <p><strong>Policy-as-Code architecture:</strong> All policies defined in YAML, stored in Git, deployed via CI/CD, supporting layering by country, product line, user segment. Every policy change has audit logs and legal approval workflow.</p>
      <p><strong>Jurisdictional examples:</strong></p>
      <ul>
        <li>EU DSA: Quarterly prevalence reports required for VLOPs</li>
        <li>India: 24hr government takedown response required</li>
        <li>Germany NetzDG: Specific content must be removed within 24hrs (heavy fines otherwise)</li>
      </ul>
    </div>
  </div>
</div>

<div class="interview">
  <h3>Q4: å¦‚ä½•æ£€æµ‹å’Œåº”å¯¹"æ‰“å“‘è°œ"çš„è¿è§„è€…ï¼Ÿï¼ˆå¯¹æŠ—æ€§ç»•è¿‡ï¼‰</h3>
  <div class="bilingual">
    <div class="zh">
      <p><strong>å¸¸è§ç»•è¿‡æ‰‹æ³•å’Œåº”å¯¹ç­–ç•¥ï¼š</strong></p>
      <table>
        <tr><th>ç»•è¿‡æ‰‹æ³•</th><th>æ£€æµ‹ç­–ç•¥</th></tr>
        <tr><td>leet speak: "h4te j3ws"</td><td>Character normalization + n-gram matching</td></tr>
        <tr><td>Unicode æ··æ·†: "Î—ate"ï¼ˆå¸Œè…ŠÎ—ï¼‰</td><td>Unicode NFKC æ ‡å‡†åŒ–</td></tr>
        <tr><td>å›¾ç‰‡æ–‡å­—åµŒå…¥è¿è§„è¯</td><td>OCRï¼ˆTesseract/PaddleOCRï¼‰æå–å›¾ç‰‡æ–‡å­—</td></tr>
        <tr><td>æˆªå›¾è§„é¿</td><td>å›¾ç‰‡+OCR è”åˆåˆ†æ</td></tr>
        <tr><td>æš—è¯­/ä»£è¯ï¼ˆ"13"=SSï¼Œ"88"=HHï¼‰</td><td>Dog-whistle è¯å…¸ + è´¦å·ç½‘ç»œåˆ†æ</td></tr>
        <tr><td>å¤šè¯­è¨€æ··ç”¨ç»•è¿‡</td><td>å¤šè¯­è¨€æ¨¡å‹ï¼ˆXLM-RoBERTaï¼‰</td></tr>
        <tr><td>è§†é¢‘æ–‡å­—å­—å¹•</td><td>è§†é¢‘ OCR + éŸ³é¢‘è½¬å½•</td></tr>
        <tr><td>è½»å¾®å˜å½¢å›¾ç‰‡ï¼ˆåŠ å™ªå£°ï¼‰</td><td>pHash robust hashingï¼ˆå®¹å¿å°æ‰°åŠ¨ï¼‰</td></tr>
      </table>
      <p><strong>å†›å¤‡ç«èµ›åº”å¯¹ï¼š</strong>ç»´æŠ¤ä¸“é—¨çš„"å¯¹æŠ—æ€§ç»•è¿‡"ç ”ç©¶å›¢é˜Ÿï¼ŒæŒç»­è¿½è¸ªè¿è§„è€…ç¤¾åŒºçš„æ–°æ‰‹æ³•ï¼Œå°†å‘ç°çš„æ–°æ‰‹æ³•åŠ å…¥è®­ç»ƒé›†ï¼ˆé€šå¸¸ä»¥æœˆä¸ºå•ä½è¿­ä»£ï¼‰ã€‚</p>
    </div>
    <div class="en">
      <p><strong>Common bypass techniques and countermeasures:</strong></p>
      <table>
        <tr><th>Bypass Technique</th><th>Detection Strategy</th></tr>
        <tr><td>Leet speak: "h4te j3ws"</td><td>Character normalization + n-gram matching</td></tr>
        <tr><td>Unicode obfuscation: "Î—ate" (Greek Î—)</td><td>Unicode NFKC normalization</td></tr>
        <tr><td>Text embedded in images</td><td>OCR (Tesseract/PaddleOCR) on images</td></tr>
        <tr><td>Screenshot evasion</td><td>Image + OCR joint analysis</td></tr>
        <tr><td>Dog whistles ("13"=SS, "88"=HH)</td><td>Dog-whistle lexicon + network analysis</td></tr>
        <tr><td>Multi-language mixing</td><td>Multilingual models (XLM-RoBERTa)</td></tr>
        <tr><td>Video text/subtitles</td><td>Video OCR + audio transcription</td></tr>
        <tr><td>Perturbed images (noise)</td><td>pHash robust hashing (tolerates small perturbations)</td></tr>
      </table>
      <p><strong>Arms race response:</strong> Maintain dedicated "adversarial evasion" research team, continuously track new techniques in violator communities, add discovered techniques to training set (typically monthly iteration cycles).</p>
    </div>
  </div>
</div>

<h2>ğŸ”‘ é¢è¯•æ€»ç»“æ¡†æ¶ / Interview Summary Framework</h2>

<div class="highlight-green">
  <h3>å†…å®¹å®¡æ ¸ç³»ç»Ÿ = 5ä¸ªæ ¸å¿ƒçŸ›ç›¾çš„å¹³è¡¡</h3>
  <table>
    <tr><th>çŸ›ç›¾</th><th>å·¦ç«¯</th><th>å³ç«¯</th><th>å¹³è¡¡ç‚¹</th></tr>
    <tr>
      <td>é€Ÿåº¦ vs ç²¾åº¦</td>
      <td>å¿«é€Ÿé—¨æ§ï¼ˆä¿ä½“éªŒï¼‰</td>
      <td>æ·±åº¦åˆ†æï¼ˆä¿å‡†ç¡®ï¼‰</td>
      <td>ä¸¤é˜¶æ®µï¼šåŒæ­¥è½»é‡ + å¼‚æ­¥é‡å‹</td>
    </tr>
    <tr>
      <td>è¯¯åˆ¤ vs æ¼åˆ¤</td>
      <td>å®å¯æ¼åˆ¤ï¼ˆç”¨æˆ·ä¼˜å…ˆï¼‰</td>
      <td>å®å¯è¯¯åˆ¤ï¼ˆå®‰å…¨ä¼˜å…ˆï¼‰</td>
      <td>æŒ‰å†…å®¹ç±»åˆ«å·®å¼‚åŒ–ï¼šCSAM å®å¯è¯¯åˆ¤ï¼›å¹½é»˜å†…å®¹å®å¯æ¼åˆ¤</td>
    </tr>
    <tr>
      <td>è‡ªåŠ¨åŒ– vs äººå·¥</td>
      <td>å…¨è‡ªåŠ¨ï¼ˆè§„æ¨¡åŒ–ï¼‰</td>
      <td>å…¨äººå·¥ï¼ˆå‡†ç¡®ï¼‰</td>
      <td>ML å¤„ç† 99%ï¼Œäººå·¥å¤„ç†è¾¹ç¼˜+ç”³è¯‰</td>
    </tr>
    <tr>
      <td>ç»Ÿä¸€æ”¿ç­– vs æœ¬åœ°åŒ–</td>
      <td>å…¨çƒç»Ÿä¸€è§„åˆ™</td>
      <td>å®Œå…¨æœ¬åœ°åŒ–</td>
      <td>Policy-as-Codeï¼šæ¨¡å‹ç»Ÿä¸€ï¼Œè§„åˆ™æŒ‰åœ°åŒºé…ç½®</td>
    </tr>
    <tr>
      <td>å¼€æ”¾å¹³å° vs å®‰å…¨</td>
      <td>æœ€å¤§åŒ–è¨€è®ºè‡ªç”±</td>
      <td>æœ€å¤§åŒ–å†…å®¹å®‰å…¨</td>
      <td>åˆ†çº§å¤„ç½šï¼ˆå…ˆé™æƒï¼Œå†ç§»é™¤ï¼‰+ ç”³è¯‰æœºåˆ¶</td>
    </tr>
  </table>
</div>

<div class="series-nav">
  <strong>ğŸ‰ Phase 2.1 AI System Design é¢è¯•é¢˜ç³»åˆ— â€” å®Œç»“ï¼</strong><br>
  6é“ç»å…¸é¢è¯•é¢˜å…¨éƒ¨è¦†ç›–ï¼š
  ChatGPT â†’ æ¨èç³»ç»Ÿ â†’ è¯­ä¹‰æœç´¢ â†’ RAGçŸ¥è¯†åº“ â†’ AI Code Review â†’ <strong>AIå†…å®¹å®¡æ ¸</strong><br><br>
  <strong>ä¸‹ä¸€é˜¶æ®µé¢„å‘Šï¼š</strong>Phase 2 å®Œæ•´å®Œæˆï¼æ¥ä¸‹æ¥è¿›å…¥é¢è¯•å®æˆ˜æ¨¡æ‹Ÿå’Œç³»ç»Ÿå¤ä¹ ã€‚
</div>

<hr>
<p style="color: #5f6368; font-size: 14px;">
  ğŸ“š AIçŸ¥è¯†æ—¥æ¨ | 2026-02-26 | Phase 2.1 æœ€ç»ˆç¯‡ ğŸ‰<br>
  <a href="https://friday.zhilongzheng.com/knowledge/ai/2026-02-26-design-ai-content-moderation.html">åœ¨çº¿é˜…è¯»</a>
</p>

</body>
</html>
