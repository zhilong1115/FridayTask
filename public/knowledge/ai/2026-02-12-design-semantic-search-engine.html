<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>2026-02-12 - è®¾è®¡è¯­ä¹‰æœç´¢å¼•æ“ / Design a Semantic Search Engine</title>
  <style>
    body { font-family: -apple-system, system-ui, sans-serif; max-width: 900px; margin: 0 auto; padding: 20px; background: #fff; color: #1a1a1a; line-height: 1.7; }
    .bilingual { display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin: 15px 0; }
    .zh { border-left: 3px solid #f9ab00; padding-left: 15px; }
    .en { border-left: 3px solid #1a73e8; padding-left: 15px; }
    h1 { color: #3c4043; border-bottom: 2px solid #f9ab00; padding-bottom: 10px; }
    h2 { color: #1a73e8; margin-top: 35px; }
    h3 { color: #5f6368; }
    .architecture { background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 20px 0; }
    pre { background: #1e1e1e; color: #d4d4d4; padding: 15px; border-radius: 8px; overflow-x: auto; font-size: 13px; }
    .highlight { background: #fff3cd; padding: 15px; border-radius: 8px; margin: 15px 0; }
    .highlight h4 { margin-top: 0; color: #856404; }
    .diagram { text-align: left; margin: 20px 0; }
    .follow-up { margin-top: 30px; padding: 15px; border: 1px dashed #dadce0; border-radius: 8px; }
    .tag { display: inline-block; padding: 2px 8px; border-radius: 12px; font-size: 12px; margin: 2px; }
    .tag-interview { background: #e8f0fe; color: #1a73e8; }
    .tag-core { background: #fce8e6; color: #d93025; }
    .series-nav { background: #e8f5e9; padding: 12px; border-radius: 8px; margin: 15px 0; }
    table { width: 100%; border-collapse: collapse; margin: 15px 0; }
    th, td { border: 1px solid #dadce0; padding: 8px 12px; text-align: left; }
    th { background: #f8f9fa; }
    .vs-table td:first-child { font-weight: 600; width: 25%; }
    code { background: #f1f3f4; padding: 2px 6px; border-radius: 4px; font-size: 13px; }
    .interview-q { background: #fce8e6; padding: 15px; border-radius: 8px; margin: 15px 0; }
    .interview-q h4 { color: #d93025; margin-top: 0; }
  </style>
</head>
<body>

  <div class="series-nav">
    ğŸ“š <strong>AI System Design é¢è¯•ç³»åˆ—</strong> Day 3/5
    &nbsp;|&nbsp; <a href="2026-02-10-design-chatgpt-system.html">Day 1: ChatGPT</a>
    &nbsp;|&nbsp; <a href="2026-02-11-design-recommendation-system.html">Day 2: æ¨èç³»ç»Ÿ</a>
    &nbsp;|&nbsp; <strong>Day 3: è¯­ä¹‰æœç´¢</strong>
    &nbsp;|&nbsp; Day 4: RAG çŸ¥è¯†åº“
    &nbsp;|&nbsp; Day 5: AI Code Review
  </div>

  <h1>ğŸ” è®¾è®¡è¯­ä¹‰æœç´¢å¼•æ“ / Design a Semantic Search Engine</h1>
  <p>
    <span class="tag tag-interview">é¢è¯•é«˜é¢‘</span>
    <span class="tag tag-core">æ ¸å¿ƒç³»ç»Ÿ</span>
    ğŸ“… 2026-02-12 | Phase 2.1 AI System Design é¢è¯•é¢˜
  </p>

  <h2>ğŸ“– é¢˜ç›®å®šä¹‰ / Problem Statement</h2>
  <div class="bilingual">
    <div class="zh">
      <p><strong>é¢è¯•å®˜</strong>ï¼šè¯·è®¾è®¡ä¸€ä¸ªè¯­ä¹‰æœç´¢å¼•æ“ï¼Œç”¨æˆ·è¾“å…¥è‡ªç„¶è¯­è¨€æŸ¥è¯¢ï¼Œç³»ç»Ÿè¿”å›è¯­ä¹‰ç›¸å…³çš„æ–‡æ¡£/å•†å“/å†…å®¹ã€‚æ”¯æŒåäº¿çº§æ–‡æ¡£è§„æ¨¡ã€‚</p>
      <p><strong>å…³é”®æŒ‘æˆ˜</strong>ï¼š</p>
      <ul>
        <li>ä¼ ç»Ÿå…³é”®è¯æœç´¢ â†’ è¯­ä¹‰ç†è§£æœç´¢</li>
        <li>æ¯«ç§’çº§å»¶è¿Ÿ @ åäº¿çº§è§„æ¨¡</li>
        <li>ç²¾ç¡®åŒ¹é… + æ¨¡ç³Šè¯­ä¹‰å¹¶å­˜</li>
        <li>å®æ—¶ç´¢å¼•æ›´æ–°</li>
      </ul>
    </div>
    <div class="en">
      <p><strong>Interviewer</strong>: Design a semantic search engine where users enter natural language queries and get semantically relevant documents. Scale to billions of documents.</p>
      <p><strong>Key Challenges</strong>:</p>
      <ul>
        <li>Keyword matching â†’ Semantic understanding</li>
        <li>Sub-100ms latency at billion scale</li>
        <li>Exact match + fuzzy semantic coexist</li>
        <li>Real-time index updates</li>
      </ul>
    </div>
  </div>

  <h2>ğŸ—ï¸ æ•´ä½“æ¶æ„ / High-Level Architecture</h2>
  <div class="architecture">
    <pre>
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Query Flow (Online)                       â”‚
â”‚                                                                  â”‚
â”‚  User Query â”€â”€â†’ [Query Encoder] â”€â”€â†’ query_embedding (768d)       â”‚
â”‚       â”‚                                    â”‚                     â”‚
â”‚       â–¼                                    â–¼                     â”‚
â”‚  [BM25 Index] â”€â”€â†’ keyword_results    [ANN Index] â”€â”€â†’ vector_results
â”‚       â”‚                                    â”‚                     â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ [Hybrid Fusion] â—„â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                         â”‚ (RRF / Linear)                         â”‚
â”‚                         â–¼                                        â”‚
â”‚                  [Cross-Encoder Reranker]                         â”‚
â”‚                         â”‚                                        â”‚
â”‚                         â–¼                                        â”‚
â”‚                  Top-K Results â”€â”€â†’ User                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Indexing Flow (Offline)                       â”‚
â”‚                                                                  â”‚
â”‚  Documents â”€â”€â†’ [Chunker] â”€â”€â†’ [Doc Encoder] â”€â”€â†’ doc_embedding     â”‚
â”‚       â”‚                           â”‚                              â”‚
â”‚       â–¼                           â–¼                              â”‚
â”‚  [BM25 Inverted Index]     [Vector Index (HNSW/IVF)]            â”‚
â”‚       â”‚                           â”‚                              â”‚
â”‚       â””â”€â”€â”€â”€â”€ Both stored in â”€â”€â†’ [Search DB (Vespa/Elastic)] â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    </pre>
  </div>

  <h2>ğŸ”‘ æ ¸å¿ƒç»„ä»¶æ·±åº¦è§£æ / Core Components Deep Dive</h2>

  <h3>1. Embedding æ¨¡å‹ï¼šBi-Encoder vs Cross-Encoder</h3>

  <div class="bilingual">
    <div class="zh">
      <p>æœç´¢ç³»ç»Ÿæœ€å…³é”®çš„è®¾è®¡å†³ç­–ï¼š<strong>ç”¨ä»€ä¹ˆæ¨¡å‹ã€åœ¨å“ªä¸ªé˜¶æ®µç”¨</strong>ã€‚</p>
      <p><strong>Bi-Encoder</strong>ï¼ˆåŒå¡”æ¨¡å‹ï¼‰ï¼šQuery å’Œ Document ç‹¬ç«‹ç¼–ç ï¼Œç”¨ä½™å¼¦ç›¸ä¼¼åº¦åŒ¹é…ã€‚é€Ÿåº¦å¿«ï¼ˆå‘é‡é¢„è®¡ç®—ï¼‰ï¼Œä½†ç²¾åº¦è¾ƒä½ã€‚</p>
      <p><strong>Cross-Encoder</strong>ï¼šQuery å’Œ Document æ‹¼æ¥åä¸€èµ·è¿‡ Transformerã€‚ç²¾åº¦é«˜ï¼ˆèƒ½ç†è§£äº¤äº’å…³ç³»ï¼‰ï¼Œä½†é€Ÿåº¦æ…¢ï¼ˆæ¯å¯¹éƒ½è¦æ¨ç†ï¼‰ã€‚</p>
      <p>ğŸ’¡ <strong>ç”Ÿäº§æ–¹æ¡ˆ</strong>ï¼šBi-Encoder åšå¬å›ï¼ˆå¿«ï¼‰ï¼ŒCross-Encoder åšé‡æ’ï¼ˆç²¾ï¼‰ã€‚è¿™å°±æ˜¯ <strong>Retrieve-then-Rerank</strong> èŒƒå¼ã€‚</p>
    </div>
    <div class="en">
      <p>The most critical decision: <strong>which model, at which stage</strong>.</p>
      <p><strong>Bi-Encoder</strong>: Encode query & doc independently, match via cosine similarity. Fast (vectors pre-computed), but lower precision.</p>
      <p><strong>Cross-Encoder</strong>: Concatenate query + doc, pass through Transformer together. High precision (captures token-level interactions), but slow (O(n) inference).</p>
      <p>ğŸ’¡ <strong>Production pattern</strong>: Bi-Encoder for retrieval (fast), Cross-Encoder for reranking (precise). This is the <strong>Retrieve-then-Rerank</strong> paradigm.</p>
    </div>
  </div>

  <table class="vs-table">
    <tr><th></th><th>Bi-Encoder</th><th>Cross-Encoder</th></tr>
    <tr><td>å»¶è¿Ÿ</td><td>~5ms (ANN lookup)</td><td>~50ms per pair</td></tr>
    <tr><td>åå</td><td>10K+ QPS</td><td>~100 pairs/sec/GPU</td></tr>
    <tr><td>ç²¾åº¦ (NDCG)</td><td>~0.70</td><td>~0.85</td></tr>
    <tr><td>ç”¨é€”</td><td>Stage 1: å¬å›</td><td>Stage 2: é‡æ’ Top-50</td></tr>
    <tr><td>ä»£è¡¨æ¨¡å‹</td><td>E5-large, BGE-M3, Cohere Embed</td><td>ms-marco-MiniLM, BGE-Reranker</td></tr>
  </table>

  <pre><code>// Retrieve-then-Rerank ä¼ªä»£ç 
async function semanticSearch(query: string, topK = 10) {
  // Stage 1: Bi-Encoder å¬å› (fast, broad)
  const queryVec = await biEncoder.encode(query);
  const candidates = await annIndex.search(queryVec, topN=100);

  // Stage 1.5: BM25 keyword å¬å› + èåˆ
  const bm25Results = await invertedIndex.search(query, topN=100);
  const merged = reciprocalRankFusion(candidates, bm25Results, k=60);

  // Stage 2: Cross-Encoder é‡æ’ (slow, precise)
  const pairs = merged.slice(0, 50).map(doc => [query, doc.text]);
  const scores = await crossEncoder.predict(pairs);

  return merged.slice(0, 50)
    .map((doc, i) => ({ ...doc, rerank_score: scores[i] }))
    .sort((a, b) => b.rerank_score - a.rerank_score)
    .slice(0, topK);
}</code></pre>

  <h3>2. å‘é‡ç´¢å¼•ï¼šANN ç®—æ³•é€‰å‹</h3>

  <div class="bilingual">
    <div class="zh">
      <p>åäº¿çº§å‘é‡ä¸èƒ½æš´åŠ›æœç´¢ï¼Œå¿…é¡»ç”¨ <strong>ANN (Approximate Nearest Neighbor)</strong> ç®—æ³•ã€‚é¢è¯•é‡ç‚¹æ˜¯ç†è§£å„ç®—æ³•çš„ <strong>æƒè¡¡</strong>ã€‚</p>
    </div>
    <div class="en">
      <p>Billion-scale vectors require <strong>ANN (Approximate Nearest Neighbor)</strong> algorithms. Interview focus: understand <strong>trade-offs</strong> between approaches.</p>
    </div>
  </div>

  <table>
    <tr><th>ç®—æ³•</th><th>åŸç†</th><th>å»¶è¿Ÿ</th><th>å†…å­˜</th><th>é€‚ç”¨åœºæ™¯</th></tr>
    <tr>
      <td><strong>HNSW</strong></td>
      <td>åˆ†å±‚å¯å¯¼èˆªå°ä¸–ç•Œå›¾ã€‚å¤šå±‚è·³è¡¨ç»“æ„ï¼Œé«˜å±‚ç²—æœç´¢ï¼Œä½å±‚ç²¾æœç´¢</td>
      <td>&lt;1ms</td>
      <td>é«˜ (å…¨é‡åœ¨å†…å­˜)</td>
      <td>å»¶è¿Ÿæ•æ„Ÿï¼Œ&lt;100M å‘é‡</td>
    </tr>
    <tr>
      <td><strong>IVF-PQ</strong></td>
      <td>å…ˆèšç±» (IVF)ï¼Œå†é‡åŒ–å‹ç¼© (PQ)ã€‚åªæœæœ€è¿‘çš„å‡ ä¸ªèšç±»</td>
      <td>~5ms</td>
      <td>ä½ (å‹ç¼© 32x)</td>
      <td>æˆæœ¬æ•æ„Ÿï¼Œ1B+ å‘é‡</td>
    </tr>
    <tr>
      <td><strong>DiskANN</strong></td>
      <td>SSD-based å›¾ç´¢å¼•ã€‚Vamana å›¾ + PQ å‹ç¼©ã€‚ä»…ç´¢å¼•æ”¾å†…å­˜</td>
      <td>~5ms</td>
      <td>æä½</td>
      <td>è¶…å¤§è§„æ¨¡ï¼Œç£ç›˜å‹å¥½</td>
    </tr>
    <tr>
      <td><strong>ScaNN</strong></td>
      <td>Google æ–¹æ¡ˆï¼Œé‡åŒ– + å‰ªæã€‚anisotropic vector quantization</td>
      <td>&lt;1ms</td>
      <td>ä¸­</td>
      <td>Google å†…éƒ¨æ¨èåœºæ™¯</td>
    </tr>
  </table>

  <div class="highlight">
    <h4>ğŸ’¡ é¢è¯•é‡‘å¥ï¼šHNSW vs IVF-PQ æƒè¡¡</h4>
    <p><strong>HNSW</strong> = ç”¨ç©ºé—´æ¢æ—¶é—´ã€‚å›¾ç´¢å¼•å…¨é‡é©»å†…å­˜ï¼Œrecall@10 > 0.95ï¼Œä½† 1B å‘é‡ Ã— 768d Ã— float32 â‰ˆ <strong>3TB å†…å­˜</strong>ã€‚</p>
    <p><strong>IVF-PQ</strong> = ç”¨ç²¾åº¦æ¢ç©ºé—´ã€‚Product Quantization æŠŠ 768d float32 å‹ç¼©åˆ° 96 bytes (32x å‹ç¼©)ï¼Œ1B å‘é‡åªéœ€ <strong>~96GB</strong>ã€‚Recall é™åˆ° ~0.90ï¼Œä½† Cross-Encoder reranking å¯ä»¥è¡¥å›æ¥ã€‚</p>
    <p><strong>ç”Ÿäº§æ–¹æ¡ˆ</strong>ï¼šCoarse retrieval (IVF-PQ, å¤§é‡æ–‡æ¡£) â†’ Fine retrieval (HNSW, çƒ­é—¨æ–‡æ¡£) â†’ Rerankingã€‚æˆ–è€… HNSW + PQ å‹ç¼©çš„æ··åˆæ–¹æ¡ˆã€‚</p>
  </div>

  <pre><code>// HNSW æ ¸å¿ƒå‚æ•° (é¢è¯•è¦çŸ¥é“)
const hnswConfig = {
  M: 16,              // æ¯ä¸ªèŠ‚ç‚¹çš„è¿æ¥æ•° (è¶Šå¤§ç²¾åº¦è¶Šé«˜ã€å†…å­˜è¶Šå¤š)
  efConstruction: 200, // å»ºå›¾æ—¶çš„æœç´¢å®½åº¦ (å»ºç´¢å¼•è´¨é‡)
  efSearch: 100,       // æŸ¥è¯¢æ—¶çš„æœç´¢å®½åº¦ (recall vs latency)
};
// å…³é”®æƒè¡¡: Mâ†‘ â†’ ç²¾åº¦â†‘ + å†…å­˜â†‘ + å»ºç´¢å¼•æ…¢
// efSearchâ†‘ â†’ recallâ†‘ + å»¶è¿Ÿâ†‘ (è¿è¡Œæ—¶å¯è°ƒ!)</code></pre>

  <h3>3. Hybrid Searchï¼šè¯­ä¹‰ + å…³é”®è¯èåˆ</h3>

  <div class="bilingual">
    <div class="zh">
      <p><strong>ä¸ºä»€ä¹ˆä¸èƒ½åªç”¨å‘é‡æœç´¢ï¼Ÿ</strong></p>
      <ul>
        <li>ç²¾ç¡®åŒ¹é…ï¼šç”¨æˆ·æœ "error code E1234"ï¼Œå‘é‡å¯èƒ½æ‰¾åˆ°è¯­ä¹‰ç›¸è¿‘ä½† code ä¸å¯¹çš„ç»“æœ</li>
        <li>ç¨€æœ‰è¯ï¼šæ–°å“ç‰Œåã€ä¸“æœ‰åè¯åœ¨ embedding ç©ºé—´å¯èƒ½æ²¡æœ‰å¥½çš„è¡¨ç¤º</li>
        <li>æ•°å­—/æ—¥æœŸï¼šå‘é‡æ¨¡å‹å¯¹æ•°å­—ä¸æ•æ„Ÿ</li>
      </ul>
      <p><strong>è§£å†³æ–¹æ¡ˆ</strong>ï¼š<strong>Hybrid Search</strong> = BM25 (å…³é”®è¯) + Vector (è¯­ä¹‰)ï¼Œç”¨ RRF èåˆã€‚</p>
    </div>
    <div class="en">
      <p><strong>Why not vector-only?</strong></p>
      <ul>
        <li>Exact match: "error code E1234" â€” vectors may find semantically similar but wrong codes</li>
        <li>Rare terms: New brand names, acronyms may lack good embedding representations</li>
        <li>Numbers/dates: Embedding models are weak with numerical values</li>
      </ul>
      <p><strong>Solution</strong>: <strong>Hybrid Search</strong> = BM25 (keyword) + Vector (semantic), fused with RRF.</p>
    </div>
  </div>

  <pre><code>// Reciprocal Rank Fusion (RRF) â€” é¢è¯•å¿…çŸ¥çš„èåˆç®—æ³•
function reciprocalRankFusion(
  resultSets: SearchResult[][], 
  k: number = 60  // è°ƒèŠ‚å‚æ•°ï¼Œè¶Šå¤§è¶Šå¹³æ»‘
): SearchResult[] {
  const scores = new Map&lt;string, number&gt;();
  
  for (const results of resultSets) {
    for (let rank = 0; rank &lt; results.length; rank++) {
      const docId = results[rank].id;
      const rrfScore = 1 / (k + rank + 1);
      scores.set(docId, (scores.get(docId) || 0) + rrfScore);
    }
  }
  
  return [...scores.entries()]
    .sort(([, a], [, b]) => b - a)
    .map(([id, score]) => ({ id, score }));
}

// ä¸ºä»€ä¹ˆ RRF å¥½ï¼Ÿ
// 1. ä¸éœ€è¦åˆ†æ•°å½’ä¸€åŒ– (BM25 åˆ†å’Œä½™å¼¦ç›¸ä¼¼åº¦é‡çº²ä¸åŒ)
// 2. å¯¹å¼‚å¸¸å€¼é²æ£’ (åŸºäºæ’åè€Œéåˆ†æ•°)
// 3. æ— éœ€è®­ç»ƒæƒé‡ (æ¯” linear combination æ›´ç¨³å®š)</code></pre>

  <h3>4. å®¹é‡ä¼°ç®— / Capacity Estimation</h3>

  <div class="architecture">
    <h4>å‡è®¾ï¼š10äº¿æ–‡æ¡£ï¼Œ100K QPS</h4>
    <table>
      <tr><th>ç»„ä»¶</th><th>è®¡ç®—</th><th>ç»“æœ</th></tr>
      <tr>
        <td>å‘é‡å­˜å‚¨ (raw)</td>
        <td>1B Ã— 768d Ã— 4 bytes</td>
        <td>~3 TB</td>
      </tr>
      <tr>
        <td>å‘é‡å­˜å‚¨ (PQå‹ç¼©)</td>
        <td>1B Ã— 96 bytes (32x)</td>
        <td>~96 GB</td>
      </tr>
      <tr>
        <td>BM25 å€’æ’ç´¢å¼•</td>
        <td>~1B docs, avg 200 tokens</td>
        <td>~500 GB</td>
      </tr>
      <tr>
        <td>Embedding æ¨ç†</td>
        <td>100K QPS Ã— ~2ms/query</td>
        <td>~200 GPU (A10G)</td>
      </tr>
      <tr>
        <td>Reranker æ¨ç†</td>
        <td>100K QPS Ã— 50 pairs Ã— ~1ms/pair</td>
        <td>~5000 GPU ğŸ˜± â†’ éœ€è¦ä¼˜åŒ–</td>
      </tr>
      <tr>
        <td>ANN æœç´¢</td>
        <td>100K QPS Ã— ~1ms (HNSW)</td>
        <td>~100 CPU nodes</td>
      </tr>
    </table>
    <p>âš ï¸ <strong>Reranker æ˜¯ç“¶é¢ˆï¼</strong> ä¼˜åŒ–ç­–ç•¥ï¼š</p>
    <ul>
      <li>åª rerank top-20 (è€Œä¸æ˜¯ top-50)</li>
      <li>ç”¨è’¸é¦åçš„å°æ¨¡å‹ (MiniLM â†’ 6 å±‚ vs 12 å±‚)</li>
      <li>æ‰¹é‡æ¨ç† + TensorRT åŠ é€Ÿ</li>
      <li>é«˜æµé‡æŸ¥è¯¢ç”¨ç¼“å­˜è·³è¿‡ reranker</li>
    </ul>
  </div>

  <h3>5. å®æ—¶ç´¢å¼•æ›´æ–° / Real-time Indexing</h3>

  <div class="bilingual">
    <div class="zh">
      <p>æœç´¢å¼•æ“ä¸èƒ½åªæœ‰ç¦»çº¿ç´¢å¼•ï¼Œæ–°æ–‡æ¡£è¦å°½å¿«å¯æœç´¢ã€‚</p>
      <p><strong>åŒå±‚ç´¢å¼•æ¶æ„</strong>ï¼š</p>
      <ol>
        <li><strong>Main Index</strong>ï¼šå¤§å‹ HNSW/IVF ç´¢å¼•ï¼Œå®šæœŸï¼ˆæ¯å°æ—¶/å¤©ï¼‰å…¨é‡é‡å»º</li>
        <li><strong>Delta Index</strong>ï¼šå°å‹ in-memory ç´¢å¼•ï¼Œå®æ—¶è¿½åŠ æ–°æ–‡æ¡£</li>
        <li>æŸ¥è¯¢æ—¶åŒæ—¶æœä¸¤ä¸ªç´¢å¼•ï¼Œåˆå¹¶ç»“æœ</li>
        <li>å®šæœŸå°† Delta åˆå¹¶åˆ° Mainï¼ˆç±»ä¼¼ LSM-Tree çš„ compactionï¼‰</li>
      </ol>
    </div>
    <div class="en">
      <p>Search engines need near-real-time indexing for new documents.</p>
      <p><strong>Two-tier index architecture</strong>:</p>
      <ol>
        <li><strong>Main Index</strong>: Large HNSW/IVF, rebuilt periodically (hourly/daily)</li>
        <li><strong>Delta Index</strong>: Small in-memory index for real-time additions</li>
        <li>Query both indexes, merge results</li>
        <li>Periodically compact Delta into Main (like LSM-Tree compaction)</li>
      </ol>
    </div>
  </div>

  <pre><code>// åŒå±‚ç´¢å¼•æœç´¢
async function hybridSearch(query: string) {
  const queryVec = await encoder.encode(query);
  
  // å¹¶è¡Œæœä¸¤ä¸ªç´¢å¼•
  const [mainResults, deltaResults] = await Promise.all([
    mainIndex.search(queryVec, topN=100),   // å¤§ç´¢å¼• (HNSW)
    deltaIndex.search(queryVec, topN=20),    // å°ç´¢å¼• (brute-force ok)
  ]);
  
  // åˆå¹¶ + å»é‡ (delta ä¸­çš„ç‰ˆæœ¬æ›´æ–°)
  return mergeAndDeduplicate(mainResults, deltaResults);
}

// åå° compaction
cron.schedule('0 * * * *', async () => {  // æ¯å°æ—¶
  const delta = await deltaIndex.drain();
  await mainIndex.addBatch(delta);
  await mainIndex.optimize();  // å¯é€‰: é‡å»ºå›¾è¿æ¥
});</code></pre>

  <h2>âœ¨ è®¾è®¡äº®ç‚¹ / Design Highlights</h2>

  <div class="highlight">
    <h4>äº®ç‚¹ 1: Matryoshka Representation Learning (MRL) â€” å¼¹æ€§ç»´åº¦</h4>
    <p><strong>é—®é¢˜</strong>ï¼š768d embedding å¤ªå¤§ï¼Œå­˜å‚¨è´µã€‚ä½†ç®€å•æˆªæ–­ï¼ˆå–å‰ 256dï¼‰ä¼šæŸå¤±ç²¾åº¦ã€‚</p>
    <p><strong>æ–¹æ¡ˆ</strong>ï¼šè®­ç»ƒæ—¶è®©æ¨¡å‹åœ¨å¤šä¸ªç»´åº¦ä¸Šéƒ½æœ‰å¥½çš„è¡¨ç¤ºï¼ˆ768d, 512d, 256d, 128dï¼‰ï¼Œè¿è¡Œæ—¶æŒ‰éœ€é€‰æ‹©ç»´åº¦ã€‚</p>
    <p><strong>æ•ˆæœ</strong>ï¼šOpenAI text-embedding-3 ç”¨ MRLï¼Œ256d çš„æ€§èƒ½ â‰ˆ ä¼ ç»Ÿ 1536dï¼Œå­˜å‚¨å‡å°‘ <strong>6x</strong>ï¼</p>
    <p><strong>é¢è¯•ä»·å€¼</strong>ï¼šä½“ç°ä½ äº†è§£æœ€æ–°çš„ embedding ä¼˜åŒ–æŠ€æœ¯ã€‚</p>
  </div>

  <div class="highlight">
    <h4>äº®ç‚¹ 2: Late Interaction (ColBERT) â€” ç²¾åº¦å’Œé€Ÿåº¦çš„ç”œèœœç‚¹</h4>
    <p><strong>é—®é¢˜</strong>ï¼šBi-Encoder ä¸å¤Ÿç²¾å‡†ï¼ŒCross-Encoder ä¸å¤Ÿå¿«ã€‚</p>
    <p><strong>æ–¹æ¡ˆ</strong>ï¼šColBERT çš„ "late interaction"â€”â€”Query å’Œ Doc ç‹¬ç«‹ç¼–ç ï¼ˆåƒ Bi-Encoderï¼‰ï¼Œä½†åœ¨åŒ¹é…æ—¶åš <strong>token-level MaxSim</strong>ï¼ˆåƒ Cross-Encoder çš„éƒ¨åˆ†èƒ½åŠ›ï¼‰ã€‚</p>
    <pre>// ColBERT scoring
Score(Q, D) = Î£_i max_j  cos(q_i, d_j)
// æ¯ä¸ª query token æ‰¾åˆ°æœ€åŒ¹é…çš„ doc token</pre>
    <p><strong>æ•ˆæœ</strong>ï¼šæ¥è¿‘ Cross-Encoder çš„ç²¾åº¦ï¼Œä½†å¯ä»¥é¢„è®¡ç®— doc embeddingsï¼Œå»¶è¿Ÿä»… ~10msã€‚</p>
  </div>

  <div class="highlight">
    <h4>äº®ç‚¹ 3: Query Understanding Layer â€” æœç´¢ä¸åªæ˜¯åŒ¹é…</h4>
    <p><strong>å¥½çš„æœç´¢ç³»ç»Ÿåœ¨ encoding å‰å…ˆ"ç†è§£"æŸ¥è¯¢</strong>ï¼š</p>
    <ul>
      <li><strong>Query Expansion</strong>ï¼šæŠŠ "cheap hotels SF" â†’ "affordable accommodation San Francisco budget lodging"</li>
      <li><strong>Intent Classification</strong>ï¼šåŒºåˆ† navigational (æ‰¾ç‰¹å®šç½‘ç«™) vs informational (æ‰¾ç­”æ¡ˆ) vs transactional (ä¹°ä¸œè¥¿)</li>
      <li><strong>Spell Correction</strong>ï¼š"reccommendation system" â†’ "recommendation system"</li>
      <li><strong>Language Detection</strong>ï¼šå¤šè¯­è¨€è·¯ç”±åˆ°ä¸åŒçš„ embedding æ¨¡å‹</li>
    </ul>
  </div>

  <h2>ğŸ¯ é¢è¯•é«˜é¢‘é—®é¢˜ / Interview Questions</h2>

  <div class="interview-q">
    <h4>Q1: å‘é‡æœç´¢å¦‚ä½•å¤„ç† filterï¼Ÿæ¯”å¦‚"2024å¹´ä»¥åå‘å¸ƒçš„ AI è®ºæ–‡"ï¼Ÿ</h4>
    <p><strong>ç­”</strong>ï¼šä¸‰ç§ç­–ç•¥ï¼Œå„æœ‰æƒè¡¡ï¼š</p>
    <ol>
      <li><strong>Pre-filter</strong>ï¼šå…ˆç”¨ metadata è¿‡æ»¤ï¼Œå†åœ¨å­é›†ä¸Šåš ANNã€‚é—®é¢˜ï¼šè¿‡æ»¤åæ•°æ®åˆ†å¸ƒå˜åŒ–ï¼ŒHNSW å›¾å¯èƒ½æ–­è£‚ã€‚</li>
      <li><strong>Post-filter</strong>ï¼šå…ˆ ANN å– top-Nï¼ˆN >> Kï¼‰ï¼Œå†è¿‡æ»¤ã€‚é—®é¢˜ï¼šå¦‚æœ filter å¾ˆä¸¥æ ¼ï¼Œå¯èƒ½ top-N é‡Œæ²¡å‡ ä¸ªæ»¡è¶³æ¡ä»¶çš„ã€‚</li>
      <li><strong>Hybrid (æ¨è)</strong>ï¼šç”¨ <strong>filtered HNSW</strong>ï¼Œæœç´¢æ—¶ on-the-fly è·³è¿‡ä¸æ»¡è¶³æ¡ä»¶çš„èŠ‚ç‚¹ã€‚Weaviateã€Qdrant éƒ½æ”¯æŒã€‚ä¿è¯ recall çš„åŒæ—¶æ”¯æŒè¿‡æ»¤ã€‚</li>
    </ol>
  </div>

  <div class="interview-q">
    <h4>Q2: å¦‚ä½•ä¿è¯æœç´¢ç»“æœçš„å¤šæ ·æ€§ï¼ˆé¿å…è¿”å› 10 ä¸ªå‡ ä¹ç›¸åŒçš„ç»“æœï¼‰ï¼Ÿ</h4>
    <p><strong>ç­”</strong>ï¼š</p>
    <ul>
      <li><strong>MMR (Maximal Marginal Relevance)</strong>ï¼šåœ¨é€‰æ‹©ä¸‹ä¸€ä¸ªç»“æœæ—¶ï¼ŒåŒæ—¶è€ƒè™‘"ä¸ query çš„ç›¸å…³æ€§"å’Œ"ä¸å·²é€‰ç»“æœçš„å·®å¼‚æ€§"ã€‚<code>score = Î» Ã— sim(q, d) - (1-Î») Ã— max(sim(d, d_selected))</code></li>
      <li><strong>Cluster-based</strong>ï¼šå…ˆå¯¹ candidates èšç±»ï¼Œæ¯ä¸ª cluster å– top-1</li>
      <li><strong>Subtopic modeling</strong>ï¼šè¯†åˆ« query çš„å¤šä¸ªæ„å›¾ï¼Œæ¯ä¸ªæ„å›¾éƒ½æœ‰ç»“æœè¦†ç›–</li>
    </ul>
  </div>

  <div class="interview-q">
    <h4>Q3: Embedding æ¨¡å‹å¦‚ä½•æŒç»­ä¼˜åŒ–ï¼Ÿæ–°å“ç±»/é¢†åŸŸçš„æ–‡æ¡£æœç´¢ä¸å‡†æ€ä¹ˆåŠï¼Ÿ</h4>
    <p><strong>ç­”</strong>ï¼š</p>
    <ul>
      <li><strong>Contrastive Fine-tuning</strong>ï¼šç”¨æœç´¢æ—¥å¿— (query, clicked_doc) ä½œä¸ºæ­£æ ·æœ¬ï¼Œimpression æœªç‚¹å‡»çš„åšè´Ÿæ ·æœ¬ã€‚å‘¨æœŸæ€§å¾®è°ƒã€‚</li>
      <li><strong>Hard Negative Mining</strong>ï¼šç”¨å½“å‰æ¨¡å‹æ‰¾å‡º"æ’åé«˜ä½†ç”¨æˆ·æ²¡ç‚¹å‡»"çš„ç»“æœï¼Œä½œä¸º hard negatives è®­ç»ƒã€‚</li>
      <li><strong>Domain Adaptation</strong>ï¼šåœ¨é¢†åŸŸæ•°æ®ä¸Šç»§ç»­é¢„è®­ç»ƒ (masked language modeling)ï¼Œç„¶åå†å¾®è°ƒ embedding ä»»åŠ¡ã€‚</li>
      <li>âš ï¸ é‡æ–°è®­ç»ƒåå¿…é¡» <strong>reindex å…¨éƒ¨æ–‡æ¡£</strong>ï¼ˆæ‰€æœ‰ embedding éƒ½å˜äº†ï¼‰ã€‚è¿™æ˜¯å¾ˆå¤§çš„è¿ç»´æˆæœ¬ï¼</li>
    </ul>
  </div>

  <div class="interview-q">
    <h4>Q4: å¯¹æ¯”ä¸‰ç§æœç´¢èŒƒå¼ï¼šBM25 Only vs Vector Only vs Hybridã€‚ä»€ä¹ˆåœºæ™¯ç”¨å“ªä¸ªï¼Ÿ</h4>
    <table>
      <tr><th>ç»´åº¦</th><th>BM25</th><th>Vector</th><th>Hybrid</th></tr>
      <tr><td>ç²¾ç¡®åŒ¹é… (error codes, IDs)</td><td>âœ… å¼º</td><td>âŒ å¼±</td><td>âœ… å¼º</td></tr>
      <tr><td>è¯­ä¹‰ç†è§£ ("how to fix")</td><td>âŒ å¼±</td><td>âœ… å¼º</td><td>âœ… å¼º</td></tr>
      <tr><td>é›¶æ ·æœ¬æ³›åŒ–</td><td>âŒ</td><td>âœ…</td><td>âœ…</td></tr>
      <tr><td>è®¡ç®—æˆæœ¬</td><td>ä½</td><td>é«˜ (GPU)</td><td>æœ€é«˜</td></tr>
      <tr><td>ç´¢å¼•å¤§å°</td><td>ä¸­</td><td>é«˜</td><td>æœ€å¤§</td></tr>
      <tr><td>æ¨èåœºæ™¯</td><td>ä»£ç æœç´¢, æ—¥å¿—æœç´¢</td><td>FAQ, å®¢æœ, å¤šè¯­è¨€</td><td>é€šç”¨æœç´¢, ç”µå•†, æ–‡æ¡£</td></tr>
    </table>
    <p>ğŸ’¡ é¢è¯•æ€»ç»“ï¼š<strong>"ç”Ÿäº§ç¯å¢ƒå‡ ä¹æ€»æ˜¯ç”¨ Hybrid"</strong>ï¼Œçº¯å‘é‡æœç´¢åªé€‚åˆç‰¹å®šåœºæ™¯ï¼ˆå¦‚è·¨è¯­è¨€ã€å›¾ç‰‡æœç´¢ï¼‰ã€‚</p>
  </div>

  <h2>ğŸ“š å¯¹æ¯”å‰ä¸¤å¤© / Cross-Reference</h2>

  <table>
    <tr><th>è®¾è®¡æ¨¡å¼</th><th>ChatGPT (Day 1)</th><th>æ¨èç³»ç»Ÿ (Day 2)</th><th>è¯­ä¹‰æœç´¢ (Day 3)</th></tr>
    <tr><td>æ ¸å¿ƒæ¨¡å¼</td><td>SSE æµå¼è¾“å‡º</td><td>å¤šé˜¶æ®µæ¼æ–—</td><td>Retrieve â†’ Rerank</td></tr>
    <tr><td>å»¶è¿Ÿè¦æ±‚</td><td>é¦– Token &lt;500ms</td><td>~200ms E2E</td><td>&lt;100ms E2E</td></tr>
    <tr><td>AI ç»„ä»¶</td><td>LLM (ç”Ÿæˆ)</td><td>åŒå¡” + MMoE (æ’åº)</td><td>Bi-Encoder + Cross-Encoder</td></tr>
    <tr><td>ç¼“å­˜ç­–ç•¥</td><td>Semantic Cache</td><td>Feature Store</td><td>Query Cache + Result Cache</td></tr>
    <tr><td>æˆæœ¬ç“¶é¢ˆ</td><td>Token ç”Ÿæˆ</td><td>Training GPU</td><td>Reranker GPU + å‘é‡å­˜å‚¨</td></tr>
  </table>

  <div class="follow-up">
    <h3>ğŸ’¬ åç»­è®¨è®º / Follow-up Discussion</h3>
    <p>æ˜å¤© Day 4 å°†è¦†ç›– <strong>è®¾è®¡ RAG çŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿ</strong>ï¼ŒæŠŠä»Šå¤©çš„æœç´¢å¼•æ“å’Œ Day 1 çš„ ChatGPT ç»“åˆï¼Œè®¾è®¡ä¼ä¸šçº§é—®ç­”ç³»ç»Ÿã€‚è¿™ä¸‰å¤©çš„å†…å®¹ä¼šåœ¨ Day 4 èåˆï¼</p>
    <p>å¦‚æœå¯¹ HNSW å›¾çš„å…·ä½“æ„å»ºç®—æ³•ã€PQ é‡åŒ–æ•°å­¦åŸç†ã€æˆ– ColBERT çš„å®ç°ç»†èŠ‚æ„Ÿå…´è¶£ï¼Œå¯ä»¥æ·±å…¥è®¨è®º ğŸ”</p>
  </div>

</body>
</html>
